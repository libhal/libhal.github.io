{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udfe1 Home","text":"Welcome to libhal"},{"location":"#abstract","title":"Abstract","text":"<p>libhal exists to make hardware drivers \ud83d\ude9a portable, \ud83e\uddbe flexible, \ud83d\udce6 accessible, and \ud83c\udf70 easy to use. libhal seeks to provide a foundation for embedded drivers, allowing those drivers to be used across different processors, microcontrollers, systems, and devices.</p> <p>The design philosophy of libhal is to be:</p> <ol> <li>Portable &amp; Cross Platform</li> <li>General</li> <li>Fast &amp; Compact</li> <li>Minimalist</li> <li>Safe, Reliable, Tested &amp; Testable</li> <li>Build Time Conscious</li> <li>OS Agnostic</li> </ol>"},{"location":"#the-basics","title":"The Basics","text":"<p>libhal, at its core, is simply a set of interfaces that correspond to hardware devices and peripherals. These interfaces use runtime polymorphism in order to decouple application logic from driver implementation details. This decoupling enables applications to run on any platform device that has the necessary components available.</p> <p>A quick example is a blinker program. You want to turn on and off an LED at a fixed interval. This would require something along the lines of a GPIO and a timer to tell time. In libhal we can use drivers that implement the <code>hal::output_pin</code> and <code>hal::steady_clock</code> interfaces. Such code would look like the following and would support the <code>lpc4078</code>, <code>stm32f103c8</code>, and devices supported by the <code>libhal-micromod</code> project.</p> include/resource_list.hppmain.cppplatform/stm32f103c8.hppplatform/micromod.hppplatform/lpc4078.hpp <pre><code>#pragma once\n\n#include &lt;libhal/functional.hpp&gt;\n#include &lt;libhal/output_pin.hpp&gt;\n#include &lt;libhal/serial.hpp&gt;\n#include &lt;libhal/steady_clock.hpp&gt;\n\nstruct resource_list\n{\n  hal::callback&lt;void()&gt; reset;\n  hal::output_pin* status_led;\n  hal::serial* console;\n  hal::steady_clock* clock;\n};\n\nresource_list initialize_platform();\n</code></pre> <pre><code>#include &lt;libhal-util/steady_clock.hpp&gt;\n\n#include &lt;resource_list.hpp&gt;\n\nresource_list resources{};\n\nint main()\n{\n  try {\n    resources = initialize_platform();\n  } catch (...) {\n    while (true) {\n      // halt here and wait for a debugger to connect\n      continue;\n    }\n  }\n\n  hal::output_pin&amp; led = resources.led;\n  hal::steady_clock&amp; clock = resources.clock;\n\n  for (int i = 0; i &lt; 10; i++) {\n    // Turn on LED\n    led.level(true);\n    hal::delay(clock, 500ms);\n    // Turn off LED\n    led.level(false);\n    hal::delay(clock, 500ms);\n  }\n}\n</code></pre> <pre><code>#include &lt;libhal-arm-mcu/dwt_counter.hpp&gt;\n#include &lt;libhal-arm-mcu/stm32f1/clock.hpp&gt;\n#include &lt;libhal-arm-mcu/stm32f1/constants.hpp&gt;\n#include &lt;libhal-arm-mcu/stm32f1/output_pin.hpp&gt;\n#include &lt;libhal-arm-mcu/stm32f1/uart.hpp&gt;\n#include &lt;libhal-arm-mcu/system_control.hpp&gt;\n\n#include &lt;resource_list.hpp&gt;\n\nresource_list initialize_platform()\n{\n  using namespace hal::literals;\n\n  // Set the MCU to the maximum clock speed\n  hal::stm32f1::maximum_speed_using_internal_oscillator();\n\n  static hal::cortex_m::dwt_counter counter(\n    hal::stm32f1::frequency(hal::stm32f1::peripheral::cpu));\n\n  static hal::stm32f1::uart uart1(hal::port&lt;1&gt;,\n                                  hal::buffer&lt;128&gt;,\n                                  hal::serial::settings{\n                                    .baud_rate = 115200,\n                                  });\n\n  static hal::stm32f1::output_pin led('C', 13);\n\n  return {\n    .reset = +[]() { hal::cortex_m::reset(); },\n    .status_led = &amp;led,\n    .console = &amp;uart1,\n    .clock = &amp;counter,\n  };\n}\n</code></pre> <pre><code>#include &lt;libhal-micromod/micromod.hpp&gt;\n\n#include &lt;resource_list.hpp&gt;\n\nresource_list initialize_platform()\n{\n  using namespace hal::literals;\n\n  hal::micromod::v1::initialize_platform();\n\n  return {\n    .reset = +[]() { hal::micromod::v1::reset(); },\n    .status_led = &amp;hal::micromod::v1::led(),\n    .console = &amp;hal::micromod::v1::console(hal::buffer&lt;128&gt;),\n    .clock = &amp;hal::micromod::v1::uptime_clock(),\n  };\n}\n</code></pre> <pre><code>#include &lt;libhal-arm-mcu/dwt_counter.hpp&gt;\n#include &lt;libhal-arm-mcu/lpc40/clock.hpp&gt;\n#include &lt;libhal-arm-mcu/lpc40/constants.hpp&gt;\n#include &lt;libhal-arm-mcu/lpc40/output_pin.hpp&gt;\n#include &lt;libhal-arm-mcu/lpc40/uart.hpp&gt;\n#include &lt;libhal-arm-mcu/startup.hpp&gt;\n#include &lt;libhal-arm-mcu/system_control.hpp&gt;\n\n#include &lt;resource_list.hpp&gt;\n\nresource_list initialize_platform()\n{\n  using namespace hal::literals;\n\n  // Set the MCU to the maximum clock speed\n  hal::lpc40::maximum(12.0_MHz);\n\n  auto cpu_frequency = hal::lpc40::get_frequency(hal::lpc40::peripheral::cpu);\n  static hal::cortex_m::dwt_counter counter(cpu_frequency);\n\n  static std::array&lt;hal::byte, 64&gt; receive_buffer{};\n  static hal::lpc40::uart uart0(0,\n                                receive_buffer,\n                                hal::serial::settings{\n                                  .baud_rate = 115200,\n                                });\n\n  static hal::lpc40::output_pin led(1, 10);\n\n  return {\n    .reset = +[]() { hal::cortex_m::reset(); },\n    .status_led = &amp;led,\n    .console = &amp;uart0,\n    .clock = &amp;counter,\n  };\n}\n</code></pre>"},{"location":"#support","title":"Support","text":"<ul> <li>libhal discord server (preferred)</li> <li>GitHub issues</li> <li>Cpplang Slack #embedded channel</li> </ul>"},{"location":"#distribution","title":"Distribution","text":"<ul> <li>Conan package manager</li> <li>Source code is hosted on GitHub</li> </ul>"},{"location":"#sponsorships","title":"Sponsorships","text":"<p>We are proud to be sponsored by JFrog. JFrog generously provides us with free artifact management, security, and CI/CD tools, allowing us to focus on the success of our project.</p> <p>We are grateful for their support and contribution to the open source community. Thank you, JFrog!</p> <p>For more information about JFrog's community initiatives, visit their Giving Back page.</p>"},{"location":"getting_started/","title":"\ud83d\ude80 Getting Started","text":""},{"location":"getting_started/#install-prerequisites","title":"\ud83e\uddf0 Install Prerequisites","text":"<p>What you will need in order to get started with libhal.</p> <ul> <li><code>python</code>: 3.10 or above</li> <li><code>conan</code>: 2.2.0 or above</li> <li><code>llvm</code>: 17</li> <li><code>make</code>: (CMake is downloaded via conan and uses make to build)</li> <li><code>git</code> (only needs to be installed on Windows)</li> </ul> Ubuntu 20.04+MacOS XWindows <p>Install <code>llvm</code> toolchain &amp; APT repos:</p> <pre><code>wget https://apt.llvm.org/llvm.sh\nchmod +x llvm.sh\nsudo ./llvm.sh 17\n</code></pre> <p>Install LLVM's C++ standard library (this will use the llvm apt repos):</p> <pre><code>sudo apt install libc++-17-dev libc++abi-17-dev\n</code></pre> <p>Info</p> <p>If you are using 20.04 you will need to upgrade Python to 3.10:</p> <pre><code>sudo apt update\nsudo apt install software-properties-common -y\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt install Python3.10\n</code></pre> <p>Install <code>pipx</code> which is used to install conan:</p> <pre><code>sudo apt install pipx\n</code></pre> <p>Installing conan:</p> <pre><code>pipx install \"conan&gt;=2.10.1\"\n</code></pre> <p>Install Homebrew:</p> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre> <p>Install latest version of Python &amp;&amp; llvm:</p> <pre><code>brew install python\nbrew install llvm@17\nbrew install pipx\n</code></pre> <p>Install conan:</p> <pre><code>pipx install \"conan&gt;=2.10.1\"\n</code></pre> <p>Make <code>clang-tidy</code> available on the command line:</p> <pre><code>sudo ln -s $(brew --prefix llvm)/bin/clang-tidy /usr/local/bin/\n</code></pre> <p>Install Rosetta (only required for M1 macs):</p> <pre><code>/usr/sbin/softwareupdate --install-rosetta --agree-to-license\n</code></pre> <p>We recommend using the <code>choco</code> package manager for windows as it allows easy installation of tools via the command line.</p> <p>To install <code>choco</code>, open PowerShell as an administrator and run the following command:</p> <pre><code>Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))\n</code></pre> <p>Tip</p> <p>If the <code>choco</code> command doesn't work after running this script try closing and opening again PowerShell.</p> <p>When <code>choco</code> prompts you to run install scripts from the commands below enter <code>all</code> so it can install everything.</p> <p>Install <code>git</code> (must be in admin powershell):</p> <pre><code>choco install git\n</code></pre> <p>Install mingw to get mingw-make for Windows CMake (must be in admin powershell):</p> <pre><code>choco install mingw\n</code></pre> <p>Install <code>python</code> (must be in admin powershell):</p> <pre><code>choco install python --version=3.12.2\n</code></pre> <p>Install llvm (must be in admin powershell):</p> <pre><code>choco install llvm --version=17.0.6\n</code></pre> <p>Install conan (must be in admin powershell):</p> <pre><code>python -m pip install -U \"conan&gt;=2.10.1\"\n</code></pre> <p>There is no more installation required at this point.</p> <p>Close and reopen powershell as a normal user now.</p>"},{"location":"getting_started/#setting-up-conan","title":"\ud83d\udd27 Setting up Conan","text":"<p>Add the <code>libhal-trunk</code> repository to your system. This repository holds all of the libhal packages.</p> <pre><code>conan remote add libhal-trunk https://libhal.jfrog.io/artifactory/api/conan/trunk-conan\n</code></pre> <p>Next, install the libhal <code>settings_user.yml</code> which extends the architectures of conan's <code>settings.yml</code> file to include baremetal architectures. These additional architecture definitions are required for ALMOST ALL libhal applications.</p> <pre><code>conan config install -sf profiles/baremetal/v2 https://github.com/libhal/conan-config.git\n</code></pre> <p>Next, setup the host profile. Host profiles define the compiler, compiler version, standard library version, and many other settings used to configure how applications are built.</p> <p>First detect the default.</p> <pre><code>conan profile detect --force\n</code></pre> <p>Now install the profile for your particular OS and CPU architecture.</p> Intel LinuxARM64 LinuxIntel WindowsARM64 Windows <p>If your host machine is using an intel core processor as its CPU then you'll want to use this default configuration.</p> <pre><code>conan config install -sf profiles/x86_64/linux/ -tf profiles https://github.com/libhal/conan-config.git\n</code></pre> <p>It is less likely your host desktop is an ARM64. This section is mostly for building applications and tests on a Raspberry PI or other SBC. But if you do have a laptop powered by an ARM64 core, then this is the correct configuration for you.</p> <pre><code>conan config install -sf profiles/armv8/linux/ -tf profiles https://github.com/libhal/conan-config.git\n</code></pre> <p>If your Windows machine uses an Intel processor then you'll want to use this default configuration.</p> <pre><code>conan config install -sf profiles/x86_64/windows/ -tf profiles https://github.com/libhal/conan-config.git\n</code></pre> <p>If you have a modern surface laptop with ARM64, then this may be the right choice for you (this profile is untested).</p> <pre><code>conan config install -sf profiles/armv8/windows/ -tf profiles https://github.com/libhal/conan-config.git\n</code></pre> <p>For M1 Mac users:</p> M1 Mac 13 (Ventura)M1 Mac 14 (Sonoma)M1 Mac 15 (Sequoia) <p>If your Mac Book uses an M1 processor then you'll want to use this default configuration.</p> <pre><code>conan config install -sf profiles/armv8/mac-13/ -tf profiles https://github.com/libhal/conan-config.git\n</code></pre> <p>If your Mac Book uses an M1 processor then you'll want to use this default configuration.</p> <pre><code>conan config install -sf profiles/armv8/mac-14/ -tf profiles https://github.com/libhal/conan-config.git\n</code></pre> <p>If your Mac Book uses an M1 processor then you'll want to use this default configuration.</p> <pre><code>conan config install -sf profiles/armv8/mac-15/ -tf profiles https://github.com/libhal/conan-config.git\n</code></pre> <p>For Intel Mac users:</p> Intel Mac 13 (Ventura)Intel Mac 14 (Sonoma)Intel Mac 15 (Sequoia) <p>If your Mac Book uses an Intel processor then you'll want to use this default configuration.</p> <pre><code>conan config install -sf profiles/x86_64/mac-13/ -tf profiles https://github.com/libhal/conan-config.git\n</code></pre> <p>If your Mac Book uses an Intel processor then you'll want to use this default configuration.</p> <pre><code>conan config install -sf profiles/x86_64/mac-14/ -tf profiles https://github.com/libhal/conan-config.git\n</code></pre> <p>If your Mac Book uses an Intel processor then you'll want to use this default configuration.</p> <pre><code>conan config install -sf profiles/x86_64/mac-15/ -tf profiles https://github.com/libhal/conan-config.git\n</code></pre>"},{"location":"getting_started/#building-demos","title":"\ud83d\udee0\ufe0f Building Demos","text":"<p>Before start building demos, we have to consider on what device do we plan to run the demo on? ARM microcontrollers are quite common so lets use that as an example. Lets clone the <code>libhal-arm-mcu</code> repo.</p> <pre><code>git clone https://github.com/libhal/libhal-arm-mcu\ncd libhal-arm-mcu\n</code></pre> <p>The next lets install the device profiles. Device profiles instruct the build system, conan &amp; cmake, to build the binaries for your particular device. A few commonly used profiles are the <code>lpc4078</code> and <code>stm32f103c8</code> profiles. To make them available on your system run the following command:</p> <pre><code>conan config install -sf conan/profiles/v1 -tf profiles https://github.com/libhal/libhal-arm-mcu.git\n</code></pre> <p>The device profiles only has half of the information. The other half needed to build an application is the compiler profile. Compiler profiles are used to instruct the conan+cmake build system on the compiler to use for the build.</p> <pre><code>conan config install -sf conan/profiles/v1 -tf profiles https://github.com/libhal/arm-gnu-toolchain.git\n</code></pre> <p>Now we have everything we need to build our project. To build using conan you just need to run the following:</p> LPC4078STM32F103 <pre><code>conan build demos -pr lpc4078 -pr arm-gcc-12.3\n</code></pre> <pre><code>conan build demos -pr stm32f103c8 -pr arm-gcc-12.3\n</code></pre> <p>When you build for the <code>lpc4078</code> you should have a <code>uart.elf</code> and <code>blinker.elf</code> file in the <code>demos/build/lpc4078/MinSizeRel/</code> directory.</p> <p>When you build for the <code>stm32f103c8</code> you should have a <code>uart.elf</code> and <code>blinker.elf</code> file in the <code>demos/build/stm32f103c8/MinSizeRel/</code> directory.</p> <p>Error</p> <p>You can get this error if the arm gnu toolchain wasn't installed correctly and the cmake toolchain was already generated.</p> <pre><code>  The CMAKE_CXX_COMPILER:\n\n    /Users/user_name/.conan2/p/b/arm-ged7418b49387e/p/bin/bin/arm-none-eabi-g++\n\n  is not a full path to an existing compiler tool.\n</code></pre> <p>Fix this by deleting the <code>demos/build/</code> like so:</p> <pre><code>rm -r demos/build\n</code></pre>"},{"location":"getting_started/#uploading-demos-to-device","title":"\ud83d\udcbe Uploading Demos to Device","text":"<p>In order to complete this tutorial you'll one of these devices:</p> <ul> <li>LPC4078 MicroMod with SparkFun ATP board</li> <li>SJ2 Board</li> <li>STM32F103 MicroMod with SparkFun ATP board</li> <li>STM32 Blue Pill along with USB to serial adapter</li> </ul> LPC4078STM32F103 <p>Install the <code>nxpprog</code> flashing software for LPC devices:</p> <pre><code>python3 -m pip install nxpprog\n</code></pre> <p>Tip</p> <p>On Ubuntu 22.04 you will need to use the command <code>python3.10</code> because the default python is usually 3.8.</p> <pre><code>python3.10 -m pip install nxpprog\n</code></pre> <p>On other systems you may have to just use <code>python</code> as the command.</p> <pre><code>nxpprog --control --binary demos/build/lpc4078/MinSizeRel/uart.elf.bin --device /dev/tty.usbserial-140\n</code></pre> <ul> <li>Replace <code>/dev/tty.usbserial-140</code> with the correct port   name of the device plugged into your computer via USB.</li> <li>Replace <code>uart.elf.bin</code> with any other application found in the   <code>demos/applications/</code> directory.</li> </ul> <p>Install the <code>stm32loader</code> flashing software for STM32 devices:</p> <pre><code>python3 -m pip install stm32loader\n</code></pre> <p>then</p> <pre><code>stm32loader -e -w -v -B -p /dev/tty.usbserial-10 demos/build/stm32f103c8/MinSizeRel/uart.elf.bin\n</code></pre> <p>Replace <code>/dev/tty.usbserial-10</code> with the correct port name of the device plugged into your computer via USB.</p> <p>Use <code>demos/build/stm32f103c8/Debug/uart.elf.bin</code> or replace it with any other application to be uploaded.</p> <p>Question</p> <p>Don't know which serial port to use?</p> <p>Question</p> <p>stm32loader command faild because it doesn't have permission?</p>"},{"location":"getting_started/#on-linux","title":"On Linux","text":"<p>With the device unplugged, run the below command <pre><code>$ ls /dev/ttyUSB*\nls: cannot access '/dev/ttyUSB*': No such file or directory\n</code></pre> Plug the device into the USB port, then rerun the command, the device should appear in the result: <pre><code>$ ls /dev/ttyUSB*\n/dev/ttyUSB0\n</code></pre> The device may also be under the name <code>/dev/ttyACM*</code>, like below <pre><code>$ ls /dev/ttyACM*\n/dev/ttyACM0\n</code></pre> From the above 2 examples for device name, the port name in the <code>stm32loader</code> command would be replaced with <code>/dev/ttyUSB0</code> or <code>/dev/ttyACM0</code> respectively.</p>"},{"location":"getting_started/#on-mac","title":"On Mac","text":"<p>With the device unplugged, run the below command <pre><code>$ ls /dev/tty.usbserial-*\nzsh: no matches found: /dev/tty.usbserial-*\n</code></pre> Plug the device into the USB port, then rerun the command, the device should appear in the result: <pre><code>$ ls /dev/tty.usbserial-*\n/dev/tty.usbserial-14240\n</code></pre></p> <p>From the above example for the device name, the port name in the <code>stm32loader</code> command would be replaced with <code>/dev/tty.usbserial-14240</code>.</p>"},{"location":"getting_started/#on-windows","title":"On Windows","text":"<p>Open Device Manager, by pressing the Windows key and typing \"Device Manager\", then pressing enter.</p> <p>Once the Device Manager window is open, plug the device in to your computer via USB and expand the <code>Ports (COM &amp; LPT)</code> menu. The device should be visible in the list with a COM port like below:</p> <p> From the above screenshot, the port name in the <code>stm32loader</code> command would be replaced with <code>COM3</code>.</p>"},{"location":"getting_started/#on-linux_1","title":"On Linux","text":"<p>Add yourself to the dialout user group to give yourself the permission. This group has the permission to talk to serial ports.</p> <pre><code>$ usermod -a -G dialout $USER\n</code></pre>"},{"location":"getting_started/#changing-built-type","title":"\u26a1\ufe0f Changing Built Type","text":"<p>The build type determines the optimization level of the project. The libhal default for everything is <code>MinSizeRel</code> because code size is one of the most important aspects of the project.</p> <p>You can also change the <code>build_type</code> to following build types:</p> <ul> <li>\ud83e\uddea Debug: Turn on some optimizations to reduce binary size and improve   performance while still maintaining the structure to make debugging easier.   Recommended for testing and prototyping.</li> <li>\u26a1\ufe0f Release: Turn on optimizations and favor higher performance   optimizations over space saving optimizations.</li> <li>\ud83d\udddc\ufe0f MinSizeRel: Turn on optimizations and favor higher space saving   optimizations over higher performance.</li> </ul> <p>To override the default and choose <code>Release</code> mode simply add the following to your conan command: <code>-s build_type=Release</code></p>"},{"location":"getting_started/#creating-a-new-project","title":"\ud83c\udf89 Creating a new Project","text":"<p>Start by cloning <code>libhal-starter</code>:</p> <pre><code>git clone https://github.com/libhal/libhal-starter.git\n</code></pre> <p>Take a look at the <code>README.md</code> of libhal/libhal-starter to get details about how to modify the starter project and make it work for your needs.</p>"},{"location":"summary/","title":"Summary","text":"<ul> <li>\ud83c\udfe1 Home</li> <li>\ud83d\ude80 Getting Started</li> <li>\ud83d\udcd6 User Guide</li> <li>\ud83e\uddd1\ud83c\udfff\u200d\ud83d\udcbb Setting up VSCode</li> <li>\ud83e\uddf1 Fundamentals of libhal</li> <li>\ud83d\udd17 Interfaces in libhal</li> <li>\ud83c\udfaf Debugging Firmware</li> <li>\ud83e\udea4 Error Handling in libhal</li> <li>\u2696\ufe0f Policies &amp; FAQ</li> <li>\ud83c\udfeb Education</li> <li>What are Embedded Systems?</li> <li>Bit Masking</li> <li>Microcontroller Architecture</li> <li>General Purpose I/O</li> <li>DMA</li> <li>Timers &amp; Counters</li> <li>ADC</li> <li>PWM</li> <li>SPI</li> <li>UART</li> <li>I2C</li> <li>DAC</li> <li>CAN BUS</li> <li>Basics of Sensors</li> <li>Basics of Actuators</li> <li>RTOS</li> <li>TBD</li> <li>\ud83d\udcda Contributor Guides</li> <li>\ud83d\udcdc Design Philosophy</li> <li>\ud83d\uddc3\ufe0f Organization</li> <li>\ud83c\udfa8 Style Guide</li> <li>\ud83d\udd17 Interface Design Philosophy</li> <li>\ud83d\udd39 Library Development Guide</li> <li>\ud83e\udde0 ARM Cortex M Bring Up</li> <li>\u23e9 DMA Tutorial</li> <li>\u2b06\ufe0f Upgrade Device Library to 3.x.y</li> <li>\ud83c\udfd7\ufe0f Architectural Design Decisions</li> <li>\ud83d\udcca Project Information</li> <li>\ud83d\udfe2 Library Status \ud83d\udd34</li> <li>About</li> <li>\ud83e\udde9 APIs</li> </ul>"},{"location":"contributor_guide/architecture/","title":"\ud83c\udfd7\ufe0f Architectural Design Decisions","text":""},{"location":"contributor_guide/architecture/#a1-always-use-modern-c","title":"A.1 Always use modern C++","text":"<p>libhal uses the modern C++. Meaning that libhal is will follow the most modern and available compilers available. When a sufficient number of features have become available in both GCC &amp; Clang and are determined to be useful to libhal libhal will increment its major number to indicate that it has upgraded compiler versions.</p> <p>This decision exists to escape the issues of vendor and toolchain lock in thats prevalant in the C++ and embedded industry. With sufficient testing, upgrading compilers shouldn't result in bugs in applications.</p>"},{"location":"contributor_guide/architecture/#a2-interface-design-choices","title":"A.2 Interface Design Choices","text":"<p>Interfaces MUST follow this layout:</p> <ul> <li>Use <code>#pragma once</code> at the start of the file: Simpler than an include guard</li> <li>All <code>virtual</code> functions must be private &amp; each <code>virtual</code> functions is   accompanied by a public API that is used to call the virtual API</li> <li>~~The return type of each API MUST be a <code>result&lt;T&gt;</code> where <code>T</code> is a structure.~~ Amendment 1.0: Return types should never be a structure with the   expectation that it can be grown in the future. This is an ABI break.</li> </ul> <p>Pragma once is needed to ensure files are included once. Its less error prone then hand writing include guards.</p> <p>The reasons for a private virtual with public API can be found in this article (TODO: add link to article).</p> <p>Returning a structure for each API means that, in the future, if the return type needs to be extended, it can be done without breaking down stream libraries. For example:</p> <pre><code>class adc {\n  struct read_t { // V1\n    float percentage;\n  };\n  struct read_t { // V2\n    float percentage;\n    // Optional field that is default initialized to std::nullopt indicating\n    // that it defaults to not exist\n    std::optional&lt;uint8_t&gt; bit_resolution = std::nullopt;\n  };\n};\n</code></pre> <p>Given that the field <code>bit_resolution</code> is an optional, code looking for it can determine if it is available or not, and code that never used it can ignore it.</p>"},{"location":"contributor_guide/architecture/#a21-no-utility-methods-in-interfaces-ufcs","title":"A.2.1 No utility methods in interfaces (UFCS)","text":"<p>Utility functions shall not exist in interface definitions. For example, <code>hal::i2c</code> could have a <code>hal::i2c::write()</code> and <code>hal::i2c::read()</code> function implemented in its interface.</p> <p>This has the effect of reducing the number of headers in the interface files and dependencies. This, in turn, results in an interface that is minimal, clean, and simple.</p> <p>The major purpose of this is to keep compile times down as much possible for each interface. This also ensures that the \"pay-for-what-you-use\" model is followed. No need to pay for a utility you never planned to use.</p> <p>The final reason is in preparation for UFCS (Unified Function Call Syntax). UFCS is a proposal for C++23 and C++26. It did not get into C++23 but is slated for review in 26. For more details see this page What is unified function call syntax anyway?.</p>"},{"location":"contributor_guide/architecture/#a3-using-tweak-files-over-macros","title":"A.3 Using tweak files over macros","text":"<p>Tweak files were used as an alternative to MACROS. MACROs can be quite problematic in many situations and are advised against in the core C++ guidelines. The benefits of tweak files can be found here.</p>"},{"location":"contributor_guide/architecture/#a4-header-only-implementations-see-amendment-a21","title":"A.4 \u274c ~~Header Only Implementations~~ \u27a1\ufe0f (See Amendment A.21)","text":"<p>libhal libraries and drivers are, in general, header-only. libhal uses header only implementations in order to enable the broadest set of package managers, build system and projects to use it.</p> <p>The strongest reason for a header-only approach is due to the fact that libhal libraries never intend to be distributed in prebuilt binaries. Conan is designed to ship with prebuilt binaries or build against the host machine. These settings can be altered, but you still end up with a single global prebuilt binary for a driver does not make sense when that driver could be used in a variety of environments such as the host device for host side tests, a specific target device, and a target device that is in the family of that specific target device.</p> <p>For example, lets consider liblpc40xx. If you are building to target the lpc4078 chip then that prebuilt ought to be built with usage of FPU registers enabled. But if you use that same prebuilt with the lpc4074, you'll find that the program crashes because the 74 variant does not have an FPU. You can attempt make a prebuilt binary for ever possible build variation that an embedded engineer may want, but you'll always come up short. The better approach is to simply build the library each time, thus ensuring that the build flags are considered each time.</p> <p>If compile-times are a concern, there are reasonably easy methods for managing this. See Handling Long Compile Times.</p>"},{"location":"contributor_guide/architecture/#a5-encapsulated-memory-mapped-classes","title":"A.5 Encapsulated Memory Mapped Classes","text":"<p>Target drivers that use Memory-Mapped-IO usually come with a vendor generated header file that describes each peripheral as a structure type, along with bit mask MACROs, and MACROs that result in pointers to each peripheral in memory. The main problem using these headers files causes is naming conflicts. Many of these vendor generated headers work with both C and C++. Meaning that namespaces are not utilized. And many do not expect that they will be used in an environment where another vendor generated header file will exists. So no care is taken to ensure that the names of the types are unique. This WILL cause linker errors as the linker sees both <code>GPIO_TypeDef</code> from an STM library and <code>GPIO_TypeDef</code> from an LPC library that aren't the same.</p> <p>Because of this we have style S.x Encapsulated Memory Mapped classes guideline.</p>"},{"location":"contributor_guide/architecture/#a6-using-halfunction_ref-over-stdfunction","title":"A.6 Using <code>hal::function_ref</code> over <code>std::function&amp;</code>","text":"<p><code>std::function</code> has all of the flexibility and functionality needed, but it has the potential to allocate and requires potentially expensive copy operations when passed by value.</p> <p><code>hal::function_ref</code> is a non-owning version of the <code>std::function</code>, with a size of just two pointers. <code>hal::function_ref</code> fits most use cases in that class functions that take them only need them for the duration of the function and do not need to own them for later.</p> <p>!!! info <code>hal::function_ref</code> is an alias for <code>tl:function_ref</code> which comes from     the project     TartanLlama/function_ref.</p>"},{"location":"contributor_guide/architecture/#a7-using-virtual-runtime-polymorphism","title":"A.7 Using <code>virtual</code> (runtime) polymorphism","text":"<p>Polymorphism is critical for libhal to reach the goals of flexible and easy of use. Static based polymorphism, by its nature, is inflexible at runtime and can be quite complicated to work with.</p> <p>Runtime polymorphism, or the usage of <code>virtual</code> enables a broader scope of flexibility and isolation between drivers and application logic. The only downside to using <code>virtual</code> polymorphism is the cost of a virtual function call. But the actual cost of making a virtual function call is usually tiny in comparison to the work performed in the actual API call. In most cases the call latency and lack of inlining of a virtual call isn't an important factor in most applications.</p> <p>And over all, along with the broad amount of flexibility comes the ease of use. Virtual polymorphism for interfaces is very easy to perform and has a ton of language support.</p>"},{"location":"contributor_guide/architecture/#a8-strongly-leverage-package-managers","title":"A.8 Strongly Leverage Package Managers","text":"<p>Finding and integration libraries into C++ programs is a pain. Doing the same thing for embedded is doubly so, especially if there is vendor IDE lock in. libhal seeks to escape this by using the available package managers and indexes.</p> <p>Libhal was designed around and split up into parts that each come together via these package managers. The purpose of this design is to achieve:</p> <ul> <li>Stable version and release control for each library</li> <li>Can be easily found the indexes</li> <li>Ease of integration</li> </ul>"},{"location":"contributor_guide/architecture/#a9-foundation-interface-stability","title":"A.9 Foundation &amp; Interface Stability","text":"<p><code>libhal-util</code>, <code>libhal-mock</code> and <code>libhal-soft</code> were all apart of <code>libhal</code> originally, but due to the constant changes and API breaks in those categories of code, the version number of <code>libhal</code> would increment constantly, shifting the foundation of the ecosystem. To prevent constant churn and API breaks <code>libhal</code> was split into those 4 libraries.</p> <p>The goal is to keep the version number for <code>libhal</code> constant for long periods of time to prevent breaking down stream libraries, drivers, and applications.</p>"},{"location":"contributor_guide/architecture/#a10-libhal-driver-directory","title":"A.10 libhal driver directory","text":"<p>One of the libhal repos will contain a directory of libhal libraries that extend it along with which interfaces it implements and what type of library it is.</p> <p>Official libhal libraries must go into the directory. Developers outside of the libhal organization can also contribute to and opt into this directory by making a PR to the repo containing the directory.</p> <p>The purpose of this is to make finding and exploring the available set of drivers easier for the end developer by having them all in one place.</p>"},{"location":"contributor_guide/architecture/#a11-github-actions-remote-workflows","title":"A.11 Github Actions &amp; Remote Workflows","text":"<p>libhal uses github and github action \"workflow_dispatch\" to allow other repos to reuse libhal's continuous integration steps. The actions are configurable via input parameters to allow libraries to customize and control how the CI works.</p> <p>libhal's CI attempts to use as many tools as reasonable to make sure that the C++ source code follows the style guide, C++ core guidelines and retains a certain level of quality. All offical libhal libaries must opt in to the common libhal/libhal workflow.</p> <p>This helps to ensure that all projects are held to the same standard and quality. The workflow files can be found in <code>libhal/libhal/.github/workflows</code>.</p>"},{"location":"contributor_guide/architecture/#a12-boostut-as-our-unit-testing-framework","title":"A.12 Boost.UT as our unit testing framework","text":"<p>Boost.UT was chosen for its lack of macros, stunning compile time performance, and its ease of use.</p>"},{"location":"contributor_guide/architecture/#a13-boostleaf-for-error-handling-see-amendment-a22","title":"A.13 \u274c ~~Boost.LEAF for error handling~~ \u27a1\ufe0f (See Amendment A.22)","text":"<p>One major issue with any project is handling errors. Because the <code>libhal</code> interfaces can be used in such broad environments, it is hard to determine what the BEST error type in advance could work for all users. Some use error codes, some use <code>std::expected&lt;T, E&gt;</code>, and some use exceptions.</p> <p>Error codes are problematic as they tend to lack details and context around an error. Sometimes the documentation along with the error code provides all of the necessary context, but many times more context is needed.</p> <p><code>std::expected&lt;T, E&gt;</code> seems like a better alternative to error codes, but... is it really? What should <code>E</code> be? An error code? What if we have it be an error code and a const string. What if we want a file name and function name? What about a line number? What about 16 bytes for holding context information about the error? That should be enough, right? What about- what about- what about? ... wait, how big is this error type? 32 bytes? Wasn't this supposed to be light weight? Unfortunately, <code>std::expected</code> is not a good choice for interfaces with extremely broad and unknowable of error states. This forces the error type to be massive to accommodate everything and everyone.</p> <p>Exceptions somewhat fix this issue but are still lacking. The benefit of exceptions is that you can throw just about anything, meaning the developer can provide loads of information in the thrown object. But exceptions fail on 4 counts:</p> <ul> <li>Exceptions tend to not be available for embedded systems, either due to a     toolchain not compiling with them enabled or because a project has strict     requirements that forbid exceptions.</li> <li>When exceptions do occur, the amount of time it takes to reach its catch can     take a long time, longer than what real time applications can handle.</li> <li>Normally requires heap allocation</li> <li>Exceptions can only throw one type and the cost of those thrown exceptions     are always paid for.</li> </ul> <p>Boost.LEAF has the following properties:</p> <ul> <li>Portable single-header format, no dependencies.</li> <li>Tiny code size when configured for embedded development.</li> <li>No dynamic memory allocations, even with very large payloads.</li> <li>Deterministic unbiased efficiency on the \"happy\" path and the \"sad\" path.</li> <li>Error objects are handled in constant time, independent of call stack depth.</li> <li>Can be used with or without exception handling.</li> <li>Can throw more than 1 error at a time</li> </ul> <p>All of these features are critical for libhal to have the performance for real time applications.</p> <p>The last feature is important for debugging, bug reports, and context specific error handling. Boost.LEAF gives the driver the choice to emit several error types and allows the user to pick out which one they would like to opt to catch if any of them. This can be used to capture an error code as well as s snapshot of the register map of a peripheral, the object's current state or even a debug message.</p>"},{"location":"contributor_guide/architecture/#a14-using-statement-expressions-with-hal_check-see-amendment-a22","title":"A.14 ~~Using Statement Expressions with <code>HAL_CHECK()</code>~~ \u27a1\ufe0f (See Amendment A.22)","text":"<p><code>HAL_CHECK()</code> is the only MACRO in <code>libhal</code>. It exists because there is nothing like Rust's <code>?</code> operator which either unwraps a value or returns an error from the current function. The \"Statement Expression\" only works with GCC &amp; Clang which is one of the reasons why <code>libhal</code> only supports those compilers. Compare the following two expressions:</p> <pre><code>// 1. Using statement expressions\nauto percentage = HAL_CHECK(adc.read()).percentage;\n\n// 2. Without using statement expressions\nHAL_CHECK(adc_read_temporary, adc.read());\nauto percentage = adc_read_temporary.percentage;\n</code></pre> <p>The second option looks very unnatural and require explanation. On the other hand users who have never seen <code>HAL_CHECK()</code> in action have an immediate idea of how it works in the first section of the code. Portability to other compilers was sacrificed in order to make the code easier to read, understand, and write.</p>"},{"location":"contributor_guide/architecture/#a15-libhal-will-not-use-fixed-point","title":"A.15 <code>libhal</code> WILL NOT use fixed point","text":"<p>Because fixed point will NOT result in better performance or space savings compared to SOFTWARE floating point. Team did venture to use fixed point throughout the entire code base and when we felt that the fixed point code reached a point where it was usable everywhere, we benchmarked it and got these:</p> <pre><code>double_time            = 8921794\n[i64 +Round]fixed_time = 4558238 (best fixed point option)\n[soft]float_time       = 1424913\n[i64 -Round]fixed_time = 1410720 (precision issues)\n[i32 +Round]fixed_time = 815107  (will easily overflow)\n[hard]float_time       = 110089  (not always available)\n[i32 -Round]fixed_time = 95085   (will not actually work)\n</code></pre> <p>Here is an old gist of the example: kammce/fixed_v_float.cpp</p> <p>The above metrics were for a program that run a map function to map an input number from one range to another range. The numbers on the right hand side are the number of cycles of a Arm Cortex M4F DWT counter. Fixed point 32-bit integers is enough for a representation but to handle arithmetic like multiplication, 64-bit integers were needed. Those 64-bit operations resulted in computation time approaching double floating point. If a system used 32-bit floats, the 32-bit fixed point would be ~4x slower. If a system used double floating point in software mode, it will only be ~2x slower than 32-bit fixed point. Fixed point, over all, is more expensive in terms of space and time.</p> <p>If you don't believe the metrics measured here, you can also check fpm performance metrics. Notice how fpm fairs far worse for anything that isn't addition/subtraction.</p> <p>See these articles for more details:</p> <ul> <li>You're Going To Have To   Think!</li> <li>WHY FIXED POINT WON'T CURE YOUR FLOATING POINT   BLUES</li> <li>WHY RATIONALS WON\u2019T CURE YOUR FLOATING POINT   BLUES</li> <li>Why Computer Algebra Won\u2019t Cure Your Floating Point   Blues</li> <li>Why Interval Arithmetic Won\u2019t Cure Your Floating Point   Blues</li> </ul>"},{"location":"contributor_guide/architecture/#a16-libhal-does-not-use-a-units-library","title":"A.16 <code>libhal</code> does NOT use a units library","text":"<p>Unit libraries have the potential to really help prevent an entire category of unit based errors, it is also extremely difficult and annoying to use.</p> <p>Th article Unit of measurement libraries, their popularity and suitability goes into detail about the usability issues faced by unit libraries. Because, at the time of writing <code>libhal</code> there is not a unit library that is easy to use and concise, <code>libhal</code> decided to simply stick with 32-bit floats and helper UDLs.</p>"},{"location":"contributor_guide/architecture/#a17-always-return-halresultt-from-every-api-see-amendment-a22","title":"A.17 ~~Always return <code>hal::result&lt;T&gt;</code> from every API~~ \u27a1\ufe0f (See Amendment A.22)","text":"<p>Every interface in libhal returns a <code>hal::result&lt;T&gt;</code> type.</p> <p>The return types should be a <code>result&lt;T&gt;</code> because the implementation could be an abstraction for anything. As an example, it could come from an I2C to PWM generator and if something goes wrong with the i2c communication, the information must be emitted from the function.</p>"},{"location":"contributor_guide/architecture/#a18-using-inplace_functionhalcallback-for-interrupt-callbacks","title":"A.18 Using <code>inplace_function</code>/<code>hal::callback</code> for interrupt callbacks","text":"<p>There are interfaces such as <code>hal::can</code>, <code>hal::interrupt_pin</code>, and <code>hal::timer</code> that all have APIs for setting a callback.</p> <p>Because those callbacks could be lambdas, function objects, pure functions, or other callable types, we need a polymorphic type erased function type that can take any callable type as input and call it when its <code>operator()</code> is called.</p> <p>The options for these callbacks are:</p> <ul> <li><code>std::function</code><ul> <li>PROS<ul> <li>Part of the standard library</li> <li>Can take any callable type without restrictions</li> </ul> </li> <li>CONS<ul> <li>Allocating (compiler implementations will use SBO but the size of   those buffers are not specified in the standard and should not be   relied upon)</li> <li>Can be quite large in size (40 bytes on 32-bit arm)</li> </ul> </li> </ul> </li> <li><code>function_ref</code><ul> <li>PROS<ul> <li>Very lightweight (very fast construction)</li> <li>Very small size (2 pointers in size)</li> </ul> </li> <li>CONS<ul> <li>For this to work as a callback, the callable passed to the   <code>function_ref</code> must have a lifetime that is greater than the object   implementing the interface.</li> </ul> </li> </ul> </li> <li><code>inplace_function</code><ul> <li>PROS<ul> <li>Works and behaves just like <code>std::function</code></li> </ul> </li> <li>CONS<ul> <li>Fixed callable size limit</li> </ul> </li> </ul> </li> </ul> <p><code>std::function</code> is automatically out because it is allocating. Using <code>std::function</code> for any interface API would ensure that applications that disallow dynamic allocations after boot or in general could never use them.</p> <p><code>function_ref</code> has two great PROS but the largets CON is lifetime issues that are really easy to fall into. Specifically something like this:</p> <pre><code>obj.on_event([&amp;single_capture]() {\n  // does a thing  ...\n});\n</code></pre> <p>The lambda is actually a temporary! So after this call it is out of scope and no longer exists. If the reference to temporary is stored and called later, the code WILL suffer from a \"stack use after scope\" violation which is undefined behavior.</p> <p><code>inplace_function</code> has all of the features of <code>std::function</code> but with limited size. Due to this, constructing an <code>inplace_function</code> is deterministic and relatively light weight.</p>"},{"location":"contributor_guide/architecture/#a19-halcallback-sizing","title":"A.19 <code>hal::callback</code> sizing","text":"<p><code>hal::callback</code> is an alias to <code>inplace_function</code> with a buffer size of 2 pointers (<code>sizeof(std::intptr_t) * 2</code>). This size was chosen in order to be small and easily storable. Two pointers worth of size should be enough to hold a pointer to <code>this</code> in classes as well a pointer to some sort of state object.</p> <p>The size of the callback object was not choosen in order to improve the performance of calling callback setting class functions. Even with the small size of <code>hal::callback</code>, its too large to take advantage of register based parameter passing. Thus the size of 2 pointers was mostly to help in keeping the memory footprint of the <code>callback</code> small. In most cases, setting an callback is something that is either done once or done very infrequently, and thus does not get much of a benefit from higher performance function calls.</p>"},{"location":"contributor_guide/architecture/#a20-why-functions-that-setup-events-do-not-return-halstatus-see-amendment-a22","title":"A.20 ~~Why functions that setup events do not return <code>hal::status</code>~~  \u27a1\ufe0f (See Amendment A.22)","text":"<p>Functions like <code>hal::can::on_receive()</code> and <code>hal::interrupt_pin::on_trigger()</code> return void and not <code>hal::status</code> like other APIs. Thus these functions cannot return an error and are considered \"infallible\". There infallibility guarantee makes constructing drivers using these interfaces easier. It also eliminates the need for drivers to concern themselves with handling errors from these APIs.</p> <p>This guarantee is easily made, because having any one of these APIs fail IS A bug and not something that a developer should or could be responsible with handling. These APIs MUST be implemented as target library peripheral drivers because setting interrupts is something that only target and processor libraries can do. Setting up and configuring interrupts is only possible if the processor supports it. Being apart of a target library means that they know exactly the set of possible configurations that are allowed. This also means that constructing a target peripheral with interrupt customization can be include compile time checks as well.</p>"},{"location":"contributor_guide/architecture/#a21-critical-importance-of-providing-prebuilt-binaries","title":"A.21 Critical importance of providing prebuilt binaries","text":"<p>This amends architectural component A.4 and pivots away from header only libraries over to prebuilt binaries.</p> <p>The following are the reasons why supporting, producing and distibuting prebuilt binaries is critical to libhal.</p> <ul> <li>\u23f1\ufe0f Faster compilation times: When a project grows in size, compiling   a C++ codebase can become time-consuming. By using precompiled binaries,   the compiler has less work to do because portions of the code have already   been compiled. It doesn't need to parse and compile the same headers over and   over again. Developers will refuse to use libhal if it results in extremely   long compilation times. They will tire of the project and seek faster to   compile alternatives.</li> <li>\u2705 Consistency: With precompiled binaries, you can be sure that the same   code will be compiled in the same way, which can reduce inconsistencies   between different environments or build configurations. libhal will not be   taken seriously if libhal didn't use prebuilt binaries and also support   producing them. Distributing consistent code in a consistent form will be a   requirement for many organizations seeking to use libhal.</li> <li>\ud83d\udce6 Code distribution and updates: When distributing C++ code, rather than   give out the full source code or require users to compile it themselves,   providing a precompiled binary is more user-friendly. Updates to the program   can also be handled by replacing the old binaries with the new ones, without   requiring the end-user to handle the compilation process. The philosophy of   conan regarding library packages is that, at their core, C++ libraries are   header files and prebuilt binaries.</li> <li>\ud83d\udd12 Protection of Intellectual Property: Precompiled binaries are much   harder to reverse-engineer than raw source code. If a developer wants to   write an application and distribute the binary, but the C++ code contains   proprietary algorithms or trade secrets that you don't want to expose to the   public, distributing it as a precompiled binary can provide an additional   layer of protection.</li> </ul> <p>In order to provide the best experience for our developers as well as necessary features of the platform, libhal emphasizes prebuilt libraries over header only.</p> <p>Note</p> <p>Why the sudden change from A.4 to this? Supporting header-only made bringing up libhal much easier. The process of implementing prebuilt binaries required adding additional architecture settings, required the use of conan profiles to make the arm-gnu-toolchain available globally for all packages, figuring out how to insert architectural compiler flags and ensure they propogate to all packages took time and was a complex process. And header-only libraries allowed the initial version of libhal to bypass all of this.</p>"},{"location":"contributor_guide/architecture/#a22-use-c-exception-for-error-handling","title":"A.22 Use C++ Exception for Error handling","text":"<p>libhal uses C++ exceptions for these reasons:</p> <ol> <li>Removes runtime cost of calling functions that error codes, result types,    and sentinel variables.</li> <li>Reduces code size greatly by:</li> <li>Amortizing the error handling mechanism to a single set of functions       rather than distributing the workload across all functions that can error.</li> <li>Unwind information is a compressed ISA that only needs 8 bits per       instruction in ARM (32 and 64), where as normal ARM or Thumb-2 which require 16 to 32 bits of information, resulting in code bloat.</li> <li>GCC's Language Specific Data Area (LSDA) is a further compressed data       structure for determining if a frame contains a suitable catch block or cleanup routine.</li> </ol> <p>Issues regarding memory allocations can be overcome by simply overriding/ wrapping <code>__cxa_allocate_exception</code> and using a statically allocated buffer.In the case of multiple threads, each thread can be given its own memory buffer through TLS or a circular pool of blocks with an <code>std::atomic&lt;int&gt;</code> for every thread to use.</p> <p>Exception throw runtime can be reduced by optimizing <code>__cxa_throw</code>'s implementation.</p> <p>The runtime is determinist because the grand majority of our code is statically linked. This means our code is not concerned with shared library locking the exception table down with a mutex to update it. This mutex lock will blocking threads from continuing to unwind, making the time non-determinist. Once you remove that, your unwind time is deterministic.</p> <p>The issue with massive code bloat when you enable <code>-fexceptions</code> only comes from the linux version of <code>std::terminate</code> which uses <code>&lt;iostream&gt;</code> and some other locale related stuff. Simply overriding this with your own implmentation fixes this issue and reduces code size by ~100kB.</p> <p>A link to a paper written by Khalil Estell will be linked here to describe in detail why C++ exception handling is the superior error handling mechanism for embedded systems and software in general when performance and code size are critical concerns.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/","title":"\ud83e\udde0 ARM Cortex-M Series Platform Bringup","text":"<p>To fully bring up an ARM Cortex-M series microcontroller for libhal, several critical elements need to be implemented:</p> <ol> <li>Conan profiles</li> <li>Linker scripts</li> <li>Continuous Integration &amp; Deployment</li> <li>Platform Constants</li> <li>Core APIs</li> </ol> <p>To ensure peripheral drivers operate without conflicts, such as clashing power control implementations, the following APIs must be implemented:</p> <ol> <li>Power control</li> <li>Pin Multiplexing</li> <li>Clock tree</li> <li>Direct Memory Access (DMA)</li> </ol> <p>While not all devices support these features, and many drivers can function without them, implementing them ensures comprehensive peripheral support. For instance, on the LPC40xx series, GPIOs are enabled by default, and simple tasks like blinking an LED don't require knowledge of the system's clock speed or DMA.</p> <p>However, accommodating all features enables support for all potential peripheral drivers.</p> <p>Keep in mind that, as with all libhal tutorials, adaptability is key. Some chips may deviate from standard architectures; in such cases, a fundamental understanding and sound judgment are essential to ensure your system functions effectively.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#getting-started","title":"\ud83d\ude80 Getting Started","text":"<p>libhal provides a template repository for ARM Cortex-M series platforms. Begin by visiting <code>libhal-__platform__</code>, clicking \"Use this template,\" and then \"Create new repository.\"</p> <p>Your project should be named <code>libhal-&lt;insert platform name&gt;</code>. This standard naming triggers the GitHub action update_name.yml to create a pull request that updates names and files within the repo from <code>__platform__</code> to your chosen name. Merge this pull request to proceed to the next phase.</p> <p>Note</p> <p>If there is demand for platform names without the <code>libhal-</code> prefix, we can modify <code>update_name.yml</code> to accommodate this. Currently, we support only prefixed package names.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#conan-profiles","title":"\ud83c\udf10 Conan Profiles","text":"<p>Libhal leverages Conan's robust profile system to specify the architecture and operating system for which an application is built. If you are new to libhal, refer to the \"Getting Started\" guide for details on building applications using compiler and platform profiles.</p> <p>A microcontroller family consists of microcontrollers with nearly identical designs but variations in memory, storage, and peripherals. Since these variations share a common architecture, drivers can typically operate across the family.</p> <p>Creating a Conan profile begins with understanding the device family. This determines the number of profiles needed. For example, the RP2040, which is a single-device family, would have one profile simply named <code>rp2040</code>. However, a chip family with 15 variations would require a distinct profile for each variant.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#components-of-a-typical-profile","title":"Components of a Typical Profile","text":"<p>Below is an example of a Conan profile for the <code>rp2040</code> microcontroller:</p> <pre><code>[settings]\nbuild_type=MinSizeRel\nos=baremetal\narch=cortex-m0plus\nlibc=custom\n\n[options]\n*:platform=rp2040\n</code></pre>"},{"location":"contributor_guide/arm_cortex_m_bringup/#explanation-of-settings","title":"Explanation of Settings","text":"<ul> <li><code>[settings]</code>: This section configures the build environment for your code.</li> <li><code>build_type</code>: Defaults to <code>MinSizeRel</code>, optimizing for the smallest   binary size, which is crucial for embedded applications.</li> <li><code>os</code>: Always set to <code>baremetal</code> for ARM Cortex-M processors, indicating a   direct hardware operation without a traditional operating system.</li> <li><code>arch</code>: Specifies the processor architecture. It is essential to consult   the user manual to identify the correct architecture as variations within the   same family may exist. For instance, the LPC4078 uses a Cortex-M4F (with   floating point unit), unlike the LPC4072, which uses a Cortex-M4 (without   floating point unit). Supported architectures include <code>cortex-m0</code>,   <code>cortex-m0plus</code>, <code>cortex-m1</code>, <code>cortex-m3</code>, <code>cortex-m4</code>, <code>cortex-m4f</code>,   <code>cortex-m7</code>, <code>cortex-m7f</code>, <code>cortex-m7d</code>, <code>cortex-m23</code>, <code>cortex-m33</code>,   <code>cortex-m33f</code>, <code>cortex-m33p</code>, <code>cortex-m35p</code>, <code>cortex-m55</code>, and <code>cortex-m85</code>.</li> <li><code>libc</code>: Should be set to <code>custom</code> to accommodate picolibc, which is   preferable over the default newlib-nano used by the GNU ARM toolchain.</li> </ul>"},{"location":"contributor_guide/arm_cortex_m_bringup/#options-section","title":"Options Section","text":"<ul> <li><code>[options]</code>: This section defines library options for the build process.   It facilitates the selection of specific package options within   <code>conanfile.py</code>.</li> <li><code>*:platform=rp2040</code>: This setting universally applies the <code>rp2040</code>   platform option across all packages, using <code>*</code> as a wildcard to ensure it   affects all compiled packages.</li> </ul>"},{"location":"contributor_guide/arm_cortex_m_bringup/#customizing-your-profile","title":"Customizing Your Profile","text":"<p>To tailor this profile for different platforms, replace <code>rp2040</code> with the relevant platform name and adjust <code>arch</code> to match the specific CPU architecture of your device. This customized approach ensures that the build settings are perfectly aligned with the hardware specifications of the microcontroller you are working with.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#using-profile-templates","title":"Using Profile Templates","text":"<p>Conan has the ability to use Jinja templates in its profiles allowing for the composition and expansion of profiles. So if you have a ton of devices in the same family with nearly identical bits of information, you can make a template for them. Check out the following examples:</p> libhal-lpc40libhal-stm32f1 <p>Notice how the only thing that changes between these are the architecture and the platform.</p> <p><code>libhal-lpc40/conan/v2/lpc40</code>:</p> <pre><code>[settings]\nbuild_type=MinSizeRel\nos=baremetal\narch={{ arch }}\nlibc=custom\n\n[options]\n*:platform={{ platform }}\n</code></pre> <p><code>libhal-lpc40/conan/v2/lpc4078</code>:</p> <pre><code>{% set platform = \"lpc4078\" %}\n{% set arch = \"cortex-m4f\" %}\n{% include \"lpc40\" %}\n</code></pre> <p><code>libhal-lpc40/conan/v2/lpc4072</code>:</p> <pre><code>{% set platform = \"lpc4072\" %}\n{% set arch = \"cortex-m4\" %}\n{% include \"lpc40\" %}\n</code></pre> <p>The only difference between the chips with respect to the settings and options is just the platform name so the template only needs to be used for the platform variable.</p> <p><code>libhal-stm32f1/conan/v2/stm32f103</code>: <pre><code>[settings]\nbuild_type=MinSizeRel\nos=baremetal\narch=cortex-m3\nlibc=custom\n\n[options]\n*:platform={{ platform }}\n</code></pre></p> <p><code>libhal-stm32f1/conan/v2/stm32f103c8</code>: <pre><code>{% set platform = \"stm32f103c8\" %}\n{% include \"stm32f1\" %}\n</code></pre></p> <p><code>libhal-stm32f1/conan/v2/stm32f103vc</code>: <pre><code>{% set platform = \"stm32f103vc\" %}\n{% include \"stm32f1\" %}\n</code></pre></p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#directory-structure","title":"Directory structure","text":"<p>In order to allow changes into the future, it is advised to put your profiles in a <code>v1</code> or <code>vN</code> directory. This way, if there is a significant change between the profiles into the future, code can still use the original profiles they used before.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#linker-scripts","title":"\ud83d\udd17 Linker Scripts","text":"<p>Linker scripts play a crucial role in defining the memory layout of embedded systems. They are used to organize different types of data within the binary, such as code, initialized data, uninitialized data, read-only data, and thread local storage. These scripts also outline the memory regions available for the application.</p> <p>The finer details about linker scripts and how they work can be found in the resources below:</p> <ul> <li>Mastering the GNU linker script by AllThingsEmbeddd: Easy to learn 13 min read</li> <li>\"The most thoroughly commented linker script (probably)\" by Thea \"Stargirl\" Flowers:   A very thoroughly documented and easy read on linker scripts</li> <li>GNU Linker Scripts: Full user specification, if you need or want those details</li> </ul> <p>This section will not go into detail about linker scripts but will provide you all of the steps to port your device to libhal platform library.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#standard-linker-script-template","title":"Standard Linker Script Template","text":"<p>The <code>libhal-armcortex</code> library provides standardized linker script templates, which can be easily adapted for specific platforms. An example template is available at: <code>libhal-armcortex/linker_scripts/libhal-armcortex/standard.ld</code>.</p> <p>To utilize these templates, include the following definitions in your linker scripts directory:</p> <pre><code>__flash = 0x00000000;\n__flash_size = 64K;\n__ram = 0x10000000;\n__ram_size = 16K;\n__stack_size = 1K;\n\nINCLUDE \"libhal-armcortex/standard.ld\"\n</code></pre> <p>The above configuration is an example from the <code>lpc4072</code> script.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#customizing-linker-scripts","title":"Customizing Linker Scripts","text":"<p>You need to specify:</p> <ul> <li>The location and size of the flash memory within the device's address space.</li> <li>The location and size of the main RAM.</li> <li>The minimum stack size before the build should fail, typically set to <code>1K</code>   for libhal. Adjust this based on available RAM.</li> </ul> <p>Each variation within a chip family, such as those in the LPC40xx series, requires its own linker script due to differences in flash and RAM sizes:</p> <p>For example the chips in the LPC40xx series are:</p> <ul> <li>lpc4072</li> <li>lpc4074</li> <li>lpc4076</li> <li>lpc4078</li> <li>lpc4088</li> </ul> <p>Each has their own unique ram and flash amounts.</p> <p>Similarly, the STM32F10x series has distinct linker scripts for each variant based on flash and RAM requirements, such as:</p> <ul> <li>stm32f10xx4.ld</li> <li>stm32f10xx6.ld</li> <li>stm32f10xx8.ld</li> <li>stm32f10xxb.ld</li> <li>stm32f10xxc.ld</li> <li>stm32f10xxd.ld</li> <li>stm32f10xxe.ld</li> <li>stm32f10xxf.ld</li> <li>stm32f10xxg.ld</li> </ul> <p>The STM32F103C8 belongs to the STM32F1 series of microcontrollers, which are part of the STM32 family of devices from STMicroelectronics. The naming scheme for this series can be broken down as follows:</p> <ul> <li>STM32: Indicates the family of ARM Cortex-M microcontrollers.</li> <li>F1: Indicates the series within the STM32 family, specifically the   STM32F1 series.</li> <li>03: Indicates the sub-family, which in this case is the STM32F103   sub-family. The '1' before '03' generally represents the sub-category within   the series.</li> <li>C: Indicates the package type and number of pins (e.g., 'C' typically   indicates an LQFP48 package with 48 pins).</li> <li>8: Indicates the memory size, specifically the Flash memory size, in this   case, 64 KB of Flash memory.</li> </ul> <p>All devices in this family have just 20kB of RAM. Thus the only part of the profile name that matters in terms of determining the appropriate flash size is the last digit. That digits can be <code>4</code>, <code>6</code>, <code>8</code>, <code>b</code>, <code>c</code>, <code>d</code>, <code>e</code>, <code>f</code>, <code>g</code>, which is why we have that many linker scripts above. The exact reason why each number and letter is used is not known to the writer, but is also not important. All that we need to do is map those profile names to the correct <code>.ld</code> file.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#handling-multiple-flash-and-ram-configurations","title":"Handling Multiple Flash and RAM Configurations","text":"<p>Currently, <code>libhal-armcortex</code> supports MCUs with single flash and RAM configurations. For support for multi-flash and multi-RAM devices, consider contributing or following the development on this GitHub issue: Add multi flash &amp; multi ram linker scripts. In order to communicate to the build system what your linker scripts are and where to find them, we must add to the conan package's <code>cpp_info.exelinkflags</code> array. This property describes to conan what link flags should be added if a package depends on this package. See the code below.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#integrating-linker-scripts-into-build-systems","title":"Integrating Linker Scripts into Build Systems","text":"<p>To properly integrate your linker scripts with the Conan build system, add the appropriate link flags to the <code>cpp_info.exelinkflags</code> array in your package. This setup ensures that the linker scripts are correctly recognized and used during the build process.</p> <pre><code>def package_info(self):\n    self.cpp_info.set_property(\"cmake_target_name\", \"libhal::__platform__\")\n    self.cpp_info.libs = [\"libhal-__platform__\"]\n\n    if self.settings.os == \"baremetal\" and self._use_linker_script:\n        self.add_linker_scripts_to_link_flags()\n\ndef add_linker_scripts_to_link_flags(self):\n    platform = str(self.options.platform)\n    self.cpp_info.exelinkflags = [\n        \"-L\" + os.path.join(self.package_folder, \"linker_scripts\"),\n        \"-T\" + os.path.join(\"libhal-__platform__\", platform + \".ld\"),\n    ]\n</code></pre>"},{"location":"contributor_guide/arm_cortex_m_bringup/#implementing-linker-scripts-for-your-platform","title":"Implementing Linker Scripts for Your Platform","text":""},{"location":"contributor_guide/arm_cortex_m_bringup/#1-download-and-review-the-user-manual","title":"1. Download and Review the User Manual","text":"<p>Begin by downloading and reviewing the user manual for your microcontroller. The datasheet may provide some information, but the user manual will typically contain a comprehensive memory map. Search for the section labeled \"memory map\" to find detailed information about the sizes of the device's flash and RAM.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#2-determine-the-naming-scheme","title":"2. Determine the Naming Scheme","text":"<p>Device naming schemes vary. Some, like the <code>lpc4078</code>, have straightforward names, while others, like the <code>stm32f10x</code>, incorporate coded symbols. Establish a clear naming strategy for your linker scripts. Each profile should correspond to exactly one linker script, although a single linker script can apply to multiple profiles if the hardware characteristics are identical.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#3-populate-the-linker-script","title":"3. Populate the Linker Script","text":"<p>Fill out the linker script with the specific memory addresses and sizes for your device:</p> <pre><code>__flash = ???;\n__flash_size = ???;\n__ram = ???;\n__ram_size = ???;\n__stack_size = 1K;\n\nINCLUDE \"libhal-armcortex/standard.ld\"\n</code></pre>"},{"location":"contributor_guide/arm_cortex_m_bringup/#4-repeat-for-all-variants","title":"4. Repeat for All Variants","text":"<p>Continue this process for each device variant within the chip family, ensuring that all have appropriate linker scripts reflecting their specific memory configurations.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#5-update-add_linker_scripts_to_link_flags-in-conanfilepy","title":"5. Update <code>add_linker_scripts_to_link_flags()</code> in <code>conanfile.py</code>","text":"<p>Modify the <code>add_linker_scripts_to_link_flags()</code> function in your <code>conanfile.py</code> to correctly link the appropriate scripts based on the platform:</p> <p>For devices like the STM32 family, where multiple variants exist, implement a dynamic approach to link the correct script:</p> <pre><code>def add_linker_scripts_to_link_flags(self):\n    linker_script_name = list(str(self.options.platform))\n    # Replace unneeded characters with 'x' to denote a generic script\n    linker_script_name[8] = 'x'\n    linker_script_name[9] = 'x'\n    linker_script_name = \"\".join(linker_script_name)\n\n    self.cpp_info.exelinkflags = [\n        \"-L\" + os.path.join(self.package_folder, \"linker_scripts\"),\n        \"-T\" + os.path.join(\"libhal-stm32f1\", linker_script_name + \".ld\"),\n    ]\n</code></pre> <p>This adjustment allows you to use a single script for similar variants by replacing specific parts of the chip identifier with a 'don't care' symbol ('x'). Think of it like bit masking but for letters.</p> <p>For some devices with XIP (eXecute In Place) external flash memory interfaces packages can opt to conan's package \"option\" feature, allowing the user to specify the size in the command line, their own profile, or set the option directly in the final application <code>conanfile.py</code>.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#6-testing","title":"6. Testing","text":"<p>Once all scripts are in place, it's time to test:</p> <p>To build the package, run: <pre><code>conan create . -pr YOUR_PROFILE -pr arm-gcc-12.3 --version=latest\n</code></pre></p> <p>To build your demos, use: <pre><code>VERBOSE=1 conan build demos -pr YOUR_PROFILE -pr arm-gcc-12.3\n</code></pre></p> <p>On Windows: <pre><code>$env:VERBOSE=1 conan build demos -pr YOUR_PROFILE -pr arm-gcc-12.3\n</code></pre></p> <p>Ensure verbose output is enabled to check the <code>-Tyour_linker_script.ld</code> command argument during the build process. Verify the binary fits the addresses specified in the linker script with:</p> <pre><code>arm-none-eabi-readelf -S demos/build/YOUR_PROFILE/MinSizeRel/blinker.elf\n</code></pre> <p>Confirm the <code>.init</code> section aligns with the flash address and <code>.data</code> with the RAM address. If these match, your implementation is successful.</p> <p>Troubleshooting</p> <p>If commands do not execute as expected, particularly on Linux or macOS, source your environment variables with:</p> <pre><code>source demos/build/YOUR_PROFILE/MinSizeRel/generators/conanbuild.sh\n</code></pre>"},{"location":"contributor_guide/arm_cortex_m_bringup/#continuous-integration-deployment","title":"\ud83d\udd04 Continuous Integration &amp; Deployment","text":"<p>Continuous Integration (CI) ensures that code in the main branch of any libhal library\u2014or code intended for the main branch\u2014builds successfully and passes all tests. This process is crucial for maintaining code quality and functionality over time.</p> <p>Warning</p> <p>The CI system is currently optimized for use within the libhal organization. Efforts are underway to enhance its usability for other organizations without requiring a fork or clone of the <code>libhal/ci</code> repository.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#branch-pull-request-checks","title":"Branch &amp; Pull Request Checks","text":"<p>The <code>libhal-__platform__</code> includes a pre-configured <code>ci.yml</code> GitHub Action script, which provides an overview of our automated testing approach:</p> <pre><code>on:\n  workflow_dispatch:\n  pull_request:\n  push:\n    branches:\n      - main\n  schedule:\n    - cron: \"0 12 * * 0\"\n</code></pre> <p>Key Features:</p> <ul> <li>Scheduled Tests: The CI system automatically tests the main branch daily   to ensure ongoing compatibility and to detect any issues caused by changes in   other packages or the infrastructure.</li> <li>Pull Request Tests: All pull requests undergo CI tests to ensure that new   contributions do not introduce bugs or compatibility issues.</li> <li>Manual Trigger: The <code>workflow_dispatch</code> event allows for manual CI runs   without needing to push updates or create pull requests.</li> </ul> <pre><code>jobs:\n  library_checks:\n    uses: libhal/ci/.github/workflows/library_check.yml@5.x.y\n    secrets: inherit\n\n  deploy_cortex-m4f_check:\n    uses: libhal/ci/.github/workflows/deploy.yml@5.x.y\n    with:\n      arch: cortex-m4f\n      os: baremetal\n      compiler: gcc\n      compiler_version: 12.3\n      compiler_package: arm-gnu-toolchain\n    secrets: inherit\n\n  deploy_cortex-m4_check:\n    uses: libhal/ci/.github/workflows/deploy.yml@5.x.y\n    with:\n      arch: cortex-m4\n      os: baremetal\n      compiler: gcc\n      compiler_version: 12.3\n      compiler_package: arm-gnu-toolchain\n    secrets: inherit\n\n  demo_check_profile1:\n    uses: libhal/ci/.github/workflows/demo_builder.yml@5.x.y\n    with:\n      compiler_profile_url: https://github.com/libhal/arm-gnu-toolchain.git\n      compiler_profile: v1/arm-gcc-12.3\n      platform_profile_url: https://github.com/libhal/libhal-__platform__.git\n      platform_profile: v1/profile1\n    secrets: inherit\n\n  demo_check_profile2:\n    uses: libhal/ci/.github/workflows/demo_builder.yml@5.x.y\n    with:\n      compiler_profile_url: https://github.com/libhal/arm-gnu-toolchain.git\n      compiler_profile: v1/arm-gcc-12.3\n      platform_profile_url: https://github.com/libhal/libhal-__platform__.git\n      platform_profile: v1/profile2\n    secrets: inherit\n</code></pre> <p>Key Checks:</p> <ul> <li>Library Checks: Ensures packaging in host mode, conducts host side tests,   verifies API documentation (Doxygen comments), and checks code formatting.</li> <li>Deployment Checks: Uses <code>deploy.yml</code> to simulate the deployment process   for all <code>build_type</code>s such as <code>Debug</code>, <code>MinSizeRel</code>, and <code>Release</code>, without a   specific <code>version</code> input for a dry run.</li> <li>Demo Application Checks: Ensures demo applications remain functional   after changes using <code>demo_builder.yml</code>. This script should specify the paths   to compiler and platform profiles, using these to download and build the   applications.</li> </ul> <p>Each <code>ci.yml</code> configuration should include these checks. If a package does not include demos, the demo check can be omitted, though it is generally recommended to include demos to demonstrate the library's capabilities.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#platform-constants","title":"\ud83d\udcdc Platform Constants","text":"<p>Now we've reached the point where we can start modifying the C++ source code. The first area to start with is defining the <code>peripheral</code> and <code>irq</code> enumeration class constants. These outline the set of peripherals and interrupt requests that can be used on the platform.</p> <p>Here's a guide section for \"Peripheral Constants\" that you can use in your documentation. This section explains how to map peripheral identifiers to their respective power and clock control registers, tailored specifically for an API like the one you're designing for libhal.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#peripheral-constants","title":"Peripheral Constants","text":"<p>In the libhal ecosystem, peripheral constants play a crucial role in the power and clock management APIs. These constants uniquely identify each peripheral and correspond directly to control bits in the power and clock registers. This design ensures efficient and straightforward management of peripheral power states and clock frequencies.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#defining-peripheral-constants","title":"Defining Peripheral Constants","text":"<p>Peripheral constants are defined in an enumeration where each constant corresponds to a specific bit in a device's power or clock enable registers. This method allows direct manipulation of these registers using bit operations, which are both fast and memory-efficient.</p> <pre><code>namespace hal::your_platform {\n  /// List of each peripheral and their power on id number for this platform\n  enum class peripheral : std::uint8_t\n  {\n    // Examples\n    gpio = 0,\n    uart0 = 1,\n    spi1 = 2,\n    // More peripherals follow...\n    max, // Placeholder for the count of peripherals\n  };\n}\n</code></pre>"},{"location":"contributor_guide/arm_cortex_m_bringup/#mapping-to-power-registers","title":"Mapping to Power Registers","text":"<ol> <li> <p>Locate Power Registers: First, consult the power management section of    your microcontroller's user manual. Identify the registers responsible for    powering peripherals. These are often labeled as power control registers or    clock enable registers.</p> </li> <li> <p>Understand Register Layout: Registers typically control multiple    peripherals. Each bit in a register corresponds to the power state of one    peripheral. For instance, bit 0 might control the power for the GPIO    interface, bit 1 for the UART0, and so on.</p> </li> <li> <p>Designing the Enumeration: Define each peripheral in the enum class such    that the value of the enum matches the bit position in the power register.    For a microcontroller with two 32-bit power registers:</p> </li> <li>Peripherals controlled by the first register will have IDs 0 to 31.</li> <li> <p>Peripherals controlled by the second register will have IDs 32 to 63.</p> </li> <li> <p>Bitwise Operations: With each peripheral ID corresponding directly to a    bit position, you can toggle power by applying bitwise operations. For    example, to power on a peripheral, the operation would be:</p> </li> </ol> <pre><code>power_register |= (1 &lt;&lt; static_cast&lt;int&gt;(peripheral::uart0));\n</code></pre> <p>To power it off:</p> <pre><code>power_register &amp;= ~(1 &lt;&lt; static_cast&lt;int&gt;(peripheral::uart0));\n</code></pre>"},{"location":"contributor_guide/arm_cortex_m_bringup/#example-usage","title":"Example Usage","text":"<p>Consider a scenario where the ADC peripheral is mapped to bit 12 in the power control register. By defining the <code>adc</code> constant as 12 in the enum, you enable straightforward manipulation:</p> <ul> <li>Power On: <code>power_register |= (1 &lt;&lt; static_cast&lt;int&gt;(peripheral::adc));</code></li> <li>Check Power State: <code>bool isPowered = power_register &amp; (1 &lt;&lt; static_cast&lt;int&gt;(peripheral::adc));</code></li> <li>Power Off: <code>power_register &amp;= ~(1 &lt;&lt; static_cast&lt;int&gt;(peripheral::adc));</code></li> </ul>"},{"location":"contributor_guide/arm_cortex_m_bringup/#benefits","title":"Benefits","text":"<p>This mapping strategy ensures that your power and clock management API is both efficient and easy to use. It reduces the overhead of calculating bit masks and positions dynamically, leading to faster execution and cleaner code.</p> <p>This guide section aims to clarify the process of defining and using peripheral constants within the libhal framework, providing a structured approach to managing device resources effectively.</p> <p>Note</p> <p>Your microcontroller may use multiple bits or have a more complicated scheme to power control. If that is the case, then it is up to you to determine what is the best scheme for powering on peripheral on the device that driver and potentially users can utilize.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#irq-constants","title":"IRQ Constants","text":"<p>It may be useful to understand how ARM Cortex M exceptions work. To learn these details, we'd highly recommend reading A Practical guide to ARM Cortex-M Exception Handling by Chris Coleman of Memfault.</p> <p>The maximum number of interrupts for Cortex-M series CPUs varies depending on the specific model within the Cortex-M family. Here is a breakdown of the maximum interrupt numbers for different Cortex-M series processors:</p> <ol> <li>Cortex-M0/M0+: Supports up to 32 external interrupts.</li> <li>Cortex-M3/M4/M7/M33/M35P: Supports up to 240 external interrupts.</li> <li>Cortex-M23: Supports up to 32 external interrupts.</li> </ol> <p>The exact number of interrupts available in a specific microcontroller will also depend on the chip and the specific features they have included. Consult the technical reference manual or datasheet for the mcu to get the precise number of interrupts supported and what they map to.</p> <pre><code>// The enum class type must always be `std::int16_t`, representing the\n// maximum number of IRQs a Cortex-M processor can support. This type is also\n// used for the input parameter that specifies the IRQ number.\nenum class irq : std::int16_t\n{\n  watchdog_timer = 0, // The first IRQ must always be zero\n  timer0 = 1,\n  timer1 = 2,\n  uart0 = 5,\n  uart1 = 6,\n  pwm1 = 9,\n  i2c0 = 10,\n  i2c1 = 11,\n  i2c2 = 12,\n  reserved0 = 13, // Fill gaps with reserved IRQs\n  spi0 = 14,\n  spi1 = 15,\n  pll0 = 16,\n  rtc = 17,\n  // ... Add the rest...\n  max, // The final entry must ALWAYS be \"max\"\n};\n</code></pre> <p>When referencing your user manual, look for the term NVIC, which stands for Nested Vector Interrupt Controller. This is a typical title in ARM MCU data sheets for where the interrupts IRQs are defined. The NVIC section in the manual typically includes IRQ numbers for each peripheral. Integrate these numbers into the enum class, assigning them as corresponding values. Additionally, you may encounter ISER, or Interrupt Set-Enable Register, which is the ARM designation for the register controlling interrupt enabling.</p>"},{"location":"contributor_guide/arm_cortex_m_bringup/#implementing-the-core-apis","title":"\ud83e\udde9 Implementing the core APIs","text":"<p>To be written.</p>"},{"location":"contributor_guide/board_library/","title":"Board Library Guide","text":"<p>A board library</p>"},{"location":"contributor_guide/dma_tutorial/","title":"\u23e9 DMA: Direct Memory Access Development Guide","text":"<p>DMA is a key feature in many microcontrollers. DMA allows data to be transferred from one location to another without the need for the CPU to perform the copy. This can be used to transfer large amounts of data from one place in memory to another place. It can also be used to automatically transfer data to a peripheral.</p> <p>As an example, lets consider an peripheral implementation of <code>hal::spi</code>. In order to write an spi driver without DMA, the CPU has to load a register used by the peripheral with data, then wait for the data to be shifted out of the device, before another byte can be put in. This means that the CPU has to baby sit the spi peripheral for each and every byte that is transferred. Whereas with DMA all that is needed is to tell the controller:</p> <ol> <li>The address of source data</li> <li>The address of the destination data</li> <li>The length of the transfer</li> <li>The word width of the source &amp; destination (8-bit, 16-bit, 32-bit)</li> <li>[optional] The endianness of the transfer</li> <li>And whether or not to increment the source and/or the destination address</li> </ol> <p>After that, just fire it off and it will do the work of loading the data register for you until it finishes. On completion, an interrupt will be invoked that indicates to the application that the transfer has completed.</p> <p>And that about it for simplicity. There are typically other configurations such as:</p> <ol> <li>Stride/stride-length: how many words lengths to skip in the input or output sequence. For example, if you had two dacs and PCM16 with L/R data alternating in the array like so, <code>u16l0, u16r0, u16l1, u16_r1, ..., u16_ln, u16_rn</code>, then the left side dac could start at address 0 with a stride length of 2 to skip the right side data. The same logic can be used to setup the right dac.</li> <li>Circular mode: DMA channels acts like a ring buffer allowing it to jump back to the start of the buffer when it reaches the end. This is very useful for <code>hal::serial</code> implementations.</li> <li>Burst size: allows a DMA controller to keep control over the bus for multiple cycles in order to ensure that data is sent without any break time.</li> </ol>"},{"location":"contributor_guide/dma_tutorial/#channels","title":"Channels","text":"<p>DMA controllers generally have a fixed set of DMA channels. These channels can operate independently, and allows for multiple transfer to occur at the \"same\" time.</p> <p>Channels can be used for a period of time or can be occupied for the lifetime of a driver. In general, DMA channels shouldn't be help for the lifetime of the driver as that would limit the number of available DMA channels that can be used by other drivers. An explicit exception to this is <code>hal::serial</code> which requires that its implementation is backed by a buffer. It is common to see uart implementations where there is only a single byte register for the uart data that is overwritten when the next byte is received. In order to not lose bytes, either an interrupt service routine is needed or DMA can be used fill up a buffer of bytes. Interrupts, although fast, still require cpu attention where as DMA handle this work for the cpu.</p> <p>The number of channels is limited and thus it is possible for there to be more drivers that require a DMA channel than DMA channels available. In these cases, the function for setting up DMA MUST busy wait until a DMA channel is made available before returning. In general, when designing an application, it is important to be mindful of the number of DMA channels a device has and how many drivers need channels. If the number of device drivers that use 1 or more DMA channels is greater than the number of channels, then the application developer must be mindful of this and design around this constraint.</p>"},{"location":"contributor_guide/dma_tutorial/#ram-blocks","title":"Ram blocks","text":"<p>When the cpu access memory from ram, it will use the device's address and data bus to make the transfer occur. DMA is no different. If DMA attempts to access the same resource as the cpu, then either the cpu or the DMA controller will stall until the other device is finished.</p> <p>A lot of devices will separate their memory into multiple ram blocks. The reason, with respect to DMA, is that having multiple ram blocks allow DMA to access one block of ram while the cpu works with ram in another ram block. If an application can design itself around this, it will help with the performance of the cpu and DMA when performing any sort of work.</p> <p>For example, lets say you want to make an MP3 player project. Gaps in audio can cause audio distortions and artifacts like clicks and pops. Gaps can be prevented by always ensuring that audio is making its way to the DAC. To ensure that there is always audio available to be streamed through the DAC a double buffering approach is used, where one buffer is actively being streamed out to the DAC and the other buffer is being filled with the new audio data. A dedicated thread is provided for audio decoding and audio streaming. The audio stream thread takes a buffer of audio data, sets up DMA for the transfer and then blocks its own thread. The audio decoder can now fill the other buffer with decoded mp3 data. Now consider this, lets assume that the buffers are both on the same RAM chip. In this case, whenever the DMA and cpu attempt to access the ram block, one of them will be stalled waiting for the other to finish. This can reduce performance and potentially result in audio artifacts. If these buffers are located in different ram blocks, then the DMA can access the ram block without stalling the CPU and vise-versa.</p> <p>Note that this also depends on if your system is a \"Single Bus System\" or a \"Multi Bus System\".</p> <ul> <li>Single Bus System: If there is only one data and address bus shared by all components, then even with multiple RAM blocks, access to these blocks is serialized through the single bus. In this case, the DMA and CPU cannot truly operate in parallel when accessing different blocks, as the single bus must arbitrate between them. This can still lead to stalls, though the overall impact might be reduced if the arbiter is efficient.</li> <li>Multiple Bus System: Some more complex systems might employ multiple buses (e.g., a separate bus for DMA and CPU). This architecture can allow truly concurrent access to different RAM blocks, significantly reducing or eliminating stalls because each master has its own path to memory.</li> </ul>"},{"location":"contributor_guide/dma_tutorial/#implementing-halplatformsetup_dma_transferdma","title":"Implementing <code>hal::&lt;platform&gt;::setup_dma_transfer(dma)</code>","text":"<p>All parts of this section require the user manual for your particular device.</p>"},{"location":"contributor_guide/dma_tutorial/#implementing-the-dma-structure","title":"Implementing the <code>dma</code> structure","text":"<p>The <code>dma</code> structure should include fields for every possible configuration that the dma.</p> <p>Warning</p> <p>Channel selection should not be a field in the dam structure. The channel selected should be determined by the <code>setup_dma_transfer</code> call based on which channels are available. Some dma devices provide a priority for each channel. The current philosophy is to ignore this priority system and simply provide the first channel that is available and if possible make the priority of all channels the same.</p> <p>Here is an example dma structure from <code>libhal-lpc40</code>:</p> <pre><code>enum class dma_transfer_type : std::uint8_t\n{\n  /// Flow Control: DMA controller\n  memory_to_memory = 0b000,\n  /// Flow Control: DMA controller\n  memory_to_peripheral = 0b001,\n  /// Flow Control: DMA controller\n  peripheral_to_memory = 0b010,\n  /// Flow Control: DMA controller\n  peripheral_to_peripheral = 0b011,\n  /// Flow Control: Destination Peripheral\n  peripheral_to_peripheral_dp = 0b100,\n  /// Flow Control: Destination Peripheral\n  memory_to_peripheral_dp = 0b101,\n  /// Flow Control: Source Peripheral\n  peripheral_to_memory_sp = 0b110,\n  /// Flow Control: Source Peripheral\n  peripheral_to_peripheral_sp = 0b111\n};\n\nenum class dma_transfer_width : std::uint8_t\n{\n  bit_8 = 0b000,\n  bit_16 = 0b001,\n  bit_32 = 0b010,\n};\n\nstruct dma\n{\n  void const volatile* source;\n  void volatile* destination;\n  std::size_t length;\n  // With every transfer, increment the address of the source location. Set to\n  // true to move forward through the length of the transaction. Set to false\n  // to keep the address the same for the entire length of the transfer. Set\n  // false is usually used when the address is a peripheral driver and the\n  // register you are reading from updates. Set to true when you want to\n  // transfer a sequence of data, an array, from ram to a peripheral or another\n  // area of memory.\n  bool source_increment;\n  // Same as source_increment but with the destination address.\n  bool destination_increment;\n  dma_transfer_width source_transfer_width;\n  dma_transfer_width destination_transfer_width;\n  dma_transfer_type transfer_type;\n};\n</code></pre> <p>Removed from the example above are the source and destination request number fields which are specific to the <code>lpc40</code> series. The burst count is also not present as well. If you're devices has such fields and are required to work, then add them to your data structure. Reading the above code should give you an idea of what a user must do in order to establish a dma transfer.</p> <p>Note the technique of using a strongly typed enumeration classes as binary control patterns. When making enumeration classes for each of your configuration parameters, it is wise to give the unique constants defined in the datasheet as the constants defined in the enum class. This way, the code for <code>setup_dma_transfer()</code> does not have to perform a translation from the value of the enum class to a value that the dma hardware can understand.</p> <p>When implementing the structure do the following:</p> <ol> <li>Open datasheet and search for the \"DMA\" section. Generally there will be a short synopsis about the device and what it supports.</li> <li>Read/skim the section on DMA. Locate the registers for controlling DMA and note what configurations it supports.</li> <li>Copy the dma structure above.</li> <li>Update the <code>dma_transfer_type</code> enum class fields with the set of values that match your device. If the enum class value codes cannot fit in std::uint8_t then the smallest size unsigned number that can fit your codes. If your device does not require or use such a construct, then simply delete the <code>dma_transfer_type</code> and <code>dma_transfer_type</code> field from the <code>dma</code> structure.</li> <li>Update <code>dma_transfer_width</code> enum class with the binary codes for your device's DMA transfer width.</li> <li>Add any other fields that are available for your dma besides channel selection.</li> </ol>"},{"location":"contributor_guide/dma_tutorial/#implementing-the-setup_dma_transfer-function","title":"Implementing the <code>setup_dma_transfer</code> function","text":"<p>The dma code should look like the following. Read the comments to get an idea of what is necessary to make this work.</p> <pre><code>constexpr std::size_t dma_channel_count = 8;\n\n// We need to provide memory to hold the callbacks for each dma channel. When\n// the dma transfer is finished, an interrupt will be invoked. That interrupt\n// handler will invoke the dma callback in this list.\nstd::array&lt;hal::callback&lt;void(void)&gt;, dma_channel_count&gt; dma_callbacks{\n  hal::cortex_m::default_interrupt_handler,\n  hal::cortex_m::default_interrupt_handler,\n  hal::cortex_m::default_interrupt_handler,\n  hal::cortex_m::default_interrupt_handler,\n  hal::cortex_m::default_interrupt_handler,\n  hal::cortex_m::default_interrupt_handler,\n  hal::cortex_m::default_interrupt_handler,\n  hal::cortex_m::default_interrupt_handler,\n};\n\nvoid handle_dma_interrupt() noexcept;\nvoid initialize_dma();\n\n// Atomic flag for acquiring the dma\nstd::atomic_flag dma_busy = ATOMIC_FLAG_INIT;\n\nvoid setup_dma_transfer(dma const&amp; p_configuration,\n                        hal::callback&lt;void(void)&gt; p_interrupt_callback)\n{\n  // Step 1.\n  //\n  // Compose the configuration, control, and whatever other registers you need\n  // to setup the dma.\n  auto const config_value = /* ... */;\n  auto const control_value = /* ... */;\n\n  // Step 2.\n  //\n  // Acquire atomic lock using spin lock\n  while (dma_busy.test_and_set(std::memory_order_acquire)) {\n    continue;  // spin lock\n  }\n\n  // Step 3.\n  //\n  // Initialize dma (this should be a one shot and should return early if the\n  // dma has already been initialized).\n  // Ensure that this call does not throw an exception, if so, use\n  initialize_dma();\n\n  // Step 4.\n  //\n  // Busy wait until a channel is available\n  while (true) {\n    // Step 5.\n    //\n    // Check for an available channel.\n    auto const available_channel = /* ... get available channel ... */\n\n    // Lets assume that if the channel number is above 8 then all channels are\n    // available.\n    if (available_channel &lt; 8) {\n      // Step 6.\n      //\n      // Copy callback to the callback array\n      dma_callbacks[available_channel] = p_interrupt_callback;\n\n      // Step 7.\n      //\n      // Get &amp; setup dma channel\n      auto* dma_channel = get_dma_channel_register(available_channel);\n\n      dma_channel-&gt;source_address =\n        reinterpret_cast&lt;std::uintptr_t&gt;(p_configuration.source);\n      dma_channel-&gt;destination_address =\n        reinterpret_cast&lt;std::uintptr_t&gt;(p_configuration.destination);\n      dma_channel-&gt;control = control_value;\n\n      // Step 8.\n      //\n      // Start dma transfer\n      dma_channel-&gt;config = config_value;\n      break;\n    }\n  }\n\n  // Step 9. Release lock\n  dma_busy.clear();\n}\n\n\nvoid initialize_dma()\n{\n  // You can use the fact that the dma is powered on to determine if the device\n  // has already been initialized.\n  if (is_on(peripheral::gpdma)) {\n    return;\n  }\n\n  // Otherwise power it on\n  power_on(peripheral::gpdma);\n\n  // Turn on interrupts\n  initialize_interrupts();\n\n  // enable the dma interrupt\n  hal::cortex_m::enable_interrupt(irq::dma, handle_dma_interrupt);\n\n  // Replace this code with what enables the dma\n  dma_reg-&gt;config = 1;\n}\n\nvoid handle_dma_interrupt() noexcept\n{\n  // The zero count from the LSB tells you where the least significant 1 is\n  // located. This allows the handled DMA interrupt callback to start at 0 and\n  // end at the last bit.\n  auto const status = std::countr_zero(dma_reg-&gt;interrupt_status);\n  auto const clear_mask = 1 &lt;&lt; status;\n\n  // NOTE: This may not be necessary on your device\n  dma_reg-&gt;interrupt_terminal_count_clear = clear_mask;\n  dma_reg-&gt;interrupt_error_clear = clear_mask;\n\n  // Call this channel's callback\n  dma_callbacks[status]();\n}\n</code></pre> <p>Take the above code and update the code to fit the needs of your device.</p>"},{"location":"contributor_guide/interface_design/","title":"\ud83d\udd17 Interface Design Philosophy","text":"<p>Interfaces are the foundation and building blocks of libhal. They are the \"A\" and \"L\" in HAL: hardware abstraction layer. They present a generalized ideal of a particular aspect of hardware or computing. For example and output pin represents a pin that can have its output voltage level state changed from a logical true or false value, which may be represented as a LOW voltage or HIGH voltage depending on the device.</p> <p>The following guidelines describe what should be kept in mind when creating an interface.</p> <p>Here is an example of some interfaces in libhal. It is recommended to take a look at these to get an idea of how the interfaces are written.</p> <ul> <li>hal::adc</li> <li>hal::serial</li> <li>hal::i2c</li> <li>hal::spi</li> <li>hal::can</li> <li>hal::dac</li> <li>hal::stream_dac</li> </ul>"},{"location":"contributor_guide/interface_design/#smallest-possible-v-table","title":"Smallest Possible v-table","text":"<p>When designing an interface aim to have the least number of virtual functions as possible.</p> <p>Why?</p> <p>Each virtual function in the interface will require a v-table entry (a pointer) in the v-table of each implementation of an interface. Each entry takes up space in the <code>.text</code> or <code>.rodata</code> sections of the binary. The more you have the more space is taken up.</p> <p>Consider:</p> <p>Combining APIs if it is possible. For example, lets consider <code>hal::output_pin</code> and <code>hal::i2c</code>.</p> <p><code>hal::output_pin</code> could have had a <code>::high()</code> and <code>::low()</code> API for setting the pins state. But these could easily be combined into a single API such as <code>::level(bool)</code> which accepts the state as an input parameter.</p> <p><code>hal::i2c</code> could have had <code>::write(...)</code>, <code>::read(...)</code>, and <code>::write_then_read(...)</code>. Instead, we have <code>transaction()</code> which can determine which of the 3 communication methods to use depending on whether or not the write and read buffers are supplied. If only one is available, then it will perform the respective <code>write</code> or <code>read</code> operation.</p>"},{"location":"contributor_guide/interface_design/#make-virtual-functions-pure-virtual","title":"Make virtual functions pure virtual","text":"<p>Interface API implementations are the responsibility of the implementer to be implemented.</p> <p>Why?</p> <p>In almost all cases, default behavior does not make sense.</p> <p>Consider:</p> <p>The exception to this rule is when a new virtual API is added to the end of the virtual API list. In order to be backwards compatible, the new API MUST be implemented with default behavior. Adding a new virtual API is a last resort and adding a new interface or an additional public class function should be preferred if it can solve the issue.</p>"},{"location":"contributor_guide/interface_design/#eliminate-viral-behavior","title":"Eliminate viral behavior","text":"<p>Another way to say this is, \"consider the overhead by the developer.\" This can be space &amp; time overhead in the program or simply the overhead required by the developer in order to use your API correctly.</p> <p>Why?</p> <p>Consider the following example of viral behavior through narrow contracts.</p> <p>Consider this line of code <code>dac.write(value)</code>. The input to the <code>write</code> function only accepts values from <code>0.0f</code> to <code>1.0f</code>. If value is greater or smaller than this then it is undefined behavior. The developer, to eliminate this undefined behavior they must do the following: <code>dac.write(std::clamp(value, 0.0f, 1.0f))</code>. This works. The concern here is that now all code that calls this function MUST add this clamp to ensure that the behavior is well defined OR have some other mechanism in place to ensure that value does no exceed the narrow contract of the <code>write</code> function. This becomes a vector for bugs and issues in the code. This viral behavior also leads to duplication of the same clamp code throughout the application developer's code as well as the interface implementation code. A well designed implementation would either check that the input is within the bounds allowed and potentially emit an error or clamp the value for the user. Now the clamp code is performed at the call site as well as the implementation. This is a waste of cycles and space.</p> <p>Consider:</p> <p>Consider what the caller of API will have to do in order to use your API correctly as well as the implementor of the API. In the example above, the solution to this viral behavior is to make the narrow contract into a wide contract where the public API clamps the input for the user, making all input (besides <code>NaN</code>), valid input. That way, the caller can be assured that their input will be clamped and the implementor can be assured that the value they get will ALWAYS be the expected values.</p> <p>Viral behavior can come in different forms that narrow and wide contracts, so great consideration must be taken when writing an API to eliminate such viral behavior.</p>"},{"location":"contributor_guide/interface_design/#private-virtual-functions","title":"Private virtual functions","text":"<p>Make virtual functions private. Make them callable via a public interface. Like so:</p> <pre><code>class my_interface {\npublic:\n  void foo() {\n    driver_foo();\n  }\n  bool bar() {\n    return driver_bar();\n  }\nprivate:\n  virtual void driver_foo() = 0;\n  virtual bool driver_bar() = 0;\n};\n</code></pre> <p>Why?</p> <p>If, in the event we need to modify the calling convention of a virtual API, we can do so by altering the public API.</p> <p>Consider:</p> <p><code>hal::motor</code> and <code>hal::dac</code> originally had narrow contracts which were widened to remove eliminate viral behavior. Previously <code>hal::motor</code> could only accept values from <code>-1.0f</code> to <code>+1.0f</code>. Anything beyond that would result in undefined behavior. This resulting in two large issues, viral behavior and undefined behavior. The first causes code bloat in terms of code size, and visual noise to the reader due to the code needed to clamp the input to motor's <code>power()</code> API. The second will cause potentially severe and hard to find bugs in the code which is unacceptable. To resolve this issue, the public API was updated to clamp the input from the caller before passing the info to the virtual API. This eliminates the need for the calling code to bounds check the value as well as eliminates the need for the virtual function implementation to bounds check the input value. This allows for backwards compatible updates to how a virtual API is called.</p> <pre><code>class motor\n{\npublic:\n  void power(float p_power)\n  {\n    auto clamped_power = std::clamp(p_power, -1.0f, +1.0f);\n    return driver_power(clamped_power);\n  }\n\nprivate:\n  virtual void driver_power(float p_power) = 0;\n};\n</code></pre> <p>Note</p> <p>This change is backwards API compatible and ABI compatible but may not be link time compatible, since there may be two definitions of the same class function between statically linked binaries.</p>"},{"location":"contributor_guide/interface_design/#consider-the-stack-ram-and-rom-requirements-of-an-api","title":"Consider the stack, ram and rom requirements of an API","text":"<p>Some API designs have the unwanted side effect of causing the user to provide or allocate a large buffer in order to operate. For example:</p> <pre><code>class big_buffer {\npublic:\n  struct big_struct {\n    std::array&lt;hal::byte, 10_kB&gt; buffer{};\n  };\nprivate:\n  virtual void driver_update(const big_struct&amp; p_buffer) = 0;\n};\n</code></pre> <p>Why?</p> <p>This can make interfaces and APIs hard to use in resource constrained systems. In the example above, in order to call the <code>driver_update</code> function, you need to pass it a buffer that takes up 10kB of ram. If this is allocated on the stack, it could easily overrun a thread's stack. If a device doesn't even have 10kB of ram then this API can never be called on the system. An example of this would be a display driver where an entire frame buffer is required in order to update the display.</p> <p>Consider:</p> <p>Consider if the input value needs to be so large? Can it be broken up into pieces? Can it implemented in another way that doesn't require a large amount of memory?</p>"},{"location":"contributor_guide/interface_design/#should-contain-no-member","title":"Should contain no member","text":"<p>Interfaces should only have public member functions and private virtual member functions. Nothing more.</p> <p>Why?</p> <p>The primary purpose of an interface is to define an abstract layer of communication between different parts of a program. Interfaces should ideally be agnostic of how their contracts are fulfilled. Including member fields implies a certain level of implementation detail that detracts from the abstraction.</p> <p>Adding fields to an interface can lead to tighter coupling between the interface and its implementations. This can complicate the design and increase the difficulty of changes in the future. Implementations are forced to manage state in a specific way, which can reduce flexibility in how they manage their internal states and behaviors.</p> <p>Consider:</p> <p>That you do not actually need to add a data member to the interface.</p>"},{"location":"contributor_guide/interface_design/#must-not-be-a-template","title":"Must not be a template","text":"<p>A templated interface is a class template that is also an interface like so:</p> <pre><code>template&lt;class PacketSize&gt;\nclass my_interface {\nprivate:\n  virtual void write(std::span&lt;const PacketSize&gt; p_payload) = 0;\n};\n</code></pre> <p>Why?</p> <p>The above example may seem like a great way to broaden an interface to an unlimited scale, but that is actually a problem. (insert reasons here).</p> <p>Template interfaces widen the scope and number of interfaces available in libhal in an unbounded way. This can result in additional v-tables for each interface implementation.</p> <p>Interface instances with different template types will not compatible with each other. Meaning an adaptor of sources would be needed to convert one to another.</p> <p>Consider:</p> <p>That this is not necessary. Consider that there exists a generic and specific implementation of an interface. Consider making two interfaces if a single interface would not suffice.</p>"},{"location":"contributor_guide/interface_design/#prefer-wide-api-contracts","title":"Prefer wide API contracts","text":"<p>A wide contract for an API means that an API can take any type of input for all of the input parameters sent to the API. Meaning that the API is well defined for all possible inputs that could be passed. That does not mean that the implementation of an API will accept all possible inputs. The API could throw an error if the input is beyond what it is capable of working with. But simply means that the API is well defined for the whole range of the inputs.</p> <p>Why?</p> <p>It helps eliminate viral behavior and tends to eliminate undefined behavior.</p> <p>Consider:</p> <p>The cost of an API having a wide contract? Would this result in viral behavior or eliminate it? Would it result in worse performance? Would it result in increased ram or increased rom utilization? Would it potentially save in all of these. If possible try and guarantee a wide contract if possible and only consider a narrow contract as a last resort. Explain in detail why a narrow contract was chosen, as those are vectors for bugs and undefined behavior.</p>"},{"location":"contributor_guide/interface_design/#do-not-break-abi","title":"Do NOT break ABI","text":"<p>ABI stands for Application Binary Interface. A breakage to an ABI is not easy for C++ or other languages to determine. A ABI break can come in many forms but it usually comes as a change between a version of code compiled previously and a version of code compiled now. Such a break can result in memory corruption, invalid input to a function and overall undefined behavior.</p> <p>Why?</p> <p>Don't do it! Its bad. But in all honesty, all hell breaks loose if we allow ABI breaks. If we MUST break ABI we MUST update the major version number of the library.</p> <p>Consider:</p> <p>With regards to interfaces, given the other rules, there is really only the following possible ABI breaking changes that can occur:</p> <ol> <li>Changing the return value of a virtual function</li> <li>Changing function calling convention.</li> <li>Reordering of virtual API within an interface.</li> <li>Reordering of members within a returned <code>struct</code> or <code>class</code>.</li> </ol> <p>These are not allowed due to how they affect how programs generate assembly for each function call. What we are allowed to do is the following:</p> <ol> <li>Add additional non-virtual public functions.</li> <li>Add additional overloads for public functions (we should <code>[[deprecate]]</code> old    APIs we know to be harmful).</li> <li>Add additional non-pure virtual APIs below the current set of virtual APIs    (should avoid this).</li> <li>Add additional fields to a settings <code>struct</code> that is passed by reference.</li> </ol>"},{"location":"contributor_guide/interface_design/#interface-independence-principle","title":"Interface Independence Principle","text":"<p>Interfaces should not be designed to have a relationship with each other outside of an IS-A or inheritance relationship. An allowable relationship is one where an interface inherits from another, such as <code>hal::advanced_can</code> inheriting from <code>hal::can</code> because it has all the same requirements and some additional ones.</p> <p>An example of a relationship that is not acceptable would be if there existed a <code>wifi</code> interface and a network <code>socket</code> interface. Technically, there is a relationship between these two interfaces. One could even consider that the wifi interface could be a \"producer\" or \"provider\" of sockets once a wifi connection is established. An API from the <code>wifi</code> interface could be added that returns a reference to an available <code>socket</code>. This couples <code>socket</code> to <code>wifi</code> and complicates the implementation of wifi, ensuring that sockets can be returned. The memory and lifetime of that socket then becomes a concern of <code>wifi</code> as well as any of its users. Overall, this results in more complex code and more coupling than necessary. A better option is to keep everything independent from each other.</p> <p>To follow this rule, refrain from:</p> <ol> <li>Returning an interface from a function in any way</li> <li>Taking another interface as an input parameter</li> </ol> <p>Instead, if there needs to be some sort of relationship between interfaces, then this type of relationship should be managed by concrete classes that can take dependent objects with a relationship and manage that relationship.</p>"},{"location":"contributor_guide/library_guides/","title":"\ud83d\udd39 Library Development Guide","text":"<p>Info</p> <p>Documentation coming soon...</p>"},{"location":"contributor_guide/organization/","title":"\ud83d\uddc3\ufe0f Organization","text":"<p>This section will explain the different parts/repos of libhal organization and ecosystem and how they are organized.</p>"},{"location":"contributor_guide/organization/#target-libraries","title":"Target Libraries","text":"<p>Target libraries depend on processor/OS libraries. The target libraries will include drivers for peripherals contained within their chip packages or, in the case of development boards and SBC (single board computers), these can also contain drivers external to the main chip. Processor/OS libraries contain APIs specific to those platforms for doing such things as handling interrupt service routines, initializing memory and more.</p> <pre><code>flowchart LR\n    libhal\n    subgraph processor/OS\n      libriscvmcu\n      libarmcortex\n      libhal-linux\n    end\n    subgraph arm-targets\n      liblpc40xx\n      libstm32f10x\n    end\n    subgraph riscv-targets\n      libgv32f10x\n      libsifive\n    end\n    subgraph linux-targets\n      libhal-linux-generic\n      libraspi\n    end\n\n    libhal--&gt;libhal-linux\n    libhal--&gt;libriscvmcu\n    libhal--&gt;libarmcortex\n\n    libarmcortex--&gt;liblpc40xx\n    libarmcortex--&gt;libstm32f10x\n\n    libriscvmcu--&gt;libgv32f10x\n    libriscvmcu--&gt;libsifive\n\n    libhal-linux--&gt;libhal-linux-generic\n    libhal-linux--&gt;libraspi</code></pre>"},{"location":"contributor_guide/organization/#device-libraries","title":"Device Libraries","text":"<p>Device driver libraries have a very simple relationship tree. Device libraries just need the libhal interfaces to work. The implementations of those interfaces will come from a target library in the application.</p> <pre><code>flowchart TD\n    libhal\n    libhal--&gt;libhal-soft\n    libhal--&gt;libmpu\n    libhal--&gt;libesp8266\n    libhal--&gt;libdrv\n    libhal--&gt;libwii\n    libhal--&gt;liballegro-micro\n    libhal--&gt;libdisplay-ssd\n    libhal--&gt;libled-apa-sk\n    libhal--&gt;libmatrix</code></pre>"},{"location":"contributor_guide/organization/#typical-application","title":"Typical Application","text":"<p>Lets consider an application such as \"Pong\". A game of pong where we use an LED matrix and two Wii controllers using the STM32F103 microcontroller.</p> <pre><code>flowchart LR\n    libhal--&gt;libmatrix--&gt;app\n    libhal--&gt;libarmcortex--&gt;libstm32f10x --&gt;app\n    libhal--&gt;libwii--&gt;app</code></pre> <p>The <code>conanfile.txt</code> would look something like this:</p> <pre><code>[requires]\nlibstm32f10x/1.1.0\nlibmatrix/1.0.2\nlibwii/1.5.2\n\n[generators]\nCMakeToolchain\nCMakeDeps\nVirtualRunEnv\n</code></pre>"},{"location":"contributor_guide/organization/#application-libraries","title":"Application Libraries","text":"<p>Application libraries are effectively applications with no specific dependency on a particular target. The point of a Application library is to deploy a fully fledged application, but with customizable drivers. For example, the pong game mentioned earlier doesn't require a wii controller or a LED matrix specifically. You could take a <code>hal::display</code> interface (not currently available) and some <code>pong::gamepad</code> interface defined by the Application library that the developer can implement themselves. Then the pong Application can take your display, gamepad and additional information like, \"paddle size\" and \"font size\" and use it to generate a game of pong. The developer gets the opportunity to choose which parts they want for each. Maybe they want a very large TFT display or they want to use a LED matrix. Maybe they want to use a Stadia controller or maybe they want to make a controller out of capacitive sensors and bananas. The choices are endless.</p>"},{"location":"contributor_guide/organization/#finding-drivers","title":"\ud83d\udd0d Finding Drivers","text":"<p>To find drivers you can look in three locations</p> <ul> <li>libhal organization</li> <li>conan center index</li> <li>libhal driver index \u274c</li> </ul> <p>Example</p> <p>libhal driver index is not available currently and is key to finding drivers around the ecosystem.</p> <p>Search for the name of the device or target you are interested with with the prefix <code>lib</code> in front of it. Try not to be too specific though. For example, the <code>stm32f103c8t6</code> microcontroller target library drivers will be in the package <code>libstm32f10x</code>. The <code>mpu6050</code> accelerometer will be in <code>libmpu</code>.</p>"},{"location":"contributor_guide/organization/#reference-material","title":"\ud83d\udcd1 Reference Material","text":"<p>Reference material can be found in the <code>datasheets/</code> and <code>schematic/</code> folders. The layout of these directories match that <code>demos/</code>, where the first layer of folders are named after the microcontroller or board they describe.</p> <p>These folders are updated with relevant documents for easy access for our developers and contributors.</p>"},{"location":"contributor_guide/philosophy/","title":"\ud83d\udcdc Design Philosophy","text":"<p>These are the core design tenets that <code>libhal</code> and libraries extending it must seek to achieve with every design choice, line written, and architecture change made.</p>"},{"location":"contributor_guide/philosophy/#d1-multi-targeted","title":"D.1 Multi Targeted","text":"<p><code>libhal</code> and the libraries that extend it, should work anywhere. So long as the appropriate compiler or cross compiler is used, the driver should do as it is intended. The exception is <code>target</code> libraries which are designated to execute for a particular target. Even so, those <code>target</code> libraries MUST be unit testable on any host machine.</p>"},{"location":"contributor_guide/philosophy/#d2-light-weight","title":"D.2 Light Weight","text":"<p><code>libhal</code> should keep its interfaces and utility code light weight, meaning such things do not allocate, and if they do only once, do not perform long/length copies, unless a copy was the desired operation,</p>"},{"location":"contributor_guide/philosophy/#d3-general","title":"D.3 General","text":"<p><code>libhal</code> interfaces should be general, meaning that they do not include APIs, or configuration settings that are uncommon in most targets or specific to a particular target.</p>"},{"location":"contributor_guide/philosophy/#d4-minimalist","title":"D.4 Minimalist","text":"<p><code>libhal</code> aims to be as simple as possible and no simpler. Interfaces, utility functions, and libraries should be straight forward for most programmers to understand with added complexity only when it is necessary and no other options exist.</p>"},{"location":"contributor_guide/philosophy/#d5-safe-reliable","title":"D.5 Safe &amp; Reliable","text":"<p><code>libhal</code> and its style guide aim to use patterns, techniques, and documentation to help reduce safety issues and improve reliability.</p>"},{"location":"contributor_guide/philosophy/#d6-tested-testable","title":"D.6 Tested &amp; Testable","text":"<p><code>libhal</code> code should be as testable and unit tested.</p>"},{"location":"contributor_guide/philosophy/#d7-compiled-quickly","title":"D.7 Compiled Quickly","text":"<p><code>libhal</code> code should build fast and eliminate/replace any unnecessary dependencies that cause compile times to be long.</p>"},{"location":"contributor_guide/philosophy/#d8-portable","title":"D.8 Portable","text":"<p><code>libhal</code> code should not require or depend on any OS or target specific code or behaviors. <code>libhal</code> is designed to work anywhere and should not rely on OS.</p>"},{"location":"contributor_guide/style/","title":"\ud83c\udfa8 Style Guide","text":""},{"location":"contributor_guide/style/#s0-code-guidelines","title":"S.0 Code Guidelines","text":"<p>All guides follow the C++ Core Guidelines.</p>"},{"location":"contributor_guide/style/#s1-formatting","title":"S.1 Formatting","text":"<ul> <li>Code shall follow libhal's   <code>.clang-format</code>   file, which uses the Mozilla C++ style format as a base with some adjustments.</li> <li>Code shall follow libhal's   <code>.naming.style</code>   file, which is very similar to the standard library naming convention:</li> <li>CamelCase for template parameters.</li> <li>CAP_CASE for MACROs (avoid MACROs in general).</li> <li>lowercase snake_case for everything else.</li> <li>prefix <code>p_</code> for function parameters.</li> <li>prefix <code>m_</code> for private/protected class member.</li> <li>Refrain from variable names with abbreviations where it can be helped. <code>adc</code>,   <code>pwm</code>, and <code>i2c</code> are extremely common so it is fine to leave them as   abbreviations. Most people know the abbreviations more than the words that   make them up. But words like <code>cnt</code> should be <code>count</code> and <code>cdl</code> and <code>cdh</code>   should be written out as <code>clock_divider_low</code> and <code>clock_divider_high</code>.   Registers do get a pass if they directly reflect the names in the data sheet   which will make looking them up easier in the future.</li> <li>Use <code>#pragma once</code> as the include guard for headers.</li> <li>Every file must end with a newline character.</li> <li>Every line in a file must stay within a 80 character limit.</li> <li>Exceptions to this rule are allowed. Use <code>// NOLINT</code> in these cases.</li> <li>Allowed number radix's for bit manipulation:</li> <li>Only use binary (<code>0b1000'0011</code>) or hex (<code>0x0FF0</code>) for bit manipulation.</li> <li>Never use decimal or octal as this is harder to reason about for most     programmers.</li> <li>Every public API must be documented with the doxygen style comments (CI will   ensure that every public API is documented fully).</li> <li>Include the C++ header version of C headers such as <code>&lt;cstdint&gt;</code> vs   <code>&lt;stdint.h&gt;</code>.</li> </ul>"},{"location":"contributor_guide/style/#s2-refrain-from-performing-manual-bit-set-clear-insertion-and-extraction","title":"S.2 Refrain from performing manual bit set, clear, insertion, and extraction","text":"<p>Bit setting, clearing, and, more importantly, multi-bit insertion and multi-bit extraction can be error prone and problematic. To solve this issue, we recommend using <code>hal::bit_modify</code> or <code>hal::bit_value</code> from the <code>libhal-util</code> library.</p> <p><code>hal::bit_modify</code> takes a reference to a volatile unsigned integer, copies its value to a temporary variable, performs the operations on that temporary variable, and, on destruction, assigns the temporary value to the referenced volatile unsigned integer.</p> <pre><code>// For exposition:\nreg_t* reg = get_peripheral_register();\n\nhal::bit_modify(reg-&gt;control)\n  .insert&lt;pre_scalar&gt;(freq() / desired_frequency)\n  .clear&lt;lower_power_mode&gt;()\n  .set&lt;enable&gt;();\n</code></pre> <p><code>hal::bit_value</code> performs bit modifications on an integer. These are useful for creating <code>constexpr</code> register values that already known at compile time, but want to express the value with a combination of bit mask and modification.</p> <pre><code>constexpr auto default_pin_config = hal::bit_value(0U)\n  .insert&lt;mode&gt;(0x04) // GPIO mode = 0x04\n  .clear&lt;high_slew_rate&gt;()\n  .set&lt;high_speed_mode&gt;()\n  .to&lt;std::uint32_t&gt;();\n</code></pre> <p>Use <code>hal::bit_extract</code> from <code>libhal-util</code> library to perform bitwise extraction operations.</p> <pre><code>while (hal::bit_extract&lt;state&gt;(reg-&gt;status) == states::busy) {\n  continue;\n}\n\n// ... OR ...\n\nfloat my_adc::driver_read() {\n  constexpr auto capture_value = hal::bit_mask::from(4, 11);\n  return hal::bit_extract&lt;capture_value&gt;(reg-&gt;status);\n}\n</code></pre>"},{"location":"contributor_guide/style/#s21-prefer-named-compile-time-bit-mask-apis","title":"S.2.1 Prefer named compile time bit-mask APIs","text":"<p>Always prefer giving names to bit masks as it makes it easier to understand what its impact is on the hardware.</p> <p>Always prefer using the APIs that take a bit masks as templates rather than an input parameters unless the bit mask is not known at compile time. For a bit mask to be used in a template means its <code>constexpr</code> or defined at compile time, allowing the compiler more information about the operation, which it can use to greatly optimize the operation.</p> <pre><code>constexpr auto state = hal::bit_mask::from(4, 5);\nconstexpr auto enable = hal::bit_mask::from(3);\nconstexpr auto prescale = hal::bit_mask::from(6, 13);\n</code></pre>"},{"location":"contributor_guide/style/#s21-use-temporary-tail-chaining-when-possible-on-halbit_modify-and-halbit_value","title":"S.2.1 Use temporary tail chaining when possible on <code>hal::bit_modify</code> and <code>hal::bit_value</code>","text":"<p>Temporary tail chaining looks like the following:</p> <pre><code>hal::bit_value(0U)\n  .insert&lt;hal::nibble_m&lt;1, 2&gt;&gt;(7)\n  .insert&lt;hal::nibble_m&lt;0&gt;&gt;(5)\n  .to&lt;std::uint32_t&gt;();\n</code></pre> <p>Tail chaining allows you to all another API of the class from the return type. GCC seems to perform better when it can see the whole lifetime of the object as well as all of the operations performed on it. This tends to result in very optimal codegen.</p>"},{"location":"contributor_guide/style/#s22-exception-concatenation-can-use-native-syntax","title":"S.2.2 [exception] Concatenation can use native syntax","text":"<p>In a lot of cases, using <code>hal::bit_modify</code> or <code>hal::bit_value</code> can be less expressive than just using left and right shifts. So concatenating integers together using <code>&lt;&lt;</code> and <code>|</code> is acceptable.</p> <pre><code>// auto == std::array&lt;hal::byte, 2&gt;\nauto data = hal::write_then_read&lt;2&gt;(m_i2c, 0x11, addr, timeout);\n// data[0] holds bits 4:11 and data[1] holds bits 0:3\nstd::uint32_t val = data[0] &lt;&lt; 4 | data[1] &gt;&gt; 4;\nreturn val;\n</code></pre> <p>vs</p> <pre><code>// auto == std::array&lt;hal::byte, 2&gt;\nauto data = hal::write_then_read&lt;2&gt;(m_i2c, 0x11, addr, timeout);\nauto value = hal::bit_value(0U)\n  .insert&lt;hal::nibble_m&lt;1, 2&gt;&gt;(data[0])\n  .insert&lt;hal::nibble_m&lt;0&gt;&gt;(hal::bit_extract&lt;hal::nibble_m&lt;1&gt;&gt;(data[1]))\n  .to&lt;std::uint32_t&gt;();\nreturn val;\n</code></pre> <p>Either of these is fine. Choose what you think is cleaner.</p>"},{"location":"contributor_guide/style/#s3-refrain-from-using-macros","title":"S.3 Refrain from using MACROS","text":"<p>Only use macros if something cannot be done without using them. Usually macros can be replaced with <code>constexpr</code> or const variables or function calls. A case where macros are the only way is for HAL_CHECK() since there is no way to automatically generate the boiler plate for returning if a function returns and error in C++ and thus a macro is needed here to prevent possible mistakes in writing out the boilerplate.</p> <p>Only use preprocessor <code>#if</code> and the like if it is impossible to use <code>if constexpr</code> to achieve the same behavior.</p>"},{"location":"contributor_guide/style/#s4-never-include-c-iostream-libraries","title":"S.4 Never include C++ <code>&lt;iostream&gt;</code> libraries","text":"<p>Applications incur an automatic 150kB space penalty for including any of the ostream headers that also statically generate the global <code>std::cout</code> and the like objects. This happens even if the application never uses any part of <code>&lt;iostream&gt;</code> library. <code>&lt;iostream&gt;</code> can be used in libraries that will only be used for host side testing.</p>"},{"location":"contributor_guide/style/#s5-refrain-from-memory-allocations","title":"S.5 Refrain from memory allocations","text":"<p>Interfaces and drivers should refrain from APIs that force memory allocations or implementations that allocate memory from heap. This means avoiding STL libraries that allocate such as <code>std::string</code> or <code>std::vector</code>.</p> <p>Many embedded system applications, especially the real time applications, do not allow dynamic memory allocations. There are many reasons for this that can be found MISRA C++ and AutoSAR.</p>"},{"location":"contributor_guide/style/#s6-drivers-should-not-log-to-stdout-or-stdin","title":"S.6 Drivers should not log to STDOUT or STDIN","text":"<p>Peripheral drivers must NOT log to stdout or stderr. This means no calls to</p> <ul> <li><code>std::printf</code></li> <li><code>std::cout</code></li> <li><code>std::print</code> (C++26's version of print based on <code>std::format</code>)</li> </ul> <p>Consider using the file I/O libraries in C, C++, python or some other language. Would you, as a developer, ever imagine that opening, reading, writing, or closing a file would (write?) to your console? Especially if there did not exist a way to turn off logging. Most users would be very upset as this would not seem like the role of the file I/O library to spam the console. This gets even worse if a particular application has thousands of files and each operation is logging.</p> <p>The role of logging should be held by the application developer, not their drivers or helper functions, unless the purpose of the helper functions or driver is to write to console.</p>"},{"location":"contributor_guide/style/#s7-drivers-should-not-purposefully-halt-or-terminate-the-application","title":"S.7 Drivers should not purposefully halt OR terminate the application","text":"<p>Drivers are not entitled to halt the execution of the application and thus any code block that would effectively end or halt the execution of the program without giving control back to the application are prohibited.</p> <p>As an example drivers should never call:</p> <ul> <li><code>std::abort()</code></li> <li><code>std::exit()</code></li> <li><code>std::terminate()</code></li> <li>any of their variants</li> </ul> <p>This includes placing an infinite loop block in a driver.</p> <p>An application should have control over how their application ends. A driver should report severe errors to the application and let the application decide the next steps. If a particular operation cannot be executed as intended, then an appropriate <code>hal::exception</code> type should be thrown.</p>"},{"location":"contributor_guide/style/#s8-drivers-should-not-pollute-the-global-namespace","title":"S.8 Drivers should not pollute the global namespace","text":"<p>All drivers must be within the <code>hal</code> namespace or within their own bespoke namespace.</p> <p>Inclusion of a C header file full of register map structures is not allowed as it pollutes the global namespace and tends to result in name collisions.</p> <p>Care should be taken to ensure that the <code>hal</code> namespace is also as clean as possible by placing structures, enums, const data, and any other symbols into the driver's class's namespace like so:</p> <pre><code>namespace hal::target\n{\nclass target {\n  struct register_map {\n    std::uint32_t control1;\n    std::uint32_t control2;\n    std::uint32_t data;\n    std::uint32_t status;\n    // ..\n  };\n\n  struct control1_register {\n    static constexpr auto channel_enable = hal::bit::range::from&lt;0, 7&gt;();\n    static constexpr auto peripheral_enable = hal::bit::range::from&lt;8&gt;();\n    // ...\n  };\n\n  // ...\n};\n}\n</code></pre>"},{"location":"contributor_guide/style/#s9-interface-should-follow-the-public-private-api-scheme","title":"S.9 Interface should follow the public private API Scheme","text":"<p>See private virtual method for more details. Rationale can be found within that link as well.</p>"},{"location":"contributor_guide/style/#s10-avoid-using-bool-as","title":"S.10 Avoid using <code>bool</code> as","text":""},{"location":"contributor_guide/style/#s101-an-object-member","title":"S.10.1 an object member","text":"<p><code>bool</code> has very poor information density and takes up 8-bits per entry. If only one <code>bool</code> is needed, then a bool is a fine object member. If multiple <code>bool</code>s are needed, then use a <code>std::bitset</code> along with static <code>constexpr</code> index positions in order to keep the density down to the lowest amount possible.</p> <p>Note</p> <p><code>std::bitset</code> seems to default to building blocks of size <code>int</code> meaning, on 32-bit architectures, this is 4-bytes for a bitset between 1 to 32.</p>"},{"location":"contributor_guide/style/#s102-a-parameter","title":"S.10.2 a parameter","text":"<p>See the article \"Clean code: The curse of a boolean parameter\" for details as to why <code>bool</code> parameters are awful.</p> <p><code>bool</code> is fine if it is the only parameter and it acts as a lexical switch, for example:</p> <pre><code>// This is fine because it reads as set \"LED\" voltage \"level\" to \"FALSE\"\nled.level(false);\n// This is fine because it reads as set \"LED\" voltage \"level\" to \"TRUE\"\nled.level(true);\n</code></pre>"},{"location":"contributor_guide/style/#s11-integrating-third-party-libraries-by-source","title":"S.11 Integrating third party libraries by source","text":"<p>In general, third party libraries should NOT be integrated into a library by source. It should be depended upon using a package manager. But in some cases third party libraries must be included by source. In these cases, the third party libraries should be committed into a project, without modifications, into the <code>include/&lt;library_name&gt;/third_party</code> directory. After that commit, the third party libraries can be used by and integrated into the library code base, in a following commit.</p> <p>If a third party library is modified, that library must have a section at the top of the file with the following description:</p> <pre><code>/**\n * [libhal] modifications to this file are as follows:\n *\n *    1. mod 1\n *    2. mod 2\n *    3. mod 3\n *    4. mod 4\n */\n\n/**\n * &lt;LICENSE GOES HERE!&gt;\n */\n</code></pre> <p>Care must be taken to ensure that third party libraries do not conflict with the licenses of libhal libraries and permit direct integration as well as modification.</p> <p>Rationale: Makes keeping track of changes and the history of files easier to manage.</p>"},{"location":"contributor_guide/style/#s12-avoid-stdatomic","title":"S.12 Avoid <code>std::atomic</code>","text":"<p>Avoid using <code>std::atomic</code> in device libraries due to portability issues across architectures. Device libraries are designed to work across architectures meaning they cannot depend on platform specific constructs like this.</p> <p>Note that <code>target</code> and <code>processor</code> libraries are allowed to use <code>std::atomic</code> if it is available with their cross compiler and toolchain. In this case, the we can know which target devices the software is running on, either the target itself, which we already know can support it, or on a host machine for unit testing, which is very likely to have a compiler that supports atomics.</p>"},{"location":"contributor_guide/style/#s13-avoid-thread","title":"S.13 Avoid <code>&lt;thread&gt;</code>","text":"<p>Embedded system compilers tend to not provide an implementation of <code>&lt;thread&gt;</code> because the choice of which threading model or multi-threading operating system is left to the developer.</p> <p>In general, <code>#include &lt;thread&gt;</code> will almost never work when cross compiling.</p>"},{"location":"contributor_guide/style/#s14-headers","title":"S.14 Headers","text":"<p>Header files should be self-contained (compile on their own) and end in <code>.hpp</code> for C++ files and <code>.h</code> for C files.</p> <p>When a header declares inline functions or templates that clients of the header will instantiate, the inline functions and templates must also have definitions in the header. When all instantiations of a template occur in one .cc file, either because they're explicit or because the definition is accessible to only the .cc file, the template definition can be kept in that file.</p>"},{"location":"contributor_guide/style/#s141-include-guards","title":"S.14.1 Include Guards","text":"<p>For ease of use, use <code>#pragma once</code> as your include guard. Usage of classic include guards like:</p> <pre><code>#ifndef FOO_BAR_BAZ_H_\n#define FOO_BAR_BAZ_H_\n\n...\n\n#endif  // FOO_BAR_BAZ_H_\n</code></pre> <p>Are annoying and error prone. Do not use these!</p>"},{"location":"contributor_guide/style/#s142-include-what-you-use","title":"S.14.2 Include What You Use","text":"<p>If a source or header file refers to a symbol defined elsewhere, the file should directly include a header file which properly intends to provide a declaration or definition of that symbol. It should not include header files for any other reason.</p> <p>Do not rely on transitive inclusions. This allows people to remove no-longer-needed #include statements from their headers without breaking clients. This also applies to related headers - foo.cc should include bar.h if it uses a symbol from it even if foo.h includes bar.h.</p>"},{"location":"contributor_guide/style/#s143-include-order","title":"S.14.3 Include Order","text":"<p>Headers should be included in your headers and source files in the following order:</p> <ul> <li>C standard library headers. Include using chevrons: <code>&lt;&gt;</code>.</li> <li>C 3rd party library packages. Include using chevrons: <code>&lt;&gt;</code>.</li> <li>C++ standard library headers. Include using chevrons: <code>&lt;&gt;</code>.</li> <li>C++ 3rd party Libraries' headers (<code>libhal</code>, <code>libhal-arm-mcu</code>, <code>libhal-util</code>,   etc...). Include using chevrons: <code>&lt;&gt;</code></li> <li>Local package/project headers. Include using quotes: <code>\"\"</code></li> </ul> <p>For standard C headers use the C++ <code>&lt;cstdio&gt;</code> style over the C <code>&lt;stdio.h&gt;</code> style.</p> <p>Headers should be sorted alphabetically. <code>clang-format</code> will perform this work for you. Rely on it vs doing it yourself.</p> <p>Here is an example of how this should look:</p> <pre><code>// License at the top of the file with newline between the start of pragma once\n\n#pragma once\n\n// C headers first\n#include &lt;cstdio&gt;\n#include &lt;cstdint&gt;\n\n// C library headers\n#include &lt;minimp3.h&gt;\n\n// C++ headers\n#include &lt;string_view&gt;\n#include &lt;span&gt;\n\n// C++ Library headers\n#include &lt;libhal-util/output_pin.hpp&gt;\n#include &lt;libhal-util/serial.hpp&gt;\n#include &lt;libhal-util/steady_clock.hpp&gt;\n#include &lt;libhal-util/stream_dac.hpp&gt;\n\n// Local Project\n#include \"resource_list.hpp\"\n\n// leave a blank line for the actual code\n</code></pre> <p>Exception: <code>boost.ut</code> must ALWAYS be the last include in the code in order to allow <code>ostream</code> <code>operator&lt;&lt;</code> overloading to work.</p>"},{"location":"contributor_guide/style/#s15-classes","title":"S.15 Classes","text":""},{"location":"contributor_guide/style/#s151-declaration-order","title":"S.15.1 Declaration Order","text":"<p>A class's visibility specifiers and member sections should appear in the following order:</p> <ol> <li>Public</li> <li>Protected</li> <li>Private</li> </ol> <p>Omit any sections that would be empty.</p> <p>Within each section, group similar declarations together and follow this order:</p> <ol> <li>Types and type aliases:<ul> <li>Using directives (<code>using</code>)</li> <li>Enum classes</li> <li>Nested structs and classes</li> <li>Friend classes and structs</li> </ul> </li> <li>Static constants</li> <li>Factory functions (if applicable)</li> <li>Constructors and assignment operators</li> <li>Destructor</li> <li>All other member functions (static and non-static member functions, as well    as friend functions)</li> <li>All other data members (static and non-static)</li> </ol> <p>Do not put large method definitions inline within the class definition. Typically, only trivial or performance-critical methods that are very short may be defined inline. If the class is a template, then all functions must be defined inline in the header file.</p> <p>Note</p> <p>If a friend is a class or class function, then the friend should appear under the same visibility specifier as the friend. For example, if you are friending a private class function, then the friend function declaration should also appear in the private section of the friending class.</p>"},{"location":"contributor_guide/style/#s152-storing-references","title":"S.15.2 Storing references","text":"<p>libhal drivers classes should not have reference member variables like so:</p> <pre><code>class my_driver {\npublic:\n  my_driver(hal::adc16&amp; p_adc): m_adc(p_adc) {\n  }\n\nprivate:\n  hal::adc16&amp; m_adc;  // \u274c Bad! Do not do this.\n}\n</code></pre> <p>Reference members implicitly delete the copy and move constructors of a class they are within because they themselves are not copyable. You cannot reassign a reference after it is made.</p> <p>Instead take the parameter as a reference but save its address as a pointer:</p> <pre><code>class my_driver {\npublic:\n  my_driver(hal::adc16&amp; p_adc): m_adc(&amp;p_adc) {\n  }\n\nprivate:\n  hal::adc16* m_adc = nullptr;  // \u2705 Good!\n}\n</code></pre>"},{"location":"contributor_guide/upgrade_to_libhal_3_device_library/","title":"Upgrading a Device Library from libhal 2.x.y to 3.x.y","text":"<p>This guide is for device, utility, RTOS, or any other cross platform libraries that need to be ported from libhal 2.x.y to 3.x.y.</p> <p>The upgrade to libhal 3.x.y is a breaking change for everything so their major number for your library will need to be updated. So if the previous version was 2.1.5, then its new version is 3.0.0. If the version was 3.0.1, then the next is 4.0.0. Remember that version for later because everywhere in this code with where you see <code>3.0.0</code> replace it with the correct version for your library.</p>"},{"location":"contributor_guide/upgrade_to_libhal_3_device_library/#1-set-the-ciyml-to-the-following","title":"(1) Set the <code>ci.yml</code> to the following","text":"<pre><code>name: \u2705 CI\n\non:\n  workflow_dispatch:\n  pull_request:\n  push:\n    branches:\n      - main\n  schedule:\n    - cron: \"0 12 * * 0\"\n\njobs:\n  ci:\n    uses: libhal/ci/.github/workflows/library_check.yml@5.x.y\n    secrets: inherit\n\n  deploy_cortex-m4f_check:\n    uses: libhal/ci/.github/workflows/deploy.yml@5.x.y\n    with:\n      arch: cortex-m4f # Replace with correct architecture\n      os: baremetal\n      compiler: gcc\n      compiler_version: 12.3\n      compiler_package: arm-gnu-toolchain\n    secrets: inherit\n\n  demo_check:\n    uses: libhal/ci/.github/workflows/demo_builder.yml@5.x.y\n    with:\n      compiler_profile_url: https://github.com/libhal/arm-gnu-toolchain.git\n      compiler_profile: v1/arm-gcc-12.3\n      platform_profile_url: https://github.com/libhal/libhal-lpc40.git\n      platform_profile: v2/lpc4078 # replace if you are not using lpc4078\n    secrets: inherit\n</code></pre> <p>This will handle everything you need for checking your library conforms to the libhal standards.</p>"},{"location":"contributor_guide/upgrade_to_libhal_3_device_library/#2-add-a-release-yaml-file-with-the-next-version-of-the-library","title":"(2) Add a release yaml file with the next version of the library","text":"<p>The new scheme for launching versions is to have a workflow dispatch action file. This action must be manually invoked to launch a version. This allows for more control over which versions are deployed to the server as well as launching revisions if a dependency has a bug but a client cannot upgrade the library version.</p> <p>The file name in the <code>.github</code> file will be <code>X.0.0.yml</code> where X is the next major version number.</p> <pre><code>name: \ud83d\ude80 Deploy 3.0.0 # Replace with the next major version\n\non:\n  workflow_dispatch:\n\njobs:\n  deploy:\n    uses: libhal/ci/.github/workflows/deploy_all.yml@5.x.y\n    with:\n      version: 3.0.0 # Replace with the next major version must match the title\n    secrets: inherit\n</code></pre>"},{"location":"contributor_guide/upgrade_to_libhal_3_device_library/#3-refactor-library-conanfilepy-found-at-the-root-of-the-repo","title":"(3) Refactor library <code>conanfile.py</code> (found at the root of the repo)","text":"<p>Replace the contents of the file with the data below:</p> <pre><code># Copyright 2024 Khalil Estell\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom conan import ConanFile\n\nrequired_conan_version = \"&gt;=2.0.14\"\n\n\nclass libhal___device___conan(ConanFile):\n    name = \"libhal-__device__\"\n    license = \"Apache-2.0\"\n    homepage = \"https://github.com/libhal/libhal-__device__\"\n    description = (\"... fill this out ...\")\n    topics = (\"... fill this out ...\")\n    settings = \"compiler\", \"build_type\", \"os\", \"arch\"\n\n    python_requires = \"libhal-bootstrap/[^1.0.0]\"\n    python_requires_extend = \"libhal-bootstrap.library\"\n\n    def requirements(self):\n        bootstrap = self.python_requires[\"libhal-bootstrap\"]\n        bootstrap.module.add_library_requirements(self)\n\n    def package_info(self):\n        self.cpp_info.libs = [\"libhal-__device__\"]\n        self.cpp_info.set_property(\"cmake_target_name\", \"libhal::__device__\")\n</code></pre> <p>Replace every instance of <code>__device__</code> with the name of the library.</p> <pre><code>    description = (\"... fill this out ...\")\n    topics = (\"... fill this out ...\")\n</code></pre> <p>Fill the <code>description</code> and <code>topics</code> sections based on what they were before.</p>"},{"location":"contributor_guide/upgrade_to_libhal_3_device_library/#4-update-cmakeliststxt","title":"(4) Update CMakeLists.txt","text":"<p>Remove the following packages and link libraries from your CMake file. These are now automatically linked against your library when you use <code>libhal_test_and_make_library</code>.</p> <pre><code>  PACKAGES\n  libhal\n  libhal-util\n\n  LINK_LIBRARIES\n  libhal::libhal\n  libhal::util\n</code></pre>"},{"location":"contributor_guide/upgrade_to_libhal_3_device_library/#5-update-test_packagecmakeliststxt","title":"(5) Update <code>test_package/CMakeLists.txt</code>","text":"<p>Replace it with this, update <code>__device__</code> to the correct library name:</p> <pre><code># Copyright 2024 Khalil Estell\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\ncmake_minimum_required(VERSION 3.15)\nproject(test_package LANGUAGES CXX)\n\nfind_package(libhal-__device__ REQUIRED CONFIG)\n\nadd_executable(${PROJECT_NAME} main.cpp)\ntarget_include_directories(${PROJECT_NAME} PUBLIC .)\ntarget_compile_features(${PROJECT_NAME} PRIVATE cxx_std_20)\ntarget_link_libraries(${PROJECT_NAME} PRIVATE libhal::__device__)\n</code></pre>"},{"location":"contributor_guide/upgrade_to_libhal_3_device_library/#5-update-test_packageconanfilepy","title":"(5) Update <code>test_package/conanfile.py</code>","text":"<p>Replace it with this:</p> <pre><code># Copyright 2024 Khalil Estell\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom conan import ConanFile\n\n\nclass TestPackageConan(ConanFile):\n    settings = \"os\", \"arch\", \"compiler\", \"build_type\"\n\n    python_requires = \"libhal-bootstrap/[^1.0.0]\"\n    python_requires_extend = \"libhal-bootstrap.library_test_package\"\n\n    def requirements(self):\n        self.requires(self.tested_reference_str)\n</code></pre>"},{"location":"contributor_guide/upgrade_to_libhal_3_device_library/#5-replace-demosconanfilepy","title":"(5) Replace <code>demos/conanfile.py</code>","text":"<p>Replace it with the following:</p> <pre><code># Copyright 2024 Khalil Estell\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom conan import ConanFile\n\n\nclass demos(ConanFile):\n    python_requires = \"libhal-bootstrap/[^1.0.0]\"\n    python_requires_extend = \"libhal-bootstrap.demo\"\n\n    def requirements(self):\n        bootstrap = self.python_requires[\"libhal-bootstrap\"]\n        bootstrap.module.add_demo_requirements(self)\n        # Change 3.0.0 to the correct major release number\n        # Replace __device__ with the name of the library\n        self.requires(\"libhal-__device__/[^3.0.0 || latest]\")\n</code></pre> <p>Info</p> <p>You may be wonder why we have <code>|| latest</code> for the version range. \"latest\" is the version used by CI to ensure that the demo builds using the \"latest\" version built on the CI's virtual machine. It isn't a valid libhal version for a library, so we can use it for CI purposes.</p>"},{"location":"contributor_guide/upgrade_to_libhal_3_device_library/#6-replace-demoscmakeliststxt","title":"(6) Replace <code>demos/CMakeLists.txt</code>","text":"<pre><code># Copyright 2024 Khalil Estell\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\ncmake_minimum_required(VERSION 3.20)\n\nproject(demos LANGUAGES CXX)\n\nlibhal_build_demos(\n    DEMOS\n    demo1\n    demo2\n    # Add more demos if applicable\n\n    PACKAGES\n    libhal-__device__\n\n    LINK_LIBRARIES\n    libhal::__device__\n)\n</code></pre> <p><code>libhal</code>, <code>libhal-util</code>, and <code>libhal-__platform__</code> (where <code>__platform__</code> is the platform defined in your platform profile file), are automatically searched for and linked into your project, so you only need to link in your library and any others that are needed for the demos to build correctly.</p> <p>Add any other additional packages that are linked in beyond the <code>__device__</code>.</p> <p>Replace <code>demo1</code> and <code>demo2</code> with the correct demo names in the <code>applications</code> directory. Demos have the name <code>demo_name.cpp</code>, and the name you put in the <code>DEMOS</code> list is their name without the <code>.cpp</code> extension.</p>"},{"location":"contributor_guide/upgrade_to_libhal_3_device_library/#7-refactor-code","title":"(7) Refactor code","text":"<p>This is where the fun bit comes in. Now that all of the interfaces have been modified, Each header and cpp file that uses them will need to fixed up.</p> <ol> <li>For every api that inherits an interface, update the APIs for derived class    to match the new interface.</li> <li>Replace factory functions with constructors (make functions should stay the    same as they were before).</li> <li>Use exceptions rather than <code>return hal::new_error()</code>. Make sure to use    <code>hal::safe_throw</code> instead of <code>throw</code> directly. To know which exception to    throw you MUST read the <code>libhal/error.hpp</code> file and determine which    exception fits the best. If none of them seem to fit, join the discord and    ask about it in the \"discussions\" channel. Also consider leaving an issue on the <code>libhal/libhal</code> repo about the error you'd like to add to the list or if you aren't sure. See <code>std::errc</code> for the list of error codes we use to make our exceptions.</li> </ol>"},{"location":"contributor_guide/upgrade_to_libhal_3_device_library/#8-refactor-tests_package","title":"(8) Refactor <code>tests_package/</code>","text":"<p>Update the test package to use the newly refactored code. If there is nothing in the <code>main.cpp</code> besides including a header file, then leave it as is.</p>"},{"location":"contributor_guide/upgrade_to_libhal_3_device_library/#8-refactor-tests","title":"(8) Refactor tests","text":"<p>This shouldn't be too hard. Apply the same techniques used in refactor code. Be sure to look at <code>libhal-util</code>, <code>libhal-soft</code> and <code>libhal-mock</code> to get an idea of what is needed for the refactor. Remove all of the checks for success status such as:</p> <pre><code>  expect(!result1);\n  expect(!result2);\n  expect(!result3);\n  expect(!result4);\n  expect(!result5);\n\n  // or\n\n  expect(bool{ result1 });\n  expect(bool{ result2 });\n  expect(bool{ result3 });\n  expect(bool{ result4 });\n  expect(bool{ result5 });\n</code></pre> <p>To test for a thrown exception use the following pattern:</p> <pre><code>  expect(throws&lt;hal::argument_out_of_domain&gt;([&amp;]() {\n    test_subject_object.function_that_will_throw(input_that_will_cause_throw);\n  }));\n</code></pre> <p><code>throws</code> checks if an exception of a particular type is thrown and will catch it and return an expectation value. It takes a lambda or any other callable, that invokes the throwing behavior. If the calls do not throw an exception then throws fails and reports that to the user.</p>"},{"location":"contributor_guide/upgrade_to_libhal_3_device_library/#7-refactor-test_package","title":"(7) Refactor test_package","text":"<p>Remove any code needed for boost.</p> <pre><code>namespace boost {\nvoid throw_exception(std::exception const&amp; e)\n{\n  hal::halt();\n}\n}  // namespace boost\n</code></pre> <p>Remove anything that is target specific in the test package such as cross compile flags. Those flags MUST be removed and only handled by the compiler.</p> <p>Update the test package to make the new APIs.</p>"},{"location":"contributor_guide/upgrade_to_libhal_3_device_library/#questions","title":"Questions?","text":"<p>If you have any questions please post them in the <code>discussions</code> channel in discord. Make sure to make it a thread so the main channel is not overwhelmed with messages.</p>"},{"location":"education/actuators/","title":"Basics of Actuators","text":"<p>Coming soon...</p>"},{"location":"education/adc/","title":"ADC: Analog to Digital Converter","text":"<p>Warning</p> <p>This document describes the ADC for libhal 5.0.0 which is not out yet.</p> <p>Welcome to the libhal adc tutorial. ADCs are used to sample analog voltage signals and convert them into a number that can be used by controllers to sense the world .</p>"},{"location":"education/adc/#learning-about-adcs","title":"Learning about ADCs","text":"<p>To learn more about ADCs we have made a list of online resources to learn:</p> <ul> <li>Sparkfun Tutorial:   (RECOMMENDED) Quick and easy to understand.</li> <li>element14 ADC tutorial video:   A great 10min long video that goes into the many different ADC   implementations and how they convert voltages into decimal numbers.</li> </ul>"},{"location":"education/adc/#adc-interfaces-and-how-to-use-them","title":"ADC interfaces and how to use them","text":"<p>libhal has 4 ADC interfaces. Each is suffixed with the bit resolution of the ADC.</p> <ul> <li><code>hal::adc8</code>: for ADCs with 8 bits or below</li> <li><code>hal::adc16</code>: for ADCs with 9 to 16 bits</li> <li><code>hal::adc24</code>: for ADCs with 17 to 24 bits</li> <li><code>hal::adc32</code>: for ADCs with 25 to 32 bits</li> </ul> <p>Different applications require different resolutions of analog measurement.</p> <ul> <li><code>hal::adc8</code> for when resolution is not very important and can be low</li> <li><code>hal::adc16</code> will be the most common ADC version and will suite most general   use cases</li> <li><code>hal::adc24</code> is for applications that need high precision</li> <li><code>hal::adc32</code> is for applications that need extremely high precision</li> </ul> <p>The ADC interfaces have a singular API which is <code>read()</code>.</p> <pre><code>// Returns value from 0 to 255\nhal::u8 hal::adc8::read();\n// Returns value from 0 to 65,535\nhal::u16 hal::adc16::read();\n// Returns value from 0 to 16,777,215\nhal::u32 hal::adc24::read();\n// Returns value from 0 to 4,294,967,295\nhal::u32 hal::adc32::read();\n</code></pre> <p>The <code>read()</code> API returns a value between <code>0</code> and the maximum value representable for that bit-width. Drivers that are not exactly the bit-width of the adc they represent must upscale their ADC values to match the ADC they are implementing. For example a 9-bit ADC would need to perform an upscale to 16-bits.</p>"},{"location":"education/adc/#how-adc-upscaling-works","title":"How ADC upscaling works","text":"<p>libhal provides an integer upscaling facility in:</p> <pre><code>template&lt;std::size_t incoming_bit_width, std::size_t upscaled_bit_width&gt;\nconstexpr container_int_t&lt;upscaled_bit_width&gt; upscale(\n    std::unsigned_integral auto p_value);\n</code></pre> <p>This may look pretty complicated but lets see it in use:</p> <pre><code>hal::u16 my_adc::read() {\n  hal::u16 adc_value = /* ... acquire 9-bit sample ... */;\n  // scale 9-bit sample to 16-bits\n  return hal::upscale&lt;9, 16&gt;(adc_value);\n}\n</code></pre> <p>The key to proportional upscaling is replicating the original bits into the larger bit depth through shifting and bitwise OR operations. Consider upscaling an 8-bit value to 16 bits:</p> <pre><code>8-bit value:          10110101 (decimal 181)\nNaive padding:        10110101 00000000 (decimal 46,336)\nBit duplication:      10110101 10110101 (decimal 46,421)\n</code></pre> <p>Zero-padding (left shifting) multiplies the value by 256, which distorts the proportional relationship. More importantly, zero-padding can never reach the maximum 16-bit value (65,535) as the lower bits are always 0. Similarly, padding with 1s means you can never reach 0 in the larger bit depth.</p> <p>To demonstrate this distortion, let's look at the middle value of a <code>uint8_t</code> (127):</p> <pre><code>8-bit middle:         01111111 (decimal 127, 49.803% of 256)\nNaive padding:        01111111 00000000 (decimal 32,512)\nBit duplication:      01111111 01111111 (decimal 32,767)\n</code></pre> <p>With naive zero-padding, 32,512 is only 49.61% of the 16-bit maximum (65,535), creating a proportional error of 0.193%. In contrast, bit duplication yields 32,767, which is exactly 50% of 65,535, maintaining the correct proportional relationship from the original 8-bit value.</p> <p>Bit duplication ensures that all values maintain their relative positions when scaled up - when the input is 0, the output is 0, and when the input is max (255), the output is max (65,535). This makes it ideal for ADC upscaling where maintaining proportional relationships across the entire range is crucial.</p>"},{"location":"education/adc/#using-upscaled-adc-values-for-math","title":"Using upscaled ADC values for math","text":"<p>Typically, ADC values are used to scale other values. Lets take a very rudimentary example of a potentiometer with 350 degrees of movement.</p> <pre><code>hal::u16 adc_to_degrees(hal::adc16&amp; p_adc) {\n  constexpr hal::u16 max_degrees = 350;\n  constexpr auto u16_max = std::numeric_limits&lt;hal::u16&gt;::max();\n\n  auto const u16_sample = p_adc.read();\n  // Multiplication between two u16s requires u32 to contain it\n  hal::u32 const overscaled_value =  max_degrees * u16_sample;\n  // Divide resolve by the maximum value of a u16 to scale it back to degrees\n  // Because we are dividing by the max of u16, the resulting value will be u16\n  // in size.\n  auto const degrees = static_cast&lt;hal::u16&gt;(overscaled_value / u16_max);\n\n  return degrees;\n}\n</code></pre> <p>Scaling using a proportional integer value works like so:</p> <pre><code>           /  adc_value * 350  \\\ndegrees = | ------------------- |\n           \\       65535       /\n</code></pre> <p>Lets put in a value that is in the middle of the ADC value. We should get a degrees value also in the middle of the 350 degrees which is 175.</p> <pre><code>           /    32767 * 350    \\\ndegrees = | ------------------- | =  175 (middle of the potentiometer)\n           \\       65535       /\n</code></pre>"},{"location":"education/adc/#performance-of-scaled-values","title":"Performance of scaled values","text":"<p>By using scaled values, the application writer can decide how they want to perform mathematics on the adc samples based on their maximum value. For example, if the application requires a <code>adc24</code> and the result is multiplied by an <code>8-bit</code> number, the result can still be contained in a <code>u32</code> without needing to use a <code>u64</code> bit value. Note that u64 math on 32-bit systems must me emulated in software which results in a performance drop.</p>"},{"location":"education/adc/#adc-utilities","title":"ADC Utilities","text":""},{"location":"education/adc/#adc-scaler-apis","title":"ADC scaler APIs","text":"<p>To make this scaling easier we provide two APIs</p> <pre><code>constexpr hal::u16 hal::scale_value(hal::u16 p_max_value,\n                                    hal::adc16&amp; p_adc);\ntemplate&lt;std::integral int_t&gt;\nconstexpr hal::u16 hal::scale_value(hal::range&lt;int_t&gt; p_value_range,\n                                    hal::adc16&amp; p_adc);\n</code></pre> <p>Using these APIs we get:</p> <pre><code>hal::u16 adc_to_degrees(hal::adc16&amp; p_adc) {\n  constexpr hal::u16 max_degrees = 350;\n  return scale_value(max_degrees, p_adc);\n}\n\nhal::u16 adc_to_degrees(hal::adc16&amp; p_adc) {\n  // In this case we have a minimum that is not\n  constexpr hal::u16 min_degrees = 20;\n  constexpr hal::u16 max_degrees = 350;\n  return scale_value({ .min = min_degrees, .max = max_degrees}, p_adc);\n}\n</code></pre>"},{"location":"education/adc/#adaptor-classes","title":"Adaptor classes","text":"<p>Let say you have a 16-bit ADC and want to use it in place of a 8-bit adc. This can happen when a driver that requires an ADC requires a different ADC then what you currently have. Reducing the resolution is as easy as shifting the data to the right to reach the desired bit-width.</p> <pre><code>template&lt;hal::adc_t destination_adc, hal::adc_t source_adc&gt;\nclass adc_adaptor {\npublic:\n  adc_adaptor(source_adc&amp; p_source);\n  adc_adaptor(source_adc&amp;&amp; p_source);\n};\n</code></pre> <p>Usage:</p> <pre><code>hal::adc24&amp; high_precision_adc = /* ... */;\nhal::adc_adaptor&lt;hal::adc16&gt; adc_16_bit(high_precision_adc);\nhal::u16 reading = adc_16_bit.read();\n</code></pre> <p>The adaptor can also scale up bit data but usage in that direction is dubious if an driver requires a specific resolution.</p> <pre><code>hal::adc8&amp; low_precision_adc = /* ... */;\nhal::adc_adaptor&lt;hal::adc16&gt; adc_16_bit(low_precision_adc);\nhal::u16 reading = adc_16_bit.read();\n</code></pre>"},{"location":"education/adc/#building-drivers-that-take-haladcn","title":"Building Drivers that take <code>hal::adcN</code>","text":"<p><code>hal::adcN</code> can be shared but in general it is recommended to pass a single adc to a single driver to use. Driver implementors should assume that they are the only users of the <code>hal::adcN</code>. Driver implementors should assume that the passed in adc will outlive the lifetime of the driver.</p> <p>Drivers that require an ADC to function should look similar to the following:</p> <pre><code>class my_driver {\npublic:\n  my_driver(hal::adc16&amp; p_adc): m_adc(&amp;p_adc) {\n    // Do what is needed for the driver\n  }\n\nprivate:\n  hal::adc16* m_adc = nullptr;\n}\n</code></pre> <ul> <li>For your application, decide what bit-resolution your driver requires. When   in doubt, choose <code>hal::adc16</code> as it is the most common ADC type.</li> <li>Accept your ADC type by reference and store the ADC's address within a   pointer. See style guide \"S.15.2 Storing references\" for more details.</li> </ul> <p>And thats about it. You can use the adc as much as you like in your APIs. The only concern is ensuring that you do not get integer overflows when performing math on the ADC values.</p>"},{"location":"education/adc/#implementing-the-adc-interface","title":"Implementing the ADC interface","text":"<p>Warning</p> <p>This section is incomplete!</p> <p>ADCs can appear in different locations such as:</p> <ul> <li>Embedded into the silicon of a microcontroller</li> <li>Discrete devices that a controller to speak to over protocols like i2c and   spi.</li> </ul> <p>ADCs typically come with multiple channels. Each ADC object should manage and control a singular ADC channel. Initializing an ADC object may require that it setup the whole.</p>"},{"location":"education/adc/#why-this-design-choice","title":"Why this design choice?","text":"<p>This section goes over the API design choice for the <code>hal::adcN</code> APIs. Starting with the original design:</p>"},{"location":"education/adc/#why-not-provide-a-single-interface-w-a-bit-width-api","title":"Why not provide a single interface w/ a bit-width API?","text":"<p>A very common approach for an ADC abstraction would be something like this:</p> <pre><code>struct adc {\n  hal::u8 bit_width();\n  hal::u32 read();\n};\n</code></pre> <p>Where an API is provided for both the bit-width and ADC value. To compute actual scaled value, the caller will need to call the <code>bit_width</code> API before it can use the information from <code>read()</code>. Calculating the maximum value for a bit width can be done with the following expression: <code>(1 &lt;&lt; bit_width) - 1</code>. This approach would allow interfaces to be used for everything ADC related.</p> <p>There are a couple of reasons why I do not like this approach:</p>"},{"location":"education/adc/#problem-1-2-virtual-calls-needed-to-realize-the-value","title":"Problem #1: 2 virtual calls needed to realize the value","text":"<p>If a function or method has never once called any APIs on an ADC, it must first call <code>bit_width</code> then call <code>read</code> to understand the value of <code>read</code>. Luckily the <code>bit_width</code> is a value that should be known at compile time and is intrinsic to the ADC's hardware, so returning the value is very simple and straight forward. But for each scope where the <code>bit_width</code> information is lost, the <code>bit_width</code> API must be called.</p> <p>The second virtual API call requires additional cycles, although not that many, but if we can avoid extra API calls and get all of the information in a single call, then I think that is the better technical design decision.</p>"},{"location":"education/adc/#problem-2-caching-bit-width-in-drivers","title":"Problem #2: Caching bit-width in drivers","text":"<p>For drivers, calling <code>bit_width</code> each time you need to scale a value based on <code>read</code> would be a waste of cycles. It would be faster to call <code>bit_width</code> once at driver construction and cache the full-scale value into a <code>hal::u32</code>. Then reuse that value through out the code.</p> <p>This would mean that drivers using an ADC interface will preferable cache an extra 32-bit word to save on a virtual call. Thus, this API design results in additional memory usage in order to improve on performance.</p>"},{"location":"education/adc/#problem-3-computational-complexity","title":"Problem #3: Computational complexity","text":"<p>Because the width isn't known until runtime, code using any such ADC will have to prepared for ADCs with large bit widths such as 24-bit ADCs. Code will need to perform a check against the bit-width and determine what resolution is needed for the code. It would look something like this:</p> <pre><code>hal::u32 scale_to_degrees(hal::adc_split&amp; impl)\n{\n  constexpr hal::u16 max_degrees = 360;\n  auto bit_width = impl.bit_width();\n  auto response = impl.read();\n\n  if (bit_width &gt; 16) {\n    auto const shift_amount = bit_width - 16;\n    response &gt;&gt;= shift_amount;\n    bit_width = 16;\n  }\n\n  auto const max_scale = (1 &lt;&lt; bit_width) - 1;\n  auto const up_scaled = response * max_degrees;\n  auto const final_value = up_scaled / max_scale;\n  return final_value;\n}\n</code></pre> <p>In this case, our math can only work with 16-bit resolution values, so a check against the bit_width is required. If that branch is taken additional operations are needed to scale the value down to a bit-width that the code can work with. Or to eliminate the branch, the code could use <code>hal::u64</code>, but then the performance on 32-bit systems tanks.</p>"},{"location":"education/adc/#problem-4-why-not-return-both","title":"Problem #4: Why not return both?","text":"<p>You could return a struct with both of the information. But now each call has the additional cost of returning a bit-width each time it is called even if it won't be used.</p>"},{"location":"education/adc/#conclusion-about-bit-width-apis","title":"Conclusion about bit-width APIs","text":"<p>The choice to include a bit-width API takes information that is known at compile time and is intrinsic to the device and makes it only accessible via runtime. To accommodate this, code developers must:</p> <ol> <li>Make additional calls</li> <li>Cache information</li> <li>Computer the full-scale value</li> <li>Perform additional logic to ensure math safety</li> </ol> <p>These can all be eliminated by categorizing each adc bit-width bucket into the 4 interfaces mentioned and merging the bit-width info into the returned value via upscaling. Lets consider <code>hal::adc16</code>:</p> <ol> <li>Only requires a single call</li> <li>No need to cache information, simply use the sample that was returned</li> <li>Full scale is known at compile time as the max value of a <code>u16</code> (65535)</li> <li>No additional logic is required because bit-width is intrinsic to the    interface</li> </ol> <p>Using upscaled values eliminates operations that would otherwise be reproduced throughout a code base and across drivers. Scaling within each of the <code>adcN</code> interface buckets ensures that only a single left shift and OR operation is required to upscale the data.</p>"},{"location":"education/adc/#benchmarks-against-other-options","title":"Benchmarks against other options","text":"<pre><code>#include &lt;cinttypes&gt;\n#include &lt;climits&gt;\n#include &lt;concepts&gt;\n#include &lt;cstdint&gt;\n#include &lt;cstdio&gt;\n#include &lt;limits&gt;\n\n#include &lt;libhal-exceptions/control.hpp&gt;\n#include &lt;libhal-util/serial.hpp&gt;\n#include &lt;libhal-util/steady_clock.hpp&gt;\n#include &lt;libhal/error.hpp&gt;\n\n#include &lt;resource_list.hpp&gt;\n\n// This is only global so that the terminate handler can use the resources\n// provided.\nresource_list resources{};\n\n[[noreturn]] void terminate_handler() noexcept\n{\n  bool valid = resources.status_led &amp;&amp; resources.clock;\n\n  if (not valid) {\n    // spin here until debugger is connected\n    while (true) {\n      continue;\n    }\n  }\n\n  // Otherwise, blink the led in a pattern, and wait for the debugger.\n  // In GDB, use the `where` command to see if you have the `terminate_handler`\n  // in your stack trace.\n\n  auto&amp; led = *resources.status_led.value();\n  auto&amp; clock = *resources.clock.value();\n\n  while (true) {\n    using namespace std::chrono_literals;\n    led.level(false);\n    hal::delay(clock, 100ms);\n    led.level(true);\n    hal::delay(clock, 100ms);\n    led.level(false);\n    hal::delay(clock, 100ms);\n    led.level(true);\n    hal::delay(clock, 1000ms);\n  }\n}\n\nvoid application();\n\nint main()\n{\n  // Setup the terminate handler before we call anything that can throw\n  hal::set_terminate(terminate_handler);\n\n  // Initialize the platform and set as many resources as available for this the\n  // supported platforms.\n  initialize_platform(resources);\n\n  try {\n    application();\n  } catch (std::bad_optional_access const&amp; e) {\n    if (resources.console) {\n      hal::print(*resources.console.value(),\n                 \"A resource required by the application was not available!\\n\"\n                 \"Calling terminate!\\n\");\n    }\n  }  // Allow any other exceptions to terminate the application\n\n  // Terminate if the code reaches this point.\n  std::terminate();\n}\n\nnamespace hal {\n\nusing integral_type = std::uint16_t;\nconstexpr auto integral_type_bit_width = sizeof(integral_type) * CHAR_BIT;\n\nstruct adc_scaled\n{\n  virtual integral_type read() = 0;\n};\n\nstruct adc_float\n{\n  virtual float read() = 0;\n};\n\nstruct adc_piecewise\n{\n  struct read_t\n  {\n    integral_type value;\n    std::uint8_t bit_width;\n  };\n  virtual read_t read() = 0;\n};\n\nstruct adc_piecewise_max\n{\n  struct read_t\n  {\n    integral_type value;\n    integral_type full_scale;\n  };\n  virtual read_t read() = 0;\n};\n\nstruct adc_split\n{\n  virtual std::uint8_t bit_width() = 0;\n  virtual integral_type read() = 0;\n};\n\nconstexpr std::uint8_t test_bit_width = 7;\nstd::uint16_t adc_data = 31;\n\ntemplate&lt;std::unsigned_integral int_t, std::size_t bit_width&gt;\nconstexpr int_t upscale(int_t p_value)\n{\n  constexpr std::size_t resultant_bit_width = sizeof(int_t) * CHAR_BIT;\n  static_assert(bit_width &gt; 0 &amp;&amp; bit_width &lt;= resultant_bit_width,\n                \"Bit width must be between 1 and 32\");\n  // If already 32 bits, return as-is\n  if constexpr (bit_width == resultant_bit_width) {\n    return p_value;\n  }\n\n  // Create mask for the input bits\n  constexpr int_t mask = (1u &lt;&lt; bit_width) - 1;\n\n  // Calculate number of iterations needed (ceiling(32/bit_width) - 1)\n  constexpr auto iterations =\n    (resultant_bit_width + bit_width - 1) / bit_width - 1;\n\n  // Place cleaned input value in MSB position\n  constexpr auto shift_distance = resultant_bit_width - bit_width;\n  int_t result = (p_value &amp; mask) &lt;&lt; shift_distance;\n\n  // Replicate the pattern for the calculated number of iterations\n  for (auto i = 0U; i &lt; iterations; ++i) {\n    result |= (result &gt;&gt; bit_width);\n  }\n  return result;\n}\n\nstruct adc_scaled_impl : public adc_scaled\n{\n  integral_type read() override\n  {\n    return upscale&lt;integral_type, test_bit_width&gt;(adc_data);\n  }\n};\n\nstruct adc_piecewise_impl : public adc_piecewise\n{\n  read_t read() override\n  {\n    return { adc_data, test_bit_width };\n  }\n};\n\nstruct adc_split_impl : public adc_split\n{\n  std::uint8_t bit_width() override\n  {\n    return test_bit_width;\n  }\n\n  integral_type read() override\n  {\n    return adc_data;\n  }\n};\n\nstruct adc_float_impl : public hal::adc_float\n{\n  float read() override\n  {\n    constexpr auto max = (1 &lt;&lt; test_bit_width) - 1;\n    return float(adc_data) / max;\n  }\n};\n\nstruct adc_piecewise_max_impl : public adc_piecewise_max\n{\n  read_t read() override\n  {\n    constexpr auto max = (1 &lt;&lt; test_bit_width) - 1;\n    return { adc_data, max };\n  }\n};\n}  // namespace hal\n\nconstexpr std::uint16_t max_degrees = 360;\nconstexpr std::uint16_t u16_max = std::numeric_limits&lt;std::uint16_t&gt;::max();\nconstexpr auto shift_amount = hal::integral_type_bit_width - 16;\n\n[[gnu::noinline]]\nstd::uint32_t scale_to_degrees(hal::adc_scaled&amp; impl)\n{\n  auto const response = impl.read();\n  auto const response_u16 =\n    static_cast&lt;std::uint16_t&gt;(response &gt;&gt; shift_amount);\n  auto const up_scaled = response_u16 * max_degrees;\n  auto const final_value = up_scaled / u16_max;\n  return final_value;\n}\n\n[[gnu::noinline]]\nstd::uint32_t scale_to_degrees(hal::adc_piecewise&amp; impl)\n{\n  auto const [response, bit_width] = impl.read();\n  auto const max_scale = (1 &lt;&lt; bit_width) - 1;\n  auto const up_scaled = response * max_degrees;\n  auto const final_value = up_scaled / max_scale;\n  return final_value;\n}\n\n[[gnu::noinline]]\nstd::uint32_t scale_to_degrees(hal::adc_split&amp; impl)\n{\n  auto const bit_width = impl.bit_width();\n  auto const response = impl.read();\n  auto const max_scale = (1 &lt;&lt; bit_width) - 1;\n  auto const up_scaled = response * max_degrees;\n  auto const final_value = up_scaled / max_scale;\n  return final_value;\n}\n\n[[gnu::noinline]]\nstd::uint32_t scale_to_degrees(hal::adc_piecewise_max&amp; impl)\n{\n  auto const [response, max_scale] = impl.read();\n  auto const up_scaled = response * max_degrees;\n  auto const final_value = up_scaled / max_scale;\n  return final_value;\n}\n\n[[gnu::noinline]]\nstd::uint32_t scale_to_degrees(hal::adc_float&amp; impl)\n{\n  auto const response = impl.read();\n  auto const final_value = response * max_degrees;\n  return final_value;\n}\n\n[[gnu::noinline]]\nstd::uint32_t scale_to_degrees2(hal::adc_split&amp; impl)\n{\n  auto bit_width = impl.bit_width();\n  auto response = impl.read();\n\n  if (bit_width &gt; 16) {\n    auto const shift_amount = bit_width - 16;\n    response &gt;&gt;= shift_amount;\n    bit_width = 16;\n  }\n\n  auto const max_scale = (1 &lt;&lt; bit_width) - 1;\n  auto const up_scaled = response * max_degrees;\n  auto const final_value = up_scaled / max_scale;\n  return final_value;\n}\n\ntemplate&lt;typename T&gt;\nvoid use(T&amp;&amp; t)\n{\n  __asm__ __volatile__(\"\" ::\"g\"(t));\n}\n\nvoid application()\n{\n  using namespace std::chrono_literals;\n  constexpr auto sample_count = 2'000'000;\n\n  // Calling `value()` on the optional resources will perform a check and if the\n  // resource is not set, it will throw a std::bad_optional_access exception.\n  // If it is set, dereference it and store the address in the references below.\n  // When std::optional&lt;T&amp;&gt; is in the standard, we will change to use that.\n  auto&amp; led = *resources.status_led.value();\n  auto&amp; clock = *resources.clock.value();\n  auto&amp; console = *resources.console.value();\n\n  hal::print(console, \"Starting ADC benchmark!\\n\");\n\n  hal::adc_piecewise_impl piecewise;\n  auto const start_piecewise = clock.uptime();\n  for (int i = 0; i &lt; sample_count; i++) {\n    auto const value = scale_to_degrees(piecewise);\n    use(value);\n  }\n  auto const volatile end_piecewise = clock.uptime();\n  auto const volatile delta_piecewise = end_piecewise - start_piecewise;\n\n  auto const volatile start_split = clock.uptime();\n  hal::adc_split_impl split;\n  for (int i = 0; i &lt; sample_count; i++) {\n    auto const value = scale_to_degrees(split);\n    use(value);\n  }\n  auto const volatile end_split = clock.uptime();\n  auto const volatile delta_split = end_split - start_split;\n\n  auto const start_scaled = clock.uptime();\n  hal::adc_scaled_impl scaled;\n  for (int i = 0; i &lt; sample_count; i++) {\n    auto const value = scale_to_degrees(scaled);\n    use(value);\n  }\n  auto const volatile end_scaled = clock.uptime();\n  auto const volatile delta_scaled = end_scaled - start_scaled;\n\n  auto const start_max = clock.uptime();\n  hal::adc_piecewise_max_impl max;\n  for (int i = 0; i &lt; sample_count; i++) {\n    auto const value = scale_to_degrees(max);\n    use(value);\n  }\n  auto const volatile end_max = clock.uptime();\n  auto const volatile delta_max = end_max - start_max;\n\n  auto const volatile start_float = clock.uptime();\n  hal::adc_float_impl float_adc;\n  for (int i = 0; i &lt; sample_count; i++) {\n    auto const value = scale_to_degrees(float_adc);\n    use(value);\n  }\n  auto const volatile end_float = clock.uptime();\n  auto const volatile delta_float = end_float - start_float;\n\n  hal::print&lt;64&gt;(console, \"   start_scaled = %\" PRIu64 \"\\n\", start_scaled);\n  hal::print&lt;64&gt;(console, \"     end_scaled = %\" PRIu64 \"\\n\", end_scaled);\n  hal::print&lt;64&gt;(console, \"start_piecewise = %\" PRIu64 \"\\n\", start_piecewise);\n  hal::print&lt;64&gt;(console, \"  end_piecewise = %\" PRIu64 \"\\n\", end_piecewise);\n  hal::print&lt;64&gt;(console, \"    start_split = %\" PRIu64 \"\\n\", start_split);\n  hal::print&lt;64&gt;(console, \"      end_split = %\" PRIu64 \"\\n\", end_split);\n  hal::print&lt;64&gt;(console, \"      start_max = %\" PRIu64 \"\\n\", start_max);\n  hal::print&lt;64&gt;(console, \"        end_max = %\" PRIu64 \"\\n\", end_max);\n  hal::print&lt;64&gt;(console, \"    start_float = %\" PRIu64 \"\\n\", start_float);\n  hal::print&lt;64&gt;(console, \"      end_float = %\" PRIu64 \"\\n\", end_float);\n  hal::print(console, \"\\n\");\n  hal::print&lt;64&gt;(console, \"delta_piecewise = %\" PRIu64 \"\\n\", delta_piecewise);\n  hal::print&lt;64&gt;(console, \"   delta_scaled = %\" PRIu64 \"\\n\", delta_scaled);\n  hal::print&lt;64&gt;(console, \"    delta_split = %\" PRIu64 \"\\n\", delta_split);\n  hal::print&lt;64&gt;(console, \"      delta_max = %\" PRIu64 \"\\n\", delta_max);\n  hal::print&lt;64&gt;(console, \"    delta_float = %\" PRIu64 \"\\n\", delta_float);\n\n  hal::print(console, \"Resetting in 10s!\\n\");\n  hal::delay(clock, 10s);\n\n  resources.reset();\n}\n</code></pre> <p>All tests executed on an stm32f103c8 which featues a Cortex-M3 processor which does not include a floating point unit. Using GCC 12.3.1.</p> <p>Built using the following commands:</p> <pre><code># Defaults to min size build\nconan build . -pr stm32f103c8 -pr arm-gcc-12.3\n# For release\nconan build . -pr stm32f103c8 -pr arm-gcc-12.3 -s build_type=Release\n</code></pre> <pre><code>nm --demangle --size-sort build/stm32f103c8/MinSizeRel/app.elf | grep \"::read\"\n0000000c W hal::adc_split_impl::read()\n00000014 W hal::adc_piecewise_max_impl::read()\n00000018 W hal::adc_scaled_impl::read()\n0000001c W hal::adc_float_impl::read()\n00000024 W hal::adc_piecewise_impl::read()\n\nnm --demangle --size-sort build/stm32f103c8/MinSizeRel/app.elf | grep \"::bit_width\"\n00000004 W hal::adc_split_impl::bit_width()\n</code></pre> <p>Above we see that the scaled is in the middle in terms of code size. But we will go over why this isn't an issue in the next block.</p> <pre><code>nm --demangle --size-sort build/stm32f103c8/MinSizeRel/app.elf | grep scale_to_degrees\n00000018 T scale_to_degrees(hal::adc_scaled&amp;)\n0000001a T scale_to_degrees(hal::adc_float&amp;)\n0000001c T scale_to_degrees(hal::adc_piecewise_max&amp;)\n00000024 T scale_to_degrees(hal::adc_piecewise&amp;)\n00000026 T scale_to_degrees(hal::adc_split&amp;)\n00000036 T scale_to_degrees2(hal::adc_split&amp;)\n</code></pre> <p>In a minimum sized build, using <code>adc_scaled</code> results in the smallest code size for the same results. In this case, the <code>adc_scaled::read</code> API takes up more memory than the cost of its usage. We believe that it makes sense to optimize for the usages as those are more likely to be more numerous than ADC implementations.</p> <pre><code> nm --demangle --size-sort build/stm32f103c8/Release/app.elf | grep \"::read\"\n0000000c W hal::adc_split_impl::read()\n00000014 W hal::adc_piecewise_max_impl::read()\n00000018 W hal::adc_scaled_impl::read()\n0000001c W hal::adc_float_impl::read()\n00000024 W hal::adc_piecewise_impl::read()\n\nnm --demangle --size-sort build/stm32f103c8/Release/app.elf | grep scale_to_degrees\n00000024 t scale_to_degrees(hal::adc_piecewise&amp;) (.constprop.0)\n00000024 t scale_to_degrees(hal::adc_piecewise_max&amp;) (.constprop.0)\n00000024 t scale_to_degrees(hal::adc_split&amp;) (.constprop.0)\n00000028 t scale_to_degrees(hal::adc_float&amp;) (.constprop.0)\n0000002c t scale_to_degrees(hal::adc_scaled&amp;) (.constprop.0)\n\n00000040 T scale_to_degrees(hal::adc_scaled&amp;)\n00000044 T scale_to_degrees(hal::adc_piecewise_max&amp;)\n00000044 T scale_to_degrees(hal::adc_float&amp;)\n0000004c T scale_to_degrees(hal::adc_piecewise&amp;)\n0000005c T scale_to_degrees(hal::adc_split&amp;)\n00000088 T scale_to_degrees2(hal::adc_split&amp;)\n</code></pre> <p>In the above Release build, the results are similar. <code>(.constprop.0)</code> in GCC means that the symbol is a duplicate of another function but optimized to perform around the same. In the optimized code scaled fairs the worst by an additional 8 bytes compared to the lowest code size functions. But on the other hand, for the original symbol, the scaled ADC code is the smallest in terms of code size.</p> <pre><code># Release Build Cycles\n\ndelta_piecewise = 12000075\n   delta_scaled = 12000084\n    delta_split = 12000084\n      delta_max = 12000081\n    delta_float = 12000443\n\n# Min Size Build Cycles\ndelta_piecewise = 156000044\n   delta_scaled = 134000059\n    delta_split = 176000052\n      delta_max = 136000052\n    delta_float = 844000052\n</code></pre> <p>As you can see the cycles for almost all of these benchmarks are almost identical. So much so that there isn't really a clear winner. Some seem to perform worse off in specific builds. But overall they are about the same. And if all else is the same in performance, then code size should be the deciding factor.</p>"},{"location":"education/architecture/","title":"Microcontroller Architecture","text":"<p>Coming soon...</p>"},{"location":"education/bitmasking/","title":"The Art of Bit Masking","text":"<p>Coming soon...</p>"},{"location":"education/canbus/","title":"CAN BUS: Controller Area Network Bus","text":"<p>Warning</p> <p>This document describes the CAN for libhal 5.0.0 which is not available yet.</p> <p>Welcome to the libhal controller area network (CAN) tutorial. CAN BUS is used as a reliable broadcast communication.</p>"},{"location":"education/canbus/#learning-about-can-bus","title":"Learning about CAN BUS","text":"<p>To learn more about CAN BUS we recommend these online resources:</p> <ul> <li>\ud83c\udfa5 CAN Bus: Serial Communication - How It Works?   11m 24s video going over the basics of CAN BUS. It does not go over message   ID arbitration which is quite important to understand with CAN BUS, but not necessary to use CAN APIs.</li> <li>\ud83d\udcc4 Introduction to the Controller Area Network (CAN) by Texas Instruments:   A fully featured document going over most of the important aspects of CAN   bus. You'll learn everything you need to know about CAN with this document.</li> </ul>"},{"location":"education/canbus/#can-interfaces-and-how-to-use-them","title":"CAN interfaces and how to use them","text":"<p>libhal breaks CAN up into multiple interfaces and abstractions.</p> <ul> <li><code>hal::can_transceiver</code>: Provides APIs for sending can messages and receiving   messages.</li> <li><code>hal::can_message_interrupt</code>: Provides APIs for setting an interrupt when a   message is received.</li> <li><code>hal::can_bus_manager</code>: Provides APIs for managing the state of the can bus   hardware.</li> <li>Standard can filters:<ul> <li><code>hal::can_identifier_filter</code>: Provides a means to filter can bus messages   via a message ID.</li> <li><code>hal::can_mask_filter</code>: Provides a means to filter can bus messages via an   message ID and mask combo.</li> <li><code>hal::can_range_filter</code>: Provides a means to filter can bus messages via a   range of can message IDs</li> </ul> </li> <li>Extended can filters (same as standard but for extended message IDs):<ul> <li><code>hal::can_extended_identifier_filter</code></li> <li><code>hal::can_extended_mask_filter</code></li> <li><code>hal::can_extended_range_filter</code></li> </ul> </li> </ul> <p>The CAN peripheral functionality is broken up across multiple interfaces in order to enable greater flexibility for applications, device drivers, and the various capabilities of hardware. For example, the number of filters of each type can vary wildly between different devices, but the predominately fit in these three categories.</p>"},{"location":"education/canbus/#the-halcan_message","title":"The <code>hal::can_message</code>","text":"<p>The <code>hal::can_message</code> struct contains all of the information stored within a typical message. The object <code>hal::can_message</code> represents a standard CAN message in libhal. It provides all of the information you'd need in a typical CAN message. It is used for sending and receiving messages on the can bus. Note that the remote request and extended fields utilize bits 29th and 30th, respectively, within the of the 32-bit <code>id_flags</code> field. The 31st bit is reserved for now and must remain 0.</p> <p>The can message and its APIs are defined below.</p> <pre><code>struct can_message\n{\n  /**\n   * @brief Memory containing the ID and remote request and extended flags\n   *\n   * The 31st (final) bit in this mask is reserved and must always be set to 0.\n   * Prefer to use the accessor APIs rather than modify this field directly.\n   *\n   */\n  hal::u32 id_and_flags = 0;\n  /**\n   * @brief Reserve padding memory\n   *\n   * The size of the contents of the is struct are not a multiple of 4 meaning,\n   * on 32-bit and above systems, this struct has a size of 16-bytes where 3 of\n   * the bytes are padding bytes.\n   *\n   * These bytes are reserved and only zeros may be written to them.\n   *\n   */\n  std::array&lt;hal::byte, 3&gt; reserved{};\n  /**\n   * @brief The number of valid elements in the payload\n   *\n   * Can be between 0 and 8. A length value above 8 should be considered\n   * invalid and can be discarded.\n   */\n  uint8_t length = 0;\n  /**\n   * @brief Message data contents\n   *\n   */\n  std::array&lt;hal::byte, 8&gt; payload{};\n\n  /**\n   * @brief Enables default comparison\n   *\n   */\n  constexpr bool operator&lt;=&gt;(can_message const&amp;) const = default;\n\n  /**\n   * @brief Set message ID\n   *\n   * @param p_id - 29 to 11 bit message ID\n   * @return constexpr can_message&amp; - reference to self for function chaining\n   */\n  constexpr can_message&amp; id(hal::u32 p_id);\n  /**\n   * @brief Set the messages remote request flag\n   *\n   * @param p_is_remote_request - set to true to set message as a remote\n   * request.\n   * @return constexpr can_message&amp; - reference to self for function chaining\n   */\n  constexpr can_message&amp; remote_request(bool p_is_remote_request);\n  /**\n   * @brief Set the messages extended flag\n   *\n   * @param p_is_extended - set to true to set this message as an extended\n   * message ID.\n   * @return constexpr can_message&amp; - reference to self for function chaining\n   */\n  constexpr can_message&amp; extended(bool p_is_extended);\n  constexpr hal::u32 id();\n  constexpr bool remote_request();\n  constexpr bool extended();\n};\n</code></pre>"},{"location":"education/canbus/#using-halcan_transceiver","title":"Using <code>hal::can_transceiver</code>","text":"<p>For now, lets set aside how we acquire a <code>hal::can_transceiver</code> and consider what you can do once you have one.</p> <pre><code>u32 baud_rate() = 0;\n</code></pre> <p>This function returns the baud rate in hertz of the CAN BUS. The baud rate represents the communication rate. Common baud rates for CAN BUS are:</p> <ul> <li>100 kHz or Kbit/s</li> <li>125 kHz or Kbit/s</li> <li>250 kHz or Kbit/s</li> <li>500 kHz or Kbit/s</li> <li>800 kHz or Kbit/s</li> <li>1 MHz or Mbit/s</li> </ul> <p>This function exists to ensure that drivers that share a <code>hal::can_transceiver</code> can detect if the baud rate doesn't match a fixed baud rate required by another device on the bus. CAN BUS driver may provide an out-of-interface function for setting the baud rate, but this interface does not allow such control.</p> <p>When a can driver is constructed it is passed a baud rate it should set itself to. If the baud rate cannot be achieved the constructor will throw <code>hal::argument_out_of_domain</code>. Note when setting up a CAN BUS network that every device on the bus must have the same baud rate. The baud rate is not changeable via the <code>hal::can_transceiver</code>.</p> <pre><code>void send(can_message const&amp; p_message) = 0;\n</code></pre> <p>The send API allows a <code>hal::can_transceiver</code> to send/broadcast messages onto the can bus. Simply construct a <code>hal::can_message</code> and pass it to this function and it will make its way. This function will block until the message has been sent over the bus. This means that this API could block a thread if it never gains access over the bus long enough to transmit its message.</p> <pre><code>std::span&lt;can_message const&gt; receive_buffer() = 0;\nstd::size_t receive_cursor() = 0;\n</code></pre> <p><code>hal::can_transceiver</code> are mandated to hold a buffer can messages received over the bus. The user is allowed, at object construction to provide buffer memory for the driver. That buffer is then exposed by the <code>receive_buffer()</code> API to allow applications and drivers to scan it and to find messages meant for them. The buffer returned from <code>receive_buffer()</code> updated as a circular buffer where the <code>receive_cursor()</code> API indicates where the driver's write cursor position is located. Any value returned from <code>receive_cursor()</code> will always work like so:</p> <pre><code>// `can.receive_cursor()` always returns a value between 0 and\n// `can.receive_buffer().size() - 1` meaning the following expression is always\n// well defined. can_message is default initialized to all zeros.\ncan.receive_buffer()[can.receive_cursor()];\n</code></pre> <p>See \u26d3\ufe0f\u200d\ud83d\udca5how interface circular buffers in libhal work.</p> <p>Using the circular buffer APIs directly can be tedious and error prone, so we provide some utility classes in <code>libhal-util/can.hpp</code>.</p>"},{"location":"education/canbus/#halcan_message_finder","title":"<code>hal::can_message_finder</code>","text":"<pre><code>hal::can_transceiver&amp; can = /* ... */;\nhal::can_message_finder reader(can, 0x240);\nstd::optional&lt;hal::can_message&gt; found_message = reader.find();\nif (found_message) {\n  // Do something with the message here...\n} else {\n  // Message has not not been received yet\n}\n</code></pre> <p>This helper class uses the <code>hal::can_transceiver</code> to scan the receive buffer, relative to the position of the receive cursor, and return a copy of that <code>hal::can_message</code> with the matching ID. Find will only find messages received after the construction of the object. If there does not exist a message with the ID specified, <code>std::nullopt</code> is returned. Repeated calls to <code>find()</code> will search for messages with that ID.</p> <p>For example, consider we have the following messages in the receive buffer post object creation:</p> <ol> <li>message 0x015</li> <li>message 0x240</li> <li>message 0x333</li> <li>message 0x240</li> </ol> <p>The first call to find will the message at index 2 and return a copy. The second call will find the message at index 4 and return a copy. If no additional messages are received and <code>find()</code> is called, <code>std::nullopt</code> will be returned.</p> <p>The lifetime of the <code>hal::can_message_reader</code> is bound to the <code>hal::can_transceiver</code> passed to it and must not exceed the lifetime of that <code>hal::can_transceiver</code>.</p>"},{"location":"education/canbus/#halcan_message_reader","title":"<code>hal::can_message_reader</code>","text":"<p>Warning</p> <p>There are some safety concerns with this class returning a span to something that will be modified by the transceiver.</p> <p>Here is an example of how to use the <code>hal::can_message_reader</code>:</p> <pre><code>hal::can_transceiver&amp; can = /* ... */;\nhal::can_message_reader reader(can);\nstd::optional&lt;std::span&lt;hal::can_message&gt;&gt; new_messages = reader.read();\n// Confirm we have messages available\nif (new_messages) {\n  // Since we have some new messages, we can iterate over them and print out\n  // their ID and length.\n  for (auto const&amp; message : *new_messages) {\n    hal::print&lt;64&gt;(\"{ id: %\" PRIu32 \", length: %\" PRIu8 \"}\",\n                   message.id(),\n                   message.length);\n  }\n}\n</code></pre> <p>The lifetime of the <code>hal::can_message_reader</code> is bound to the <code>hal::can_transceiver</code> passed to it and must not exceed the lifetime of that <code>hal::can_transceiver</code>.</p>"},{"location":"education/canbus/#can-bus-device-manager","title":"CAN BUS device manager","text":"<p>In order to acquire implementations of the interfaces above, a can device manager object should be created. How this object is created depends on your platforms. As an example lets consider <code>stm32f103</code>:</p> <pre><code>namespace hal::stm32f1 {\nclass can {\npublic:\n   // Constructor\n  can(std::span&lt;hal::can_message&gt; p_receive_buffer,\n      can_pins p_pins = can_pins::pa11_pa12,\n      hal::u32 baud_rate = 100_kHz);\n  // The rest...\n}\n}\n\n// Constructing a can object using pins PB9 &amp; PB8 on the stm32f103c8 and\n// setting the bus baud rate to 1MHz.\nstd::array&lt;hal::can_message, 16&gt; receive_buffer;\nhal::stm32f1::can can(receive_buffer, hal::stm32f1::can_pins::pb9_pb8, 1_MHz);\n\n// Acquiring resources from device manager...\n\n// Typically, a can manager object only has a single transceiver, but in some\n// cases they support messages and communication over two ports. The\n// `transceiver` object claims the can object's transceiver resources and\n// attempting to create another will throw the `hal::device_or_resource_busy`\n// exception. The resource is released on the destruction of this object.\nauto transceiver = can.acquire_transceiver();\n\n// The notes about the transceiver apply to the bus manager. There is typically\n// only one and if you attempt to create multiple, the\n// `hal::device_or_resource_busy` exception will be thrown.\nauto bus_manager = can.acquire_bus_manager();\n\nauto id_filter_0 = can.acquire_id_filter();\nauto id_filter_1 = can.acquire_id_filter();\nauto id_filter_2 = can.acquire_id_filter();\nauto id_filter_3 = can.acquire_id_filter();\n</code></pre> <p>The stm32f103 only has a single CAN peripheral. Here we have to provide which CAN TX &amp; RX pins we want to use. Next we select the baud rate in terms of frequency.</p> <pre><code>// Constructing a can object\nhal::stm32f1::can can(hal::stm32f1::can_pins::pb9_pb8, 1_MHz);\n\n// Acquire a transceiver from the can manager object.\nauto transceiver = can.acquire_transceiver();\n\n// Attempting to acquire a 2nd transceiver \u274c throws\n// hal::device_or_resource_busy because can_transceiver is still around. If\n// `can_transceiver` is destroyed, then this API can be used to acquire a new\n// transceiver.\nauto transceiver2 = can.acquire_transceiver(); // \u274c\n\n// Acquire a mask filter\nauto mask_filter0 = can.acquire_mask_filter();\n// acquire mask filters until there are no more filter resources available...\nauto mask_filterN = can.acquire_mask_filter();  // \u274c throw\n</code></pre> <p>If a device runs out of a the resources needed to generate an implementation such as a filter or bus manager, that API throws <code>hal::device_or_resource_busy</code>.</p> <p>CAN devices have a limited number of filters, each with a specific set of resources assigned to it. When acquiring a filter, the object returned manages, controls, and holds onto these resources for the duration of the filter's lifetime, allowing them to be reused after the filter object is destroyed. This means that the same resources can be used for multiple filters, but only one filter can use a particular set of resources at any given time. Here is a demonstration of what that would look like, assuming we only had 2 mask filters:</p> <pre><code>// \u2705\u2705 means that we have two filters available\n// \ud83d\udfe1\u2705 means that one mask has been taken and the other is available\n\n// START: \u2705\u2705\nauto mask_filter0 = can.acquire_mask_filter(); // \ud83d\udfe1\u2705\n{\n   auto mask_filter_scoped = can.acquire_mask_filter(); // \ud83d\udfe1\ud83d\udfe1\n} // mask_filter_scoped resources freed \ud83d\udfe1\u2705\nauto mask_filter1 = can.acquire_mask_filter(); // \ud83d\udfe1\ud83d\udfe1\n// filters are exhausted and thus trying to create mask_filter2 results in an\n// exception being thrown!\nauto mask_filter2 = can.acquire_mask_filter(); // \ud83d\udfe1\ud83d\udfe1\u274c\n</code></pre> <p>The same goes for acquiring a <code>hal::can_bus_manager</code>. Typically there is only one and attempting to make two will throw an exception.</p>"},{"location":"education/canbus/#usage-in-device-drivers","title":"Usage in device drivers","text":"<p>A typical device drivers that uses can bus interfaces will accept a <code>hal::can_transceiver</code> and a filter. The device driver should capture the <code>hal::can_transceiver</code> for future use and use the filter to allow messages it expects to receive over the bus. Such a class would look like this:</p> <pre><code>class servo_controller {\npublic:\n  servo_controller(hal::can_transceiver&amp; p_transceiver,\n                 hal::can_identifier_filter&amp; p_filter):\n                 m_can(&amp;p_transceiver) {\n    p_filter.allow(servo_message_id);\n    // Do the rest...\n  }\n\n  void send_position(hal::u8 p_position) {\n    hal::can_message payload;\n    payload.length = 1;\n    // Assume: 0 means 0deg &amp; 255 means 360deg\n    payload.payload[0] = p_position;\n    payload.id(servo_message_id)\n      .extended(false)\n      .remote_request(false);\n\n    m_can-&gt;send(payload);\n  }\n\nprivate:\n  constexpr hal::u32 servo_message_id = 0x050;\n\n  hal::can_transceiver* m_can;\n};\n</code></pre> <p>In general, filters do not need to be captured. Filters can be set at driver construction and then given back to the caller. Capturing a filter is only necessary if the filter will have its ID modified at runtime.</p> <p>The example above assumes that the driver only ever needs to write can messages and never needs to receive them.</p>"},{"location":"education/canbus/#interfaces-to-avoid","title":"Interfaces to Avoid","text":"<p>Device drivers should not accept <code>hal::can_bus_manager</code> or <code>hal::can_message_interrupt</code> for any API. These interfaces are reserved for use by applications, and accepting them could lead to disruptions in other drivers and potentially the entire system. Additionally, <code>hal::can_message_interrupt</code> cannot be shared because it can only support a single interrupt callback, meaning that if two drivers were provided this interface, only the last one to set the callback would be functional, while the previous callback would be discarded.</p>"},{"location":"education/canbus/#receiving-messages","title":"Receiving messages","text":"<p>When you want to also receive messages over CAN prefer to capture the <code>hal::can_transceiver</code> via <code>hal::can_message_finder</code>. It will supply the memory to capture the <code>hal::can_transceiver</code> and provide the necessary memory to track new incoming messages from the <code>hal::can_transceiver</code>.</p> <pre><code>class battery_sensor {\npublic:\n  battery_sensor(hal::can_transceiver&amp; p_transceiver,\n                 hal::can_identifier_filter&amp; p_filter):\n                 m_can(p_transceiver, battery_response_message_id) {\n    p_filter.allow(battery_response_message_id);\n    // Do the rest...\n  }\n\n  void request_battery_capacity() {\n    hal::can_message payload;\n\n    payload.id(battery_message_id)\n      .extended(false)\n      .remote_request(false);\n    payload.length = 0;\n\n    m_can.transceiver().send(payload);\n  }\n\n  std::optional&lt;float&gt; get_battery_capacity() {\n    auto message = m_can.find();\n    if (message &amp;&amp; message.length == 1) {\n      return float(message.payload[0]) / 255.0f;\n    }\n    return std::nullopt;\n  }\n\nprivate:\n  constexpr hal::u32 battery_message_id = 0x050;\n  constexpr hal::u32 battery_response_message_id = 0x050;\n\n  hal::can_message_finder m_can;\n};\n</code></pre> <p>The transceiver can be accessed using the <code>transceiver()</code> API.</p>"},{"location":"education/canbus/#selecting-the-right-filter-type","title":"Selecting the right filter type","text":"<ol> <li>Select <code>hal::can_identifier_filter</code> if the device driver only needs to    filter a single standard message ID.</li> <li>Select <code>hal::can_extended_identifier_filter</code> if the device driver only needs    to filter a single extended message ID.</li> <li>Select <code>hal::can_range_filter</code> if the device driver expects to see messages    in a range of standard message IDs.</li> <li>Select <code>hal::can_extended_range_filter</code> if the device driver expects to see    messages in a range of standard message IDs.</li> <li>Select <code>hal::can_mask_filter</code> if the device driver expects to see messages    that fit a standard identifier with some bits that can change. In general,    this filter type isn't particular useful for device drivers.</li> <li>Select <code>hal::can_extended_mask_filter</code> if the device driver expects to see    messages that fit an extended identifier with some bits that can change. In    general, this filter type isn't particular useful for device drivers.</li> </ol>"},{"location":"education/canbus/#filter-adaptors","title":"Filter adaptors","text":"<p>Can peripherals may not provide all of the filters needed by device drivers or application. In these cases, we can use an adaptor from <code>libhal-util</code> to convert one filter to another.</p>"},{"location":"education/canbus/#range-to-identifier-filter","title":"Range to identifier filter","text":"<p>libhal provides <code>hal::range_to_identifier_can_adaptor</code> which can take a <code>hal::can_range_filter</code> and generate multiple <code>hal::can_identifier_filters</code>. This can be beneficial when the set of IDs is contiguous OR close enough together.</p> <pre><code>hal::can_range_filter&amp; range_filter = /* ... */;\nhal::range_to_identifier_can_adaptor id_generator(range_filter);\nauto id_filter_1 = id_generator.create();\nauto id_filter_2 = id_generator.create();\nauto id_filter_3 = id_generator.create();\n\nid_filter_1.allow(0x111); // range 0x111 \u2194 0x111\nid_filter_2.allow(0x112); // range 0x111 \u2194 0x112\nid_filter_3.allow(0x117); // range 0x111 \u2194 0x117\nid_filter_3.allow(0x110); // range 0x110 \u2194 0x115\nid_filter_3.allow(0x116); // range 0x110 \u2194 0x115 (no change)\n</code></pre> <p>Each id generated links back to the <code>hal::range_to_identifier_can_adaptor</code> object. They are bound by its lifetime. Each time a filter calls <code>allow()</code>, it expands the range to fit the max and min values passed previously.</p> <p>The filter is not as useful if the range between IDs is large and there are messages within that ID range.</p> <p>There exist an equivalent for extended IDs.</p>"},{"location":"education/canbus/#mask-to-identifier-filter","title":"Mask to identifier filter","text":"<p>libhal provides <code>hal::mask_to_identifier_can_adaptor</code> which can take a <code>hal::can_mask_filter</code> and generate multiple <code>hal::can_identifier_filters</code>.</p> <p>TBD...</p>"},{"location":"education/canbus/#making-a-can-driver","title":"Making a CAN driver","text":"<p>TBD...</p>"},{"location":"education/dac/","title":"DAC: Digital to Analog Convert","text":"<p>Coming soon...</p>"},{"location":"education/dma/","title":"DMA: Direct Memory Access","text":"<p>Coming soon...</p>"},{"location":"education/embedded_systems/","title":"Introduction to Embedded Systems","text":"<p>Coming soon...</p>"},{"location":"education/gpio/","title":"GPIO: General Purpose Input/Output","text":"<p>Coming soon...</p>"},{"location":"education/i2c/","title":"I2C: Inter-Integrated Circuit","text":"<p>Welcome to the libhal i2c tutorial. This article will go over:</p> <ul> <li>What i2c is</li> <li>libhal's i2c interface &amp; basic usage</li> <li>Utility functions for i2c</li> <li>How to use drivers that use i2c</li> <li>How to write an i2c device driver</li> <li>High level steps to write an i2c peripheral driver</li> </ul> <p>This tutorial only works with i2c controllers (also known as masters). Target (or slave) i2c will not be discussed here.</p>"},{"location":"education/i2c/#what-is-i2c","title":"What is i2c?","text":"<p>In order to proceed to the rest of this article, you must understand the fundamentals of i2c and how it works. Rather than rehash what is already out there, please read one of the following:</p> <ul> <li>\ud83c\udfa5 Understanding I2C by Rohde Schwarz: 10min 57sec A great video describing how I2C works.</li> <li>\ud83d\udcc4 Sparkfun I2C: A quick and   concise article that provides enough information to be ready for the rest of   this tutorial.</li> <li>\ud83c\udf10 i2c-bus.org: Website dedicated to documenting   how i2c works. If you want to get into the depths of I2C, this website does a   great job of going into how the I2C protocol works as well as some of its   other less known features such as multi-controller and clock stretching.</li> <li>\ud83d\udcc4 TI's A Basic Guide to I2C:   Detailed and contains examples of how an i2c transaction works with concrete   examples with actual i2c device register maps.</li> </ul>"},{"location":"education/i2c/#hali2c-interface-and-how-to-use-it","title":"<code>hal::i2c</code> interface and how to use it","text":"<p>The interface that provides APIs for i2c communication is <code>hal::i2c</code>. It provides two APIs <code>configure</code> and <code>transaction</code>.</p>"},{"location":"education/i2c/#creating-an-i2c-object","title":"Creating an i2c object","text":"<p>Each platform that supports i2c will have their own i2c driver. Typically the name goes like: <code>hal::&lt;platform_name&gt;::i2c</code> or <code>hal::&lt;platform_name&gt;::dma_i2c</code>.</p> <pre><code>// LPC40xx i2c driver for i2c bus 2\nhal::lpc40::i2c i2c(2);\n// stm32f1xx i2c driver for i2c bus 1\nhal::stm32f1::i2c i2c(1);\n</code></pre> <p>To know what your platform has available you'll need to look at the API docs and search for <code>i2c</code> or look at what inherits <code>hal::i2c</code>.</p> <p>Warning</p> <p>The API docs are not available currently. Consider looking at the source code of the libraries for files with the name <code>i2c.hpp</code> or <code>dma_i2c.hpp</code> to find your platform's i2c drivers.</p>"},{"location":"education/i2c/#using-hali2cconfigure","title":"Using <code>hal::i2c::configure</code>","text":"<p>This API takes a const reference to the <code>hal::i2c::settings</code> structure as an input. It currently only contains a single field which is the <code>clock_rate</code>. This field allows the application developer or drivers to change the frequency that the i2c peripheral communicates at.</p> <pre><code>struct settings\n{\n  /**\n   * @brief The serial clock rate in hertz.\n   *\n   */\n  hertz clock_rate = 100.0_kHz;\n};\n</code></pre> <p>The <code>clock_rate</code> field defaults to 100kHz which is the standard frequency for i2c. The majority of i2c devices will support 100kHz which makes it a decent default. Fast mode i2c can operate at 400kHz. Fast mode plus can operate at 1MHz. High speed mode can go up to 3.4MHz. 100kHz to 1MHz are the most common frequency ranges.</p> <p>What value should you set this to? In general, you want your communication to be as fast as possible so your code isn't stuck waiting for the transfer to happen. The higher the frequency the less time it takes to transmit or receive data. But if your bus has multiple devices with different max frequencies, you MUST choose the frequency of the device with the lowest frequency. This is due to how all devices must look at the same i2c bus lines to determine if they have been selected for a transaction, and if the frequency is too fast for them to sample, then they will either not respond or potentially respond incorrectly, leading to errors such as \"device not found\" or I/O errors.</p>"},{"location":"education/i2c/#using-hali2ctransaction","title":"Using <code>hal::i2c::transaction</code>","text":"<p>In order to communicate with an i2c you must perform an i2c transaction where you specify the device you want to talk to, the data you want to send to it and the amount of data you want back from it. There are 3 types of transactions:</p> <ol> <li><code>Write</code>: Where the controller writes to the device and get nothing back in return.</li> <li><code>Read</code>: Where the controller reads from a device.</li> <li><code>Write-then-Read</code>: Where the controller performs a write operation then performs a read operation.</li> </ol> <p>Info</p> <p>Most i2c devices will use <code>Write</code> and <code>Write-then-Read</code> operations. A lone <code>Read</code> operation is very rare. Typically write operations are used to write data or configuration settings to a device. <code>Write-then-read</code> operations are used for reading data from most devices. The write phase of the operation <code>Write-then-read</code> is used to tell the device \"what\" data you want to read, then performing a read operation to read the data back out. The \"what\" for most devices is usually an address of a register you want to read. Most i2c devices are memory mapped in this way.</p> <p>Some devices cannot support <code>Write-then-Read</code> and thus they need the <code>Write</code> and <code>Read</code> operations to be separate.</p> <p>An example of a device with a <code>Read</code> operation without a <code>Write</code> would be the i2c mux tca9548a. In this case, there is only 1 register you can write to or read from, thus the \"what\" for each transaction is just that register.</p> <pre><code>void transaction(hal::byte p_address,\n                 std::span&lt;hal::byte const&gt; p_data_out,\n                 std::span&lt;hal::byte&gt; p_data_in,\n                 hal::function_ref&lt;hal::timeout_function&gt; p_timeout)\n</code></pre> <p>Lets break down each of the input parameters:</p> <ul> <li>p_address: is a byte sized parameter that represents the 7-bit i2c   address of the device you want to communicate with. To perform a transaction   with a 10-bit address, this parameter must be the address upper byte of the   10-bit address OR'd with <code>0b1111'0000</code> (the 10-bit address indicator). The   lower byte of the address must be contained in the first byte of the   <code>p_data_out</code> span buffer.</li> <li>p_data_out: data to be written to the addressed device. Set this to a   span with <code>size() == 0</code> in order to skip writing.</li> <li>p_data_in: buffer to store read data from the addressed device. Set   this to a span with <code>size() == 0</code> in order to skip reading.</li> <li>p_timeout: A function that must throw the type <code>hal::timed_out</code> or a   derivation of <code>hal::timed_out</code> when the deadline for this operation has   exceeded its time. The i2c driver implementation must poll this function to   ensure it is within the function's deadline.</li> </ul> <p>Question</p> <p>Unfamiliar with C++'s <code>std::span</code> standard library? Read the article How to use std::span from C++20 to learn!</p> <p>Here is what a <code>Write-then-Read</code> transaction looks like:</p> <pre><code>#include &lt;array&gt;\n#include &lt;libhal/i2c.hpp&gt;\n\nvoid write_then_read(hal::i2c&amp; i2c) {\n  std::array&lt;hal::byte, 1&gt; status_register_address = { 0x01 };\n  std::array&lt;hal::byte, 1&gt; status_register_contents{};\n  i2c.transaction(0x14,\n                  status_register_address,\n                  status_register_contents,\n                  hal::never_timeout());\n}\n</code></pre> <p>In this scenario we want to talk to the device with address <code>0x14</code>, the first parameter. We pass the array <code>status_register_address</code> which implicitly converts into a <code>std::span</code> as the second parameter. In this case the value of <code>0x01</code> is the address of the register we want to read from. Next is the <code>status_register_contents</code> array which has size 1. This will cause the i2c read to read back a single byte from this register. If multiple bytes are needed for the read operation, then the size of the array can be increased to read additional bytes. Finally, the last argument for the timeout function is <code>hal::never_timeout()</code> which returns a timeout function that never throws <code>hal::timed_out</code>. This is useful for devices that do not perform clock stretching. For <code>Write-then-Read</code> transactions, the i2c implementation must handle automatically performing the write operation first, then performing a restart-read operation.</p> <p>The purpose of <code>p_timeout</code> is to be used when a target device supports clock stretching. In these situations, it may not be well defined how long the device will hold the clock lines down for, which can stall a controller if its waiting for the i2c bus to come back online before the code can proceed. This argument function allows an escape hatch to return control from the i2c implementation back to the application or driver code.</p> <p>Warning</p> <p>NOTE from Khalil: The <code>p_timeout</code> approach is silly. Yes, its helpful for clock stretching case, but its very rare to find devices that use clock stretching. If most devices supported clock stretching, then having the API take a timeout callback would be acceptable. But its so rare that most code is just passing <code>hal::never_timeout()</code>. <code>p_timeout</code> is also problematic for i2c devices that use DMA. Because this has to be polled, when should the DMA code be running? It could just spin while it waits for DMA to finish processing, but we loose out on the capability to put the device to sleep or switch tasks by using the polling option. Overall, it is likely in the future that we will either make <code>hal::i2c_v2</code> with an <code>hal::io_waiter</code> in place of the <code>p_timeout</code> or eliminate the parameter all together and recommend that i2c implementations accept an <code>io_waiter</code> as an input parameter. The outcome has yet to be decided.</p> <p>Here is what a <code>Write</code> transaction looks like:</p> <pre><code>#include &lt;array&gt;\n#include &lt;libhal/i2c.hpp&gt;\n\nvoid write_then_read(hal::i2c&amp; i2c) {\n  std::array&lt;hal::byte, 2&gt; config_register_payload = { 0x02, 0xA2 };\n  i2c.transaction(0x14,\n                  config_register_payload,\n                  {},\n                  hal::never_timeout());\n}\n</code></pre> <p>You can replace the span with just <code>{}</code> and C++ will deduce and brace initialize the span using its default constructor, which is a span of size 0 and pointer addressed to <code>nullptr</code>. By setting the <code>p_data_in</code> to an empty span, the transaction will only perform a write operation.</p> <p>Here is what a <code>Read</code> transaction looks like:</p> <pre><code>#include &lt;array&gt;\n#include &lt;libhal/i2c.hpp&gt;\n\nvoid write_then_read(hal::i2c&amp; i2c) {\n  std::array&lt;hal::byte, 4&gt; buffer{};\n  i2c.transaction(0x14,\n                  {},\n                  buffer,\n                  hal::never_timeout());\n}\n</code></pre> <p>By setting the <code>p_data_out</code> with an empty span, the transaction will only perform a write operation.</p>"},{"location":"education/i2c/#using-libhal-util","title":"Using <code>libhal-util</code>","text":"<p>Writing <code>i2c.transaction(0x14, {}, buffer, hal::never_timeout());</code> can be long. A shorter option is to use the utilities from <code>libhal-util/i2c.hpp</code>. Take a look at the following code:</p> <pre><code>#include &lt;array&gt;\n#include &lt;libhal/i2c.hpp&gt;\n#include &lt;libhal-util/i2c.hpp&gt;\n\nvoid testing_libhal_util(hal::i2c&amp; i2c) {\n  // These are stand ins\n  std::array&lt;hal::byte, 1&gt; payload = { 0xA2 };\n  std::array&lt;hal::byte, 2&gt; buffer{};\n\n  // Write `payload` to [the device with the] address 0x23\n  hal::write(i2c, 0x23, payload);\n\n  // Fill `buffer` with data read from address 0x33\n  hal::read(i2c, 0x33, buffer);\n\n  // Return a buffer of 4 bytes with 4 bytes of data read from address 0x33\n  std::array&lt;hal::byte, 4&gt; response0 = hal::read&lt;4&gt;(i2c, 0x33);\n\n  // You can also use the \"auto\" keyword to shorten the line. The type will be a\n  // hal::array&lt;hal::byte, N&gt; where N is the integral template (the &lt;4&gt;)\n  // argument.\n  auto response0 = hal::read&lt;4&gt;(i2c, 0x33);\n\n  // Two ways to write `payload` to address 0x23 and fill `buffer` with the\n  // response.\n  hal::write_then_read(i2c, 0x23, payload, buffer);\n  auto response1 = hal::write_then_read&lt;4&gt;(i2c, 0x33, payload);\n\n  // Check if the device responds on the bus. Returns true if the device\n  // acknowledges the address 0x10.\n  if (hal::probe(i2c, 0x10)) {\n    // Device did acknowledge\n  } else {\n    // Device did NOT acknowledge\n  }\n}\n</code></pre>"},{"location":"education/i2c/#using-libraries-that-use-i2c","title":"Using libraries that use i2c","text":""},{"location":"education/i2c/#how-do-i-know-if-a-library-needs-i2c","title":"How do I know if a library needs i2c?","text":"<p>If the library's constructor requires a <code>hal::i2c&amp;</code>, then that library needs i2c to operate. This goes for any other libhal interface as well.</p>"},{"location":"education/i2c/#constructing-a-driver-that-needs-i2c","title":"Constructing a driver that needs i2c","text":"<p>In this example, we will be creating a driver for the very popular, albeit obsolete, MPU6050 inertial measurement unit (IMU) and the PWM generator pca9685. IMUs have the capability to measure acceleration and rotational velocity. The pca9685 can be instructed via the i2c to generate PWM signals.</p> <pre><code>#include &lt;libhal-sensor/mpu6050.hpp&gt;\n#include &lt;libhal-extender/pca9685.hpp&gt;\n\nvoid application() {\n  hal::i2c&amp; i2c = /* ... */;\n  // Use default address\n  hal::sensor::mpu6050 mpu0(i2c);\n  // Provide your own address if your MPU6050 model has a different address\n  hal::sensor::mpu6050 mpu1(i2c, 0x69);\n  // Use default address for the pca9685\n  hal::extender::pca9685 pca(i2c);\n}\n</code></pre> <p>Note</p> <p>Many i2c devices will have multiple optional address that you can configure them to use. Address configuration can come in many ways. Some devices use a digital lines to set the bits of the i2c address. Some use a single pin that can sense the voltage on the line and depending on where it is between 0V and the device's VCC, will change its address. There probably exists i2c devices with addresses that can be configured using i2c transactions. I2c has only 112 address. 26 of the 128 address in the 7-bit address space are reserved. Having so few addresses means that its not uncommon to have to deal with address conflicts.</p> <p>In the example application, there are two MPU6050 IMUs used. Each needs access to the i2c driver to operate. References to i2c objects can be shared between multiple device drivers but there are rules.</p>"},{"location":"education/i2c/#ensuring-the-correct-clock-rate","title":"Ensuring the correct clock rate","text":"<p>Drivers that use i2c are mandated to configure i2c to the highest possible clock rate that their device can support. But what if devices sharing the i2c resource have different max clock rates? In that case, a solution would be to use the <code>hal::soft::minimum_speed_i2c</code> wrapper provided by <code>libhal-soft</code>:</p> <pre><code>#include &lt;libhal-soft/i2c_minimum_speed.hpp&gt;\n\nhal::i2c&amp; i2c = /* ... */;\nhal::soft::minimum_speed_i2c min_speed_i2c(i2c);\n\nhal::sensor::mpu6050 mpu0(min_speed_i2c);\nhal::sensor::mpu6050 mpu1(min_speed_i2c, 0x69);\nhal::extender::pca9685 pca(min_speed_i2c);\n\n// This will set the\nmin_speed_i2c.set_clock_rate_to_max_common();\n</code></pre> <p><code>hal::soft::minimum_speed_i2c</code> requires an <code>hal::i2c</code> to construct. After creating the <code>minimum_speed_i2c</code>, use it instead of the original driver for all of your i2c needs. <code>minimum_speed_i2c</code> will set the clock rate of the i2c driver to <code>100kHz</code>, which is a safe default for i2c. When <code>configure</code> is called on <code>minimum_speed_i2c</code>, it caches the lowest frequency its seen and returns. It will NOT reconfigure the passed in i2c driver. To set the i2c driver to the max common rate across all of the drivers that use the shared i2c object, call <code>set_clock_rate_to_max_common()</code>.</p> <p>Critical</p> <p>The current <code>hal::soft::minimum_speed_i2c</code> does not behave is this way. It reconfigures to the lowest speed its seen after each <code>configure</code> call. This is problematic because it won't work on an I2C bus unless the i2c objects are constructed in a particular order. To show the issue consider passing an i2c to drivers A, B, and C. A has a max clock rate of 1MHz, B 400kHz and C 100kHz. If A's constructor sets the clock rate to 1MHz and attempts talk to the device, this could result in device B or C responding because they misinterpreted the information in the bus.</p>"},{"location":"education/i2c/#thread-safety","title":"Thread safety","text":"<p>Critical</p> <p>Thread safe i2c is not currently supported. When it is added, the following will become relevant. Its still a good read if you want to see how we handle thread safety for i2c.</p> <p>I2c drivers implementations do not need to consider thread safety. The rationale for this is that thread safety is not always needed for an i2c driver. If the application is written as a super-loop application or only one thread uses the i2c driver, then there is no thread safety issue and thus no need to support thread safety.</p> <p>What happens when an application does need to use an i2c driver between threads? One option is to use wrap anything that may use the i2c driver between threads with a mutex/lock guard:</p> <pre><code>auto thread_safe_mpu_read(mpu6050&amp; p_mpu) {\n  std::lock_guard guard(my_os_mutex);\n  return p_mpu.read();\n}\n\n// my_display also has the shared i2c with the mpu6050 driver\nauto thread_safe_clear_display(my_display&amp; p_display) {\n  std::lock_guard guard(my_os_mutex);\n  p_display.clear_screen();\n}\n</code></pre> <p>This can be very error prone, especially if its not obvious that a particular driver uses the shared i2c. What we really want is access to the i2c driver to be thread safe so drivers and application writers can focus on writing code that works.</p> <p><code>libhal-soft</code> provides the <code>hal::soft::thread_safe_i2c</code> wrapper which does what it says on the tin. This is how it works:</p> <pre><code>hal::i2c&amp; i2c = /* ... */;\nhal::basic_lock&amp; i2c_lock = /* ... */;\nhal::soft::thread_safe_i2c thread_safe_i2c(i2c, i2c_lock);\n\nhal::sensor::mpu6050 mpu0(thread_safe_i2c);\nhal::sensor::mpu6050 mpu1(thread_safe_i2c, 0x69);\nhal::extender::pca9685 pca(thread_safe_i2c);\n</code></pre> <p><code>hal::soft::thread_safe_i2c</code> requires an <code>hal::i2c</code> and a <code>hal::basic_lock</code> to construct. After creating the <code>thread_safe_i2c</code>, use it instead of the original driver for all of your i2c needs. When <code>configure</code> or <code>transaction</code> is called on <code>thread_safe_i2c</code>, it will first acquires the lock for <code>i2c_lock</code>, and after it has acquired the lock, it dispatches the call to the original i2c driver. Using the thread_safe_i2c ensures that all accesses to that resource are thread safe.</p> <p>There is one some safety issues with the code above. You can still access the original <code>i2c</code>. One could accidentally use that rather than the appropriate <code>thread_safe_i2c</code> causing a race condition. A way to get around this, is to pass the i2c and basic lock to the driver as a temporary:</p> <pre><code>hal::soft::thread_safe_i2c thread_safe_i2c(\n  hal::lpc40::i2c(2),\n  hal::freertos::basic_lock()\n);\n\nhal::sensor::mpu6050 mpu0(thread_safe_i2c);\nhal::sensor::mpu6050 mpu1(thread_safe_i2c, 0x69);\nhal::extender::pca9685 pca(thread_safe_i2c);\n</code></pre> <p>As you can see above, there is no longer an i2c instance that is accessible by the code to call, preventing accidental use and making race conditions impossible.</p> <p>Note</p> <p>This usage of <code>hal::soft::thread_safe_i2c</code> also devirtualizes calls to <code>hal::lpc40::i2c</code> and <code>hal::freertos::basic_lock</code>. This comes from the way that <code>hal::soft::thread_safe_i2c</code> works. <code>hal::soft::thread_safe_i2c</code> is a template and it captures the concrete type of the i2c and basic locks passed to it. By knowing the concrete type, the compiler can skip the indirection of a virtual call and call the underlying functions for the i2c driver. Same goes for the basic_lock. This provides a slight performance improvement. If your application has multiple <code>thread_safe_i2c</code> objects where the input types are not all the same type, then for each unique type combinations you get a new instance of <code>thread_safe_i2c</code>. This is typical of class templates. Read this article to learn more: C++ Core Guidelines T.5: Combine generic and OO techniques to amplify their strengths, not their cost</p>"},{"location":"education/i2c/#dealing-with-multi-controllers-on-the-bus","title":"Dealing with multi controllers on the bus","text":"<p>Critical</p> <p>The wrappers explained here are not currently supported but will in the future. When it is added, the following will become relevant. Its still a good read if you want to see how we handle multiple controllers on the bus for i2c.</p> <p>In general, it is bad practice to have multiple controllers on the i2c bus. I2c supports this architecture, but only one device can communicate at a time. If another controller is using the bus, then all other controllers must wait until that transaction is over before any other controller can use the bus.</p> <p>But if you are in a position where you have to share an i2c bus with multiple devices, this is how you manage that.</p> <p>TBD</p>"},{"location":"education/i2c/#writing-an-i2c-device-driver","title":"Writing an i2c device driver","text":"<p>I2c device drivers are drivers that require i2c to communicate with a chip or system.</p> <p>TBD</p>"},{"location":"education/i2c/#implementing-an-i2c-driver-on-bare-metal","title":"Implementing an i2c driver on bare metal","text":"<p>Implementing i2c can be a bit of a process. Implementing i2c is a platform specific bit of work, but many i2c peripherals have similar implementations. Modern microcontrollers and system-on-chips will implement i2c in the form of a state machine, using interrupts to notify the system that the i2c peripheral has moved from one state to another. If the i2c implementation you are working with does not follow the patterns described in the guide below, then you will need to figure out how to implement the <code>hal::i2c</code> based on the data sheet you've been provided.</p> <p>Coming soon...</p>"},{"location":"education/pwm/","title":"PWM: Pulse Width Modulation","text":"<p>Warning</p> <p>This document describes the PWM for libhal 5.0.0 which is not out yet.</p> <p>Welcome to the libhal pwm tutorial. PWM stands for pulse width modulation, a method of generating a square wave at a particular frequency where the ratio of time between the signal being ON (HIGH) or OFF (LOW) is determined by a duty-cycle. The duty cycle can be changed to change that ratio. That ratio can be used to approximate analog voltages on average and can be used for power control or transmitting information.</p>"},{"location":"education/pwm/#learning-about-pwm","title":"Learning about PWM","text":"<p>To learn more about PWM, why it exists, and what it can be used for check out this video by Rohde Schwarz Understanding Pulse Width Modulation. Video time is 13min and goes over much of theory and use cases for PWM.</p> <p>Here's the improved version of the tutorial on PWM using markdown:</p>"},{"location":"education/pwm/#pwm-interfaces-and-how-to-use-them","title":"PWM Interfaces and How to Use Them","text":"<p>The <code>hal::pwm16</code> interface in libhal provides a 16-bit PWM (Pulse Width Modulation) solution, allowing you to control the duty cycle and frequency of a PWM signal.</p> <p>The <code>hal::pwm16</code> class has the following interface:</p> <pre><code>namespace hal {\nclass pwm16 {\n    void frequency(hal::u32 p_frequency_hertz);\n    void duty_cycle(hal::u16 p_duty_cycle);\n};\n}\n</code></pre>"},{"location":"education/pwm/#halpwm16frequency","title":"<code>hal::pwm16::frequency</code>","text":"<p>The <code>frequency</code> method allows you to set the frequency, in Hertz, of the PWM waveform. If the requested frequency is outside the supported range of the PWM hardware, an <code>hal::argument_out_of_domain</code> exception will be raised. In practice, most PWM hardware can support a frequency range between 100 Hz and 100 kHz.</p>"},{"location":"education/pwm/#halpwm16duty_cycle","title":"<code>hal::pwm16::duty_cycle</code>","text":"<p>The <code>duty_cycle</code> method takes a <code>hal::u16</code> value representing the duty cycle of the PWM signal. The duty cycle is divided into 65,535 (2^16 - 1) parts, where:</p> <ul> <li>A value of 0 represents a 0% duty cycle (always off)</li> <li>A value of 65,535 represents a 100% duty cycle (always on)</li> <li>A value of 32,767 represents a 50% duty cycle (equal on and off time)</li> </ul> <p>Other values between 0 and 65,535 will set the duty cycle proportionally.</p>"},{"location":"education/pwm/#pwm-utilities","title":"PWM Utilities","text":""},{"location":"education/pwm/#halscale_to_u16range-value","title":"<code>hal::scale_to_u16(range, value)</code>","text":"<p>Maps the value from the range1 to the range2 to a proportional <code>hal::u16</code>. Here are multiple ways to set the duty cycle to 50%:</p> <pre><code>pwm.duty_cycle(hal::scale_to_u16({0, 100}, 50));\npwm.duty_cycle(hal::scale_to_u16({100, 0}, 50));\npwm.duty_cycle(hal::scale_to_u16({.a = 100, .b = 0}, 50));\npwm.duty_cycle(hal::scale_to_u16&lt;0, 100&gt;(50));\npwm.duty_cycle(hal::scale_to_u16&lt;100, 0&gt;(50));\n</code></pre> <p>If the ranges are known at compile time, use the template version <code>hal::scale_to_u16&lt;100, 0&gt;()</code> of this API as it is more optimal.</p> <p>The min and max range can be in any order.</p> <pre><code>// Increment duty cycle from 0% to 100% in 1% increments\nfor (int i = 0; i &lt; 100; i++) {\n  pwm.duty_cycle(hal::scale_to_u16&lt;0, 100&gt;(i));\n  hal::delay(clock, 100ms);\n}\n</code></pre> <p>Generically, there is <code>scale_to</code> which can take a type to scale up to.</p> <pre><code>// Increment duty cycle from 0% to 100% in 1% increments\nfor (int i = 0; i &lt; 100; i++) {\n  pwm.duty_cycle(hal::scale_to&lt;hal::u16, 0, 100&gt;(i));\n  hal::delay(clock, 100ms);\n}\n</code></pre>"},{"location":"education/pwm/#halpulse_widthfrequency-stdchronomicroseconds","title":"<code>hal::pulse_width(frequency, std::chrono::microseconds)</code>","text":"<p>Lets consider a situation where a user needs to generate a waveform with a specific pulse width based on time. RC servos are the classical example of this use case. The API takes a frequency and a duration in microseconds and returns the duty cycle value that will generate that pulse width.</p> <pre><code>pwm.duty_cycle(hal::pulse_width(50, 1500us)); // middle position\npwm.duty_cycle(hal::pulse_width(50, 1000us)); // starting position\npwm.duty_cycle(hal::pulse_width(50, 2000us)); // end position\n</code></pre>"},{"location":"education/rtos/","title":"RTOS: Real time Operating Systems","text":"<p>Coming soon...</p>"},{"location":"education/sensors/","title":"Basics of Sensors","text":"<p>Coming soon...</p>"},{"location":"education/spi/","title":"SPI: Serial Peripheral Interface","text":"<p>Warning</p> <p>This document describes the CAN for libhal 5.0.0 which is not available yet.</p> <p>Welcome to the libhal Serial Peripheral Interface (SPI) tutorial. SPI is a commonly used medium speed communication protocol used for things such as SD cards, sensors, and displays.</p>"},{"location":"education/spi/#learning-about-spi","title":"Learning about SPI","text":"<p>Here are some resources for learning SPI:</p> <ul> <li>\ud83c\udfa5 Understanding SPI by Rohde Schwarz:<ul> <li>Runtime: 12min</li> <li>Description: This video goes over much of theory and use cases for SPI. After watching this you should have all of the knowledge necessary to continue this tutorial.</li> </ul> </li> </ul>"},{"location":"education/spi/#spi-interfaces-and-how-to-use-them","title":"SPI interfaces and how to use them","text":"<p>In libhal there is a single interface for SPI: <code>hal::spi_channel</code>. It provides a means to communicate over the SPI bus and control the chip select for a device.</p>"},{"location":"education/spi/#public-apis","title":"Public APIs","text":"<pre><code>class spi_channel {\n  struct settings\n  {\n    enum class mode : u8\n    {\n      m0, // SPI mode 0\n      m1, // SPI mode 1\n      m2, // SPI mode 2\n      m3, // SPI mode 3\n    };\n    u32 clock_rate = 100_kHz;\n    mode select = mode::m0;\n  };\n\n  void configure(settings const&amp; p_settings);\n  u32 clock_rate();\n\n  void transfer(std::span&lt;hal::byte const&gt; p_data_out,\n                std::span&lt;hal::byte&gt; p_data_in = {},\n                hal::byte p_filler = default_filler);\n\n  void chip_select(bool p_select);\n  void lock() { chip_select(true); }\n  void unlock() { chip_select(false); }\n};\n</code></pre> <p>Note</p> <p>\"channel\" terminology for a spi driver may be a bit foreign to typical users of SPI. Why a \"channel\"? Channel implies a dedicated communication path. It can also imply that there is some sharing between other such channels utilizing the same bus resource but in a controlled way.</p> <p>Use the comments labeled below to explain how you'd use <code>hal::spi_channel</code>:</p> <pre><code>void spi_channel_usage(hal::spi_channel&amp; spi) {\n  // Set the settings for this channel. Note that this does not apply the\n  // settings to the SPI bus immediately. Instead it caches the configuration\n  // settings and applies them to the SPI bus after bus acquisition via the\n  // `chip_select()` or `transfer()` APIs.\n  spi.configure({\n    .clock_rate = 250_kHz,\n    .mode = hal::spi_channel::mode::m0, // select SPI MODE 0\n  });\n\n  // Acquires exclusive control over the spi bus and applies configuration\n  // settings to the bus. If the bus is currently busy, this call will block\n  // until control over the bus is available.\n  spi.chip_select(true);\n  // After this point, the settings passed into configure will be applied to\n  // the SPI bus.\n\n  // Write `device_config_payload` to the device selected on the bus\n  constexpr std::array&lt;hal::byte, 2&gt; device_config_payload = { 0x02, 0x4A };\n  spi.transfer(device_config_payload);\n\n  // Read 2 bytes from the bus into the response buffer.\n  std::array&lt;hal::byte, 2&gt; response = {};\n  spi.transfer({}, response);\n\n  // Releases control over the spi bus\n  spi.chip_select(false);\n\n  // Now use the data in `response`.\n}\n</code></pre> <p>The above works but in general, direct control over the chip select should be avoided and <code>std::lock_guard</code> should be used instead.</p> <pre><code>float read_sensor_data(hal::spi_channel&amp; p_spi)\n{\n  // Prefer to use `std::lock_guard` as an automatic way to acquire and release\n  // the spi bus at the end of the scope. Also ensures the bus is released in\n  // the event of an exception.\n  std::lock_guard access_bus(p_spi);\n\n  // Perform a write transfer then a read\n  constexpr std::array&lt;hal::byte, 1&gt; sensor_register = { 0x03 };\n  p_spi.transfer(sensor_register);\n\n  std::array&lt;hal::byte, 2&gt; sensor_data{};\n  // Passing an empty span for the `p_data_out` will cause the SPI bus to\n  // transfer the default filler byte 0xFF. Data will be read from the bus into\n  // the `sensor_data` array.\n  p_spi.transfer({}, sensor_data);\n\n  // Use the data to compute the sensor reading. Note this is all made up for\n  // demonstration purposes.\n  return (sensor_data[1] &lt;&lt; 8 | sensor_data[0]) / 12.0f;\n} // After the return, access_bus is destroyed and the bus is released!\n</code></pre>"},{"location":"education/spi/#clock-rate-settings","title":"Clock Rate Settings","text":"<p>Setting the clock rate for SPI is a \"best effort\" approach following this expression:</p> <pre><code>spi.clock_rate() &lt;= settings.clock_rate; // this always evaluates to TRUE.\n</code></pre> <p>The actual clock rate of the SPI bus will be equal to or less than the <code>settings.clock_rate</code> passed to the <code>configure</code> API. We make these assumptions about how SPI will be used:</p> <ul> <li>Devices that communicate over SPI have a maximum clock rate they can tolerate.</li> <li>Devices that communicate over SPI can talk at frequencies below their maximum   without issue.</li> <li>Any call to <code>configure</code> could be a request to set the clock rate to the   maximum a device can support.</li> </ul> <p>With these assumptions, a reasonable approach to clock rate setup would be to allow the bus frequency to be equal to or below the selected clock rate. If you have an application where the clock rate has to meet a very tight tolerance, you can use the <code>clock_rate()</code> function to return the integer value of the frequency in hertz.</p> <p>We choose this over throwing an exception if they do not match, because we believe that most users will be okay with \"fastest possible\" vs \"exactly the number I specified\". And if they really need the second one, they can check themselves.</p>"},{"location":"education/spi/#spi-device-manager","title":"SPI Device Manager","text":"<p>In order to acquire spi_channels you will need an spi device manager. SPI channels are acquired from a platform's SPI manager object like so:</p> <pre><code>#include &lt;libhal-arm-mcu/stm32f1/output_pin.hpp&gt;\n#include &lt;libhal-arm-mcu/stm32f1/spi.hpp&gt;\n#include &lt;libhal-util/atomic_spin_lock.hpp&gt;\n\nvoid initialize_platform() {\n  // do stuff ...\n\n  static hal::atomic_spin_lock spi_bus_lock;\n  static hal::stm32f1::output_pin cs1('A', 5);\n  static hal::stm32f1::output_pin cs2('A', 6);\n\n  // Select SPI bus 1, and pass it the\n  static hal::stm32f1::spi spi_manager(hal::port&lt;1&gt;, spi_bus_lock);\n\n  static auto spi_channel1 = spi_manager.acquire_channel(cs1);\n  static auto spi_channel2 = spi_manager.acquire_channel(cs2);\n\n  // do other stuff ...\n}\n</code></pre> <p>The code provides a chip select output pin to the spi manager and it returns a <code>hal::spi_channel</code> with access to the SPI bus. Each spi manager object controls a single bus so creating a channel results in multiple objects that have access to a single bus. Because of this, the spi channel objects must ensure that only one chip select out of the set of spi channel's corresponding to a single spi bus is active at a time AND that only one channel gets access to the spi bus at a time.</p>"},{"location":"education/spi/#spi-utility-libraries","title":"SPI Utility Libraries","text":"<p><code>libhal-util</code> provides a couple of helpful APIs for using SPI.</p> <p>Each of the APIs below automatically asserts the chip select so it is not necessary to do so outside. If you need to perform multiple writes, read, or write-then-read operations without asserting and de-asserting the chip select each time, add the <code>hal::no_cs</code> token as the first parameter of the utility APIs.</p>"},{"location":"education/spi/#halwrite","title":"<code>hal::write()</code>","text":"<pre><code>#include &lt;mutex&gt;\n\n#include &lt;libhal-util/spi.hpp&gt;\n\nvoid hal_write_spi_example(hal::spi_channel&amp; p_spi) {\n  constexpr std::array&lt;hal::byte, 2&gt; payload = {0x04, 0x22};\n  // Performs chip select, writes `payload` on the spi bus, ignore bytes on the\n  // receive line.\n  hal::write(p_spi, payload);\n}\n</code></pre> <p>Or you can use <code>std::to_array</code> to create a temporary array inline.</p> <pre><code>#include &lt;mutex&gt;\n\n#include &lt;libhal-util/spi.hpp&gt;\n\nvoid hal_write_spi_example(hal::spi_channel&amp; p_spi) {\n  // Performs chip select, writes array { 0x04, 0x22 } on the spi bus, ignore\n  // bytes on the receive line.\n  hal::write(p_spi, std::to_array&lt;hal::byte&gt;({0x04, 0x22}));\n}\n</code></pre> <p>And here is how you use <code>hal::no_cs</code> with the <code>write</code> API.</p> <pre><code>#include &lt;mutex&gt;\n\n#include &lt;libhal-util/spi.hpp&gt;\n\nvoid hal_write_spi_example(hal::spi_channel&amp; p_spi,\n                           std::span&lt;hal::byte const&gt; p_ssid,\n                           std::span&lt;hal::byte const&gt; p_password) {\n  constexpr auto header = std::to_array&lt;hal::byte&gt;({0xAA, 0xBB, 0x00, 0x7F});\n  constexpr auto spacer = std::to_array&lt;hal::byte&gt;({0x00});\n\n  // Select the chip via std::lock_guard\n  std::lock_guard select_device(p_spi);\n  // Write the following sets of data without asserting and de-asserting for\n  // reach write operation.\n  hal::write(hal::no_cs, p_spi, header);\n  hal::write(hal::no_cs, p_spi, p_ssid);\n  hal::write(hal::no_cs, p_spi, spacer); // lets assume this is necessary\n  hal::write(hal::no_cs, p_spi, p_password);\n}\n</code></pre>"},{"location":"education/spi/#halread","title":"<code>hal::read()</code>","text":"<pre><code>#include &lt;mutex&gt;\n\n#include &lt;libhal-util/spi.hpp&gt;\n\nvoid hal_read_spi_example(hal::spi_channel&amp; p_spi) {\n  std::array&lt;hal::byte, 2&gt; buffer{};\n\n  // Perform an SPI read, ignore bytes on the receive line.\n  hal::read(p_spi, buffer);\n\n  // Buffer contains 2 bytes read from the SPI bus\n}\n</code></pre> <p>If you you want to read a fixed number of bytes, you can set the template parameter to an unsigned number and that amount of bytes will be read and returned as an <code>std::array&lt;hal::byte, N&gt;</code>:</p> <pre><code>#include &lt;mutex&gt;\n\n#include &lt;libhal-util/spi.hpp&gt;\n\nvoid hal_read_spi_example(hal::spi_channel&amp; p_spi) {\n  // Perform an SPI read of 4 bytes and return the array\n  auto const response = hal::read&lt;4&gt;(p_spi, buffer);\n\n  // response contains 4 bytes read from the SPI bus\n}\n</code></pre> <p>And here is how you use <code>hal::no_cs</code> with the <code>read</code> API.</p> <pre><code>#include &lt;mutex&gt;\n\n#include &lt;libhal-util/spi.hpp&gt;\n\nvoid hal_read_spi_example(hal::spi_channel&amp; p_spi) {\n  // Select the chip via std::lock_guard\n  std::lock_guard select_device(p_spi);\n  // Read 4 bytes without changing the chip select state.\n  auto const response = hal::read&lt;4&gt;(hal::no_cs, p_spi);\n  // Use `response` ...\n}\n</code></pre>"},{"location":"education/spi/#halwrite_then_read","title":"<code>hal::write_then_read()</code>","text":"<pre><code>#include &lt;mutex&gt;\n\n#include &lt;libhal-util/spi.hpp&gt;\n\nvoid hal_read_spi_example(hal::spi_channel&amp; p_spi) {\n  constexpr std::array&lt;hal::byte, 1&gt; payload = { 0x10 };\n  std::array&lt;hal::byte, 3&gt; buffer{};\n\n  // Perform an SPI write operation, ignoring the bytes received during the\n  // write operation, then perform a read operation, filling the write bytes\n  // with the filler bytes.\n  hal::write_then_read(p_spi, payload, buffer);\n\n  // Buffer contains 3 bytes of data read from the SPI bus\n}\n</code></pre> <p>If you you want to read back a fixed number of bytes, you can set the template parameter to an unsigned number and that amount of bytes will be read and returned as an <code>std::array&lt;hal::byte, N&gt;</code>:</p> <pre><code>#include &lt;mutex&gt;\n\n#include &lt;libhal-util/spi.hpp&gt;\n\nvoid hal_write_then_read_spi_example(hal::spi_channel&amp; p_spi) {\n  // Select the chip via std::lock_guard\n  std::lock_guard select_device(p_spi);\n\n  constexpr std::array&lt;hal::byte, 1&gt; payload = { 0x10 };\n  // Perform an SPI write operation, ignoring the bytes received during the\n  // write operation, then perform a read operation, filling the write bytes\n  // with the filler bytes.\n  auto const response = hal::write_then_read&lt;3&gt;(p_spi, payload);\n\n  // Response contains 3 bytes of data read from the SPI bus\n}\n</code></pre> <p>And here is how you use <code>hal::no_cs</code> with the <code>hal::write_then_read</code> API.</p> <pre><code>#include &lt;mutex&gt;\n\n#include &lt;libhal-util/spi.hpp&gt;\n\nvoid hal_write_then_read_spi_example(hal::spi_channel&amp; p_spi) {\n  constexpr std::array&lt;hal::byte, 1&gt; data_reg = { 0x10 };\n  // Select the chip via std::lock_guard\n  std::lock_guard select_device(p_spi);\n  // Write `data_reg` address then read 4 bytes without changing the chip\n  // select state.\n  auto const response = hal::write_then_read&lt;3&gt;(hal::no_cs, p_spi, data_reg);\n}\n</code></pre>"},{"location":"education/spi/#usage-in-device-drivers","title":"Usage in device drivers","text":"<p>A typical device driver class that requires an spi channel would look like this:</p> <pre><code>class pseudo_temperature_sensor : public hal::temperature_sensor {\npublic:\n  /// Accept a `hal::spi_channel` by reference, and capture it's address\n  pseudo_temperature_sensor(hal::spi_channel&amp; p_spi): m_spi(&amp;p_spi) {\n    constexpr auto config_address = std::to_array({ 0x01 });\n\n    // Set the bus settings\n    m_spi-&gt;configure(settings);\n    // Write configuration register address to bus and then read back an array\n    // with length 1, and access byte [0].\n    hal::u8 config = hal::write_then_read&lt;1&gt;(*m_spi, config_address)[0];\n    // Set enable bit (5) in config register\n    config |= 1 &lt;&lt; 5;\n    // Write back configuration with enable bit set to the configuration\n    // register.\n    hal::write(*m_spi, std::to_array({ config_address[0], config }));\n  }\n\nprivate:\n  constexpr hal::spi_channel::settings settings = {\n    .clock_rate = 10_MHz,\n    .select = hal::spi_channel::mode::m0,\n  };\n\n  float driver_read() override {\n    // Made up ration to convert binary i16 value to celsius\n    constexpr float bin_to_celsius = 0.025f;\n    // Made up address of the temperature data\n    constexpr auto temperature_address = std::to_array({ 0x02 });\n    // We write the address and read back 2 bytes of data\n    auto const data = hal::write_then_read&lt;2&gt;(*m_spi, temperature_address);\n    // Combine the data bytes into an i16 value.\n    hal::i16 temperature = data[0] &lt;&lt; 8 | data[1];\n    // Calculate the temperature and return it.\n    return temperature * bin_to_celsius;\n  }\n\n  // Store hal::spi_channel as a pointer (never a reference)\n  hal::spi_channel* m_spi;\n};\n</code></pre>"},{"location":"education/spi/#writing-your-own-spi-driver","title":"Writing your own SPI driver","text":"<p>TBD</p>"},{"location":"education/stream_adc/","title":"Stream ADC: Multi Sample Analog to Digital Converter","text":"<p>Warning</p> <p>This document describes the ADC for libhal 5.0.0 which is not out yet.</p> <p>Warning</p> <p>This document is not complete yet.</p> <p>Welcome to the libhal stream adc tutorial. Stream ADCs are like normal ADCs but allow you to supply them with a buffer that they will capture data into. If you don't know what an ADC is, see the adc tutorial.</p>"},{"location":"education/stream_adc/#learning-about-adcs","title":"Learning about ADCs","text":"<p>This article will not explain how ADCs work as there are many lovely tutorials out there on line already. We but will provide a list of resources to learn about ADCs:</p> <ul> <li>Sparkfun Tutorial:   (RECOMMENDED) Quick and easy to understand.</li> <li>element14 ADC tutorial video:   A great 10min long video that goes into the many different ADC   implementations and how they convert voltages into decimal numbers.</li> </ul>"},{"location":"education/stream_adc/#adc-interfaces-and-how-to-use-them","title":"ADC interfaces and how to use them","text":"<p>libhal has 4 ADC interfaces. Each is suffixed with the bit resolution of the ADC.</p> <ul> <li><code>hal::stream_adc8</code>: for ADCs with 8 bits or below</li> <li><code>hal::stream_adc16</code>: for ADCs with 9 to 16 bits</li> <li><code>hal::stream_adc24</code>: for ADCs with 17 to 24 bits</li> <li><code>hal::stream_adc32</code>: for ADCs with 25 to 32 bits</li> </ul> <p>Different applications require different resolutions of analog measurement.</p> <ul> <li><code>hal::stream_adc8</code> for when resolution is not very important and can be low</li> <li><code>hal::stream_adc16</code> will be the most common ADC version and will suite most general   use cases</li> <li><code>hal::stream_adc24</code> is for applications that need high precision</li> <li><code>hal::stream_adc32</code> is for applications that need extremely high precision</li> </ul> <p>The ADC interfaces have a singular API which is <code>read()</code>.</p>"},{"location":"education/tbd/","title":"To be determined","text":"<p>This page is just a place holder for additional content. This page will always be here because there will always be more subjects to discuss when it comes to embedded systems.</p>"},{"location":"education/timers_and_counters/","title":"Timers &amp; Counters","text":"<p>Coming soon...</p>"},{"location":"education/uart/","title":"UART: Universal Asynchronous Receiver/Transmitter","text":"<p>Coming soon...</p>"},{"location":"project_information/about/","title":"About","text":"<p>The world of embedded systems is written almost entirely in C and C++. More and more of the embedded world move away from C and towards C++. This has to do with the many benefits of C++ such as type safety, compile time features, meta-programming, multi-paradigm and much more. When these features are used correctly, they can result in smaller binary sizes and higher performance code than in C.</p> <p>But a problem that embedded C++ software suffers is that there isn't a consistent and common API for embedded libraries. Looking around, you will find that each hardware vendor has their own set of libraries and tools for their specific products. If you write a driver on top of their libraries, you will find that your code will only work for that specific platform/product. In some cases you may also be limited to just their toolchain. You as the developer are locked in to this one specific setup. And if you move to another platform, you must do the work of rewriting all of your code again.</p> <p>libhal seeks to solve this issue by creating a set of generic interfaces for embedded system concepts such as serial communication (UART), analog to digital conversion (ADC), inertial measurement units (IMU), pulse width modulation (PWM) and much more. The advantage of building a system on top of libhal is that higher level drivers can be used with any target platform whether it is a stm32, a nxp micro controller, a RISC-V, or is on an embedded linux.</p> <p>This project is inspired by the work of Rust's embedded_hal and follows many of the same design goals.</p> <p>libhal's design goals:</p> <ol> <li>Serve as a foundation for building an ecosystem of platform agnostic drivers.</li> <li>Must abstract away device specific details like registers and bitmaps.</li> <li>Must be generic across devices such that any platform can be supported.</li> <li>Must be minimal for boosting performance and reducing size costs.</li> <li>Must be composable such that higher level drivers can build on top of these.</li> <li>Be accessible through package mangers so that developers can easily pick and    choose which drivers they want to use.</li> </ol>"},{"location":"project_information/about/#software-copyrights","title":"Software Copyrights","text":"<p>This source code is licensed under the Apache License 2.0 as described in the LICENSE file.</p>"},{"location":"project_information/about/#third-party-library-licenses","title":"Third Party Library Licenses","text":"<ul> <li>tl-function-ref/1.0.0, CC0</li> </ul>"},{"location":"project_information/status/","title":"\ud83d\udfe2 Library Status \ud83d\udd34","text":"<p>Repo</p> <p>CI State</p> <p>Latest Version</p> libhal/libhal libhal/libhal-util libhal/libhal-arm-mcu libhal/libhal-micromod libhal/libhal-expander libhal/libhal-sensor libhal/libhal-actuator libhal/libhal-display libhal/libhal-input libhal/libhal-freertos libhal/libhal-storage libhal/libhal-iot"},{"location":"user_guide/debugging/","title":"\ud83c\udfaf Debugging Firmware with PyOCD - A Beginner's Guide","text":""},{"location":"user_guide/debugging/#what-is-pyocd","title":"What is PyOCD?","text":"<p>PyOCD is a Python-based debugging tool specifically designed for ARM Cortex-M microcontrollers. Think of it as a bridge between your computer and your microcontroller that lets you inspect and control your program while it's running. While it only works with ARM processors, it's much more user-friendly than alternatives like OpenOCD.</p>"},{"location":"user_guide/debugging/#setting-up-your-environment","title":"Setting Up Your Environment","text":""},{"location":"user_guide/debugging/#1-install-pyocd","title":"1. Install PyOCD","text":"<pre><code>python3 -m pip install pyocd\n</code></pre>"},{"location":"user_guide/debugging/#2-connect-your-hardware","title":"2. Connect Your Hardware","text":"<ol> <li> <p>You'll need:</p> <ul> <li>Your development board</li> <li>A debugger (like STLinkV2)</li> <li>Appropriate connecting cables</li> </ul> </li> <li> <p>Make the physical connections:</p> <ul> <li>For SWD (most common):<ul> <li>Connect GND (Ground)</li> <li>Connect SWDIO (Data line)</li> <li>Connect SWDCLK (Clock line)</li> </ul> </li> <li>If your board uses JTAG:<ul> <li>Connect GND, TDI, TMS, TCK, and TDO pins</li> </ul> </li> <li>If you have a JTAG device that supports SWD<ul> <li>Connect GND</li> <li>Connect JTAG TMS to MCU SWDIO</li> <li>Connect JTAG TCK to MCU SWDCLCK</li> </ul> </li> </ul> </li> </ol> <p>Important</p> <p>Double-check all connections! Incorrect wiring can damage your board, debugger, or computer.</p>"},{"location":"user_guide/debugging/#starting-a-debug-session","title":"Starting a Debug Session","text":""},{"location":"user_guide/debugging/#1-launch-pyocd-server","title":"1. Launch PyOCD Server","text":"<p>First, start the PyOCD server for your specific device:</p> <pre><code># For LPC40xx boards:\npyocd gdbserver --target=lpc4088 --persist\n\n# For STM32F103xx boards:\npyocd gdbserver --target=stm32f103rc --persist\n</code></pre> <p>Not sure about your target? Run <code>pyocd list --targets</code> to see all options.</p>"},{"location":"user_guide/debugging/#2-connect-gdb","title":"2. Connect GDB","text":"<p>Open a new terminal and launch GDB:</p> <pre><code>arm-none-eabi-gdb -ex \"target remote :3333\" -tui your_program.elf\n</code></pre> <p>This command:</p> <ul> <li>Opens GDB with a text-based UI (<code>-tui</code>)</li> <li>Connects to PyOCD (<code>target remote :3333</code>)</li> <li>Loads your program (<code>your_program.elf</code>)</li> </ul> <p>Tip</p> <p><code>arm-none-eabi-gdb</code> command not found? No worries, build an project for an arm based device like so <code>conan build . -pr stm32f103c8 -pr arm-gcc-12.3</code>. There is a file called <code>generators/conanbuild.sh</code> which provides your command line access to the paths to the ARM compiler toolchain where GDB resides. Sourcing those environment variables would look like this, but replace <code>stm32f103c8</code> with your platform and <code>MinSizeRel</code> with your build type:</p> <pre><code>source build/stm32f103c8/MinSizeRel/generators/conanbuild.sh\n</code></pre>"},{"location":"user_guide/debugging/#basic-debugging-commands","title":"Basic Debugging Commands","text":""},{"location":"user_guide/debugging/#essential-gdb-commands","title":"Essential GDB Commands","text":"<pre><code># Start your debug session\nb main                   # Set breakpoint at main()\nmonitor reset halt       # Reset the CPU and stop at the beginning\nc                        # Continue execution\n\n# Navigate through code\nn (or next)              # Execute next line (skip function details)\ns (or step)              # Step into functions\nfinish                   # Run until current function returns\nc (or continue)          # Run until next breakpoint\n\n# Inspect values\np variable_name          # Print variable value\ninfo registers           # View all CPU registers\n</code></pre> <p>Tip</p> <p>If you are familiar with GDB, you notice that the command \"run\" was not used. In this context, there is no program, just the CPU. The debugger is controlling and stopping the CPU from executing. So there is no need to \"run\" the program, its already running. You simply have to continue.</p>"},{"location":"user_guide/debugging/#viewing-memory-and-registers","title":"Viewing Memory and Registers","text":"<p>To access hardware registers and memory:</p> <pre><code># Enable access to all memory\nset mem inaccessible-by-default off\n\n# View register values\np gpio_reg-&gt;CTRL         # View specific register\n</code></pre>"},{"location":"user_guide/debugging/#managing-breakpoints","title":"Managing Breakpoints","text":"<pre><code>b function_name         # Break at function start\nb filename.cpp:123      # Break at specific line\ninfo breakpoints        # List all breakpoints\ndelete 1                # Remove breakpoint #1\ndelete                  # Remove all breakpoints\n</code></pre>"},{"location":"user_guide/debugging/#updating-your-program","title":"Updating Your Program","text":"<p>If you make changes to your code:</p> <ol> <li>Build your program in another terminal</li> <li>In GDB:</li> </ol> <pre><code>monitor erase         # Erase current firmware image\nload                  # Flash the new program\nmonitor reset halt    # Reset to start and halt CPU\n</code></pre>"},{"location":"user_guide/debugging/#tips-for-beginners","title":"Tips for Beginners","text":"<ul> <li>Start with simple programs to get comfortable with the debugging process</li> <li>Use frequent breakpoints to understand program flow</li> <li><code>-s build_type=Debug</code> builds are easy to debug with a debugger than   <code>-s build_type=MinSizeRel</code> or <code>-s build_type=Release</code> builds</li> <li>Remember that embedded debugging is different from regular program debugging   because your code is running on actual hardware and you are controlling the   cpu</li> <li>If you can't see source code lines initially, don't worry - this is normal   with bootloaders (like on LPC40xx boards), proceed with the <code>continue</code>   command and you should end up at your first breakpoint whenever it is reached</li> </ul> <p>For a complete reference of GDB commands, check out this GDB Cheat Sheet.</p>"},{"location":"user_guide/error_handling/","title":"\ud83e\udea4 Error Handling in libhal","text":"<p>libhal utilizes C++ exception handling for transmitting errors. C++ exceptions were chosen over other error handling mechanisms because they:</p> <ol> <li>Improve code performance by separating error handling code from normal    code, thus enhancing the performance of the normal code by reducing the    cost of calling functions that could fail.</li> <li>Make error handling easier by allowing the user to wrap multiple blocks of    code within a handler distinguished by the type/category.</li> <li>Reduce the binary size of libraries and applications by:</li> <li>Using a single algorithm to allocate, construct, and transport errors       and direct the CPU to the appropriate error handling code.</li> <li>Eliminating the need for functions to contain error return paths when       participating in error propagation.</li> <li>Providing an error path using unwind instructions, a compressed form of       machine instructions that simulate the epilog of a function, but without       the requirement to return objects on the stack.</li> <li>Although handler code can increase the code size compared to plain code    (if/else/switch), the number of error handling blocks (<code>catch</code> blocks) is    typically much smaller compared to the cost of a distributed error handling    approach (<code>result&lt;T, E&gt;</code>, returning error codes, <code>optional/nil/null</code>).</li> <li>Offer additional space in which they could be significantly improved upon    beyond their current performance.</li> </ol> <p>With that out of the way, let's delve into how libhal manages errors.</p>"},{"location":"user_guide/error_handling/#how-to-use-exceptions-in-c","title":"How to use exceptions in C++","text":"<p>Let's start with signaling an error. This can be done by writing the following bit of code:</p> <pre><code>void check_if_device_is_valid(/* ... */) {\n  constexpr hal::byte expected_id = 0xAD;\n\n  // Get ID info from device ...\n\n  if (expected_id != retrieved_id) {\n     throw hal::no_such_device(this, expected_id);\n  }\n}\n</code></pre> <p>And to catch the thrown error you do this following:</p> <pre><code>void bar() {\n  try {\n    check_if_device_is_valid(/* ... */);\n  } catch(const hal::no_such_device&amp; p_error) {\n    // do something using the error info.\n  }\n}\n</code></pre> <p>Note that this is a simplified example.</p> <p>The <code>throw</code> keyword functions similarly to other languages, where you can throw or raise an error object. This exits the function's scope without returning normally. This action causes the system to revert the CPU's state back to the state of the try scope. The exception mechanism then moves the CPU's program counter to the correct catch block based on the thrown type. In this case, since we threw <code>hal::no_such_device</code>, the catch block for that type will be selected. If no catch blocks are present with a valid error type in any scope from which the error object was thrown, then <code>std::terminate()</code> is called.</p> <p>Everything within the scope of the try block is no longer valid memory. The significance of this is that the exception unwinding mechanism can and must skip spending cycles on constructing and bubbling objects from a lower stack frame to a higher one. Since the thrown object is the only thing that escapes the scope, any information needed for error handling should be copied to the thrown object as it is being thrown.</p>"},{"location":"user_guide/error_handling/#halexception-hierarchy","title":"<code>hal::exception</code> hierarchy","text":"<p>libhal has a hierarchy of errors, which looks like the following:</p> <pre><code>hal::exception\n\u251c\u2500\u2500 hal::no_such_device\n\u2502   \u2514\u2500\u2500 hal::stm32f1::i2c_core_dump_io_error\n\u251c\u2500\u2500 hal::io_error\n\u2502   \u2514\u2500\u2500 hal::lpc40::i2c_core_dump_io_error\n\u251c\u2500\u2500 hal::timed_out\n\u251c\u2500\u2500 ...\n\u2514\u2500\u2500 hal::unknown\n</code></pre> <p><code>hal::exception</code> is the base exception for all libhal exceptions and is typically not thrown directly. Its descendants are thrown instead, most having a 1-to-1 correspondence with the enumerated constants in <code>std::errc</code>. <code>std::errc</code> follows the POSIX error codes, providing a reasonable approximation of the types of errors hardware might encounter. An exception to this rule is <code>hal::unknown</code>, which represents an unknown error, used when the exact error is undetermined. Such cases should be rare in code.</p> <p>To see the full list of exception types available, refer to the error API docs. It is important to consult this documentation to understand which exceptions should be thrown and under what circumstances they can be recovered from.</p>"},{"location":"user_guide/error_handling/#expectation-from-libhal-libraries","title":"Expectation from libhal libraries","text":"<p>libhal libraries and utilities are required to only use only the direct descendants of <code>hal::exception</code> or a more derived exception with additional information.</p> <p>Exceptions outside of the <code>hal::exception</code> hierarchy may still be thrown from a libhal library if it comes from a call to a user defined callback. The user is allowed to throw any types they wish, although care should be taken in choosing the types to be thrown. This is useful for application code that wants to bypass catch blocks provided by libhal libraries.</p>"},{"location":"user_guide/error_handling/#how-do-you-know-what-throws-what","title":"How Do You Know What Throws What?","text":"<p>C++ does not currently have a mechanism to inform the user at compile time if an uncaught exception will terminate your application. Therefore, to know what may be thrown from a function, you'll need to consult the API documentation for the function. All libhal interfaces have strict requirements for their implementations to throw very specific <code>hal::exception</code> derived types.</p>"},{"location":"user_guide/error_handling/#knowing-when-to-catch-an-error","title":"Knowing when to catch an error","text":"<p>First and foremost, accept that your application may encounter an exception that will terminate it. Plan with this possibility in mind. Use hal::set_exception to set the terminate handler function as needed for your application, such as saving state information and resetting the device.</p> <p>With this in mind, ONLY catch the errors you know how to handle. If you do not know how to handle an error, allow it to propagate to higher levels in the call chain. This gives higher-level code the opportunity to handle errors.</p> <p>Do not encase each function in a try/catch block, as this is detrimental to code size and degrades the performance of the unwind mechanism by providing it more scopes to search through.</p>"},{"location":"user_guide/error_handling/#when-to-catch-halexception","title":"When to catch <code>hal::exception</code>","text":"<p><code>hal::exception</code> should only be caught when code wants to swallow all possible exceptions from libhal OR when translating exceptions from C++ to a C API that needs an error code that roughly follows <code>std::errc</code>.</p> <pre><code>int c_callback() {\n  try {\n    foo();\n    bar();\n    baz();\n  } catch (const hal::exception&amp; p_error) {\n    return static_cast&lt;int&gt;(p_error.error_code());\n  }\n}\n</code></pre>"},{"location":"user_guide/error_handling/#using-halexceptioninstance","title":"Using <code>hal::exception::instance()</code>","text":"<pre><code>try {\n  read_timeout();\n  bandwidth_timeout();\n} catch (const hal::timed_out&amp; p_exception) {\n  if (&amp;read_timeout == p_exception.instance()) {\n    hal::print(console, \"X\");\n    read_complete = true;\n  }\n  // TODO: Replace this exceptional bandwidth timeout with a variant that\n  // simply returns if the timeout has occurred. This is not its intended\n  // purpose but does demonstrates proper usage of `p_exception.instance()`.\n  else if (&amp;bandwidth_timeout == p_exception.instance()) {\n    hal::print(console, \"\\n   +  |\");\n    bandwidth_timeout = hal::create_timeout(counter, graph_cutoff);\n  } else {\n    throw;\n  }\n}\n</code></pre> <p>In this case, <code>read_timeout</code> and <code>bandwidth_timeout</code> are callable objects that live in a scope above the try block allowing them to be modified and updated in the error handling block. Because both of these objects can throw an exception, we may want to know which one throw the exception. We can use the <code>instance()</code> function to get the address of the object that threw an exception. If the instance does not match anything in scope, then it may have been from an object that was lower in the stack and is no longer valid.</p> <p>Note the comment or <code>bandwidth_timeout</code>. <code>bandwidth_timeout</code> is apart of the normal control flow and should not be reporting errors to move along the normal control flow. <code>read_timeout</code> on the other hand does report an actual error in this context. This example is taken from <code>libhal-esp8266/demos/applications/at_benchmark.cpp</code>.</p> <p>Caution</p> <p>DO NOT USE <code>const_cast</code> and <code>reinterpret_cast</code> to FORCE an address from <code>instance()</code> into a pointer to some other type and then attempt to use it. This is strong undefined behavior. ONLY use the address returned from instance as a means to compare it to other objects.</p>"},{"location":"user_guide/error_handling/#why-you-shouldnt-throw-an-int-or-other-primitives","title":"Why you shouldn't throw an <code>int</code> or other primitives","text":"<p>Application callbacks are allowed to throw whatever type they wish although care should be taken to consider a good type to throw.</p> <p>Throwing <code>int</code> is generally a bad choice because it gives little to no information about what the kind of error is. And if such a choice was used, it probably means that the int encodes an error code, meaning many sections of code would need to catch it, check if its their error code, and rethrow it, if it is not the correct error code. This resulting in a large number of catch blocks.</p>"},{"location":"user_guide/fundamentals/","title":"\ud83e\uddf1 Fundamentals of libhal","text":""},{"location":"user_guide/fundamentals/#what-is-libhal","title":"What is libhal?","text":"<p>libhal (Hardware Abstraction Layer Library) is a C++ library that provides clean interfaces for working with hardware devices. Think of it as a translator between your code and the actual hardware - you write simple commands, and libhal handles all the complex hardware-specific details.</p> <p>For example, to control an LED, you just need to:</p> <pre><code>// Create an output pin and control it\nhal::output_pin led_pin = /* ... */;\nled_pin.level(true);  // Turn LED on\nled_pin.level(false); // Turn LED off\n</code></pre> <p>You don't need to worry about:</p> <ul> <li>Power management</li> <li>Timer configurations</li> <li>Register settings</li> <li>Platform-specific initialization</li> </ul>"},{"location":"user_guide/fundamentals/#core-concepts","title":"\ud83d\udca1 Core Concepts","text":""},{"location":"user_guide/fundamentals/#platforms","title":"Platforms","text":"<p>Platforms are devices that can execute code on. This can be a microcontrollers or operating system such as Linux. Some microcontrollers we currently support would be:</p> <ul> <li>lpc40xx</li> <li>stm32f10x</li> <li>stm32f411re</li> <li>RP2040/rp2350 (coming soon)</li> </ul>"},{"location":"user_guide/fundamentals/#interfaces","title":"Interfaces","text":"<p>Interfaces are the foundation of libhal. They define a set of functions that any implementing class must provide. Think of them as a contract - if a class implements an interface, it promises to provide all the functionality specified by that interface.</p> <p>Here's a simple example of an input pin interface:</p> <pre><code>class input_pin\n{\npublic:\n  struct settings\n  {\n    pin_resistor resistor = pin_resistor::none;\n  };\n\n  void configure(settings const&amp; p_settings) { driver_configure(p_settings); }\n  [[nodiscard]] bool level() { return driver_level(); }\n\n  virtual ~input_pin() = default;\nprivate:\n  virtual void driver_configure(settings const&amp; p_settings) = 0;\n  virtual bool driver_level() = 0;\n};\n</code></pre> <p>This interface can be used like this:</p> <pre><code>void use_input_pin(input_pin&amp; pin)\n{\n  if (pin.level()) {\n    // Do something when the pin is HIGH\n  } else {\n    // Do something when the pin is LOW\n  }\n}\n\n// Use it with any input pin implementation\nhal::stm32f103::input_pin my_pin('B', 2);\nuse_input_pin(my_pin);\n</code></pre>"},{"location":"user_guide/fundamentals/#driver-types","title":"Driver Types","text":"<p>libhal has three main types of drivers:</p> <ol> <li> <p>Peripheral Drivers</p> <ul> <li>Built into the microcontroller</li> <li>Examples: pins, I2C, SPI, UART, ADC</li> <li>Form the foundation for communicating with external devices</li> <li>Fixed in number (you can't add more than what's built into the chip)</li> </ul> </li> <li> <p>Device Drivers</p> <ul> <li>Control external hardware</li> <li>Examples: sensors, motor controllers, displays</li> <li>Require peripheral drivers to communicate</li> <li>Example usage:</li> </ul> <pre><code>// Using an I2C peripheral to communicate with an MPU6050 sensor\nhal::stm32f103::i2c i2c_bus(1);\nhal::sensor::mpu6050 imu(i2c_bus);\nauto data = imu.read_accelerometer();\n</code></pre> </li> <li> <p>Soft Drivers</p> <ul> <li>Pure software implementations that emulate interfaces</li> <li>Examples:<ul> <li>Creating I2C using GPIO pins</li> <li>Input/output pin inverters</li> <li>Thread-safe wrapper drivers</li> </ul> </li> </ul> </li> </ol>"},{"location":"user_guide/fundamentals/#device-managers","title":"Device Managers","text":"<p>Some complex devices need special handling. Device managers are classes that can provide multiple types of functionality:</p> <pre><code>// Example: RMD smart servo that provides multiple capabilities\nhal::rmd::drc smart_servo(/* ... */);\n\n// Get different interface implementations from the same device\nauto position_control = smart_servo.servo();\nauto temperature_sensor = smart_servo.temperature_sensor();\nauto voltage_sensor = smart_servo.voltage_sensor();\n</code></pre>"},{"location":"user_guide/fundamentals/#library-categories","title":"\ud83d\udcda Library Categories","text":"<p>libhal provides several types of libraries:</p> <ol> <li> <p>Platform Libraries</p> <ul> <li>Provide drivers for specific microcontrollers</li> <li>Handle hardware-specific details</li> <li>Example: STM32F1 library with its pin, I2C, and UART implementations</li> </ul> </li> <li> <p>Device Libraries</p> <ul> <li>Drivers for external hardware</li> <li>Platform-independent</li> <li>Example: Temperature sensor library that works on any platform with I2C</li> </ul> </li> <li> <p>Utility Libraries</p> <ul> <li>Pure software utilities</li> <li>Platform-independent helpers</li> <li>Examples: Buffer implementations, algorithms, data structures</li> </ul> </li> <li> <p>RTOS Libraries</p> <ul> <li>Enable multi-tasking capabilities</li> <li>Provide threading and synchronization</li> <li>Help manage shared resources</li> </ul> </li> <li> <p>Process Libraries</p> <ul> <li>Implement specific functionality using drivers</li> <li>Example: Sensor fusion combining accelerometer and gyroscope data</li> </ul> </li> </ol>"},{"location":"user_guide/fundamentals/#best-practices","title":"\u2b50\ufe0f Best Practices","text":"<ol> <li>Use Interfaces: Write code that works with interfaces rather than    specific implementations when possible. This makes your code more portable.</li> <li>Resource Management: Make sure device manager objects outlive any    drivers created from them.</li> <li>Driver Selection: Use the simplest driver type that meets your needs.    Start with peripheral drivers and build up to more complex solutions only    when needed.</li> </ol>"},{"location":"user_guide/interfaces/","title":"\ud83d\udd17 Interfaces in libhal","text":""},{"location":"user_guide/interfaces/#what-are-interfaces","title":"What are Interfaces?","text":"<p>An interface is like a contract between different parts of your program. It defines what methods a class must implement, without specifying how they should work. This is powerful because it lets you:</p> <ul> <li>Write code that works with any hardware that follows the interface</li> <li>Switch hardware without changing your application code</li> <li>Test your code more easily</li> </ul> <p>For example, if you write code using the <code>hal::input_pin</code> interface, it will work with any microcontroller that provides an implementation of that interface.</p>"},{"location":"user_guide/interfaces/#available-interfaces","title":"Available Interfaces","text":""},{"location":"user_guide/interfaces/#digital-io","title":"Digital I/O","text":"Input PinOutput PinInterrupt Pin <p>See API: <code>hal::input_pin</code></p> <p>Reads the state of a digital pin (HIGH or LOW). Used for:</p> <ul> <li>Reading button presses</li> <li>Detecting digital signals</li> <li>Reading logic levels</li> </ul> <p>See API: <code>hal::output_pin</code></p> <p>Controls digital outputs (HIGH or LOW). Used for:</p> <ul> <li>Controlling LEDs</li> <li>Sending digital signals</li> <li>Setting logic levels</li> </ul> <p>See API: <code>hal::interrupt_pin</code></p> <p>Calls a function when a pin's state changes. Used for:</p> <ul> <li>Detecting button presses</li> <li>Responding to external signals</li> <li>Event-driven programming</li> </ul>"},{"location":"user_guide/interfaces/#analog-interfaces","title":"Analog Interfaces","text":"ADC (Analog-to-Digital Converter)DAC (Digital-to-Analog Converter)Stream DACPWM (Pulse Width Modulation) <p>See API: <code>hal::adc</code></p> <p>Converts analog signals to digital values. Used for:</p> <ul> <li>Reading sensor values</li> <li>Measuring voltages</li> <li>Processing analog inputs</li> </ul> <p>See API: <code>hal::dac</code></p> <p>Converts digital values to analog signals. Used for:</p> <ul> <li>Generating analog voltages</li> <li>Controlling analog devices</li> </ul> <p>See API: <code>hal::dac</code></p> <p>Converts digital values to analog signals. Used for:</p> <ul> <li>Generating analog voltages based on a PCM waveform data</li> <li>Generating audio output</li> </ul> <p>See API: <code>hal::pwm</code></p> <p>Generates square waves with controllable duty cycle. Used for:</p> <ul> <li>Motor speed control</li> <li>LED brightness control</li> <li>Signal generation</li> </ul>"},{"location":"user_guide/interfaces/#time-management","title":"Time Management","text":"TimerSteady Clock <p>See API: <code>hal::timer</code></p> <p>Schedules future events. Used for:</p> <ul> <li>Delayed operations</li> <li>Periodic tasks</li> <li>Timeout management</li> </ul> <p>See API: <code>hal::steady_clock</code></p> <p>Provides consistent time measurements. Used for:</p> <ul> <li>Measuring durations</li> <li>Timing operations</li> <li>Creating delays</li> </ul>"},{"location":"user_guide/interfaces/#communication-protocols","title":"Communication Protocols","text":"SPII2CSerialCAN <p>See API: <code>hal::spi</code></p> <p>Fast, synchronous communication protocol. Used for:</p> <ul> <li>Communicating with displays</li> <li>Reading memory chips</li> <li>High-speed sensor data</li> </ul> <p>See API: <code>hal::i2c</code></p> <p>Two-wire communication protocol. Used for:</p> <ul> <li>Connecting multiple sensors</li> <li>Reading small devices</li> <li>Low-speed communication</li> </ul> <p>See API: <code>hal::serial</code></p> <p>Basic serial communication. Used for:</p> <ul> <li>Bi-direction asynchronous communication with a single device</li> <li>Communication with computers</li> </ul> <p>See API: <code>hal::can</code></p> <p>Robust communication bus. Used for:</p> <ul> <li>Automotive systems</li> <li>Industrial networks</li> <li>Multi-device communication</li> </ul>"},{"location":"user_guide/interfaces/#motion-control","title":"Motion Control","text":"MotorServo <p>See API: <code>hal::motor</code></p> <p>Controls open-loop motors. Used for:</p> <ul> <li>Basic motor control</li> <li>Fan control</li> <li>Simple actuators</li> </ul> <p>See API: <code>hal::servo</code></p> <p>Controls position-based motors. Used for:</p> <ul> <li>Precise positioning</li> <li>Robotic arms</li> <li>Camera mounts</li> </ul>"},{"location":"user_guide/interfaces/#sensors","title":"Sensors","text":"Temperature SensorAccelerometerGyroscopeMagnetometerDistance SensorRotation Sensor <p>See API: <code>hal::temperature_sensor</code></p> <p>Measures temperature. Used for:</p> <ul> <li>Environmental monitoring</li> <li>System protection</li> <li>Process control</li> </ul> <p>See API: <code>hal::accelerometer</code></p> <p>Measures acceleration in X, Y, Z axes. Used for:</p> <ul> <li>Motion detection</li> <li>Orientation sensing</li> <li>Vibration monitoring</li> </ul> <p>See API: <code>hal::gyroscope</code></p> <p>Measures rotation rates. Used for:</p> <ul> <li>Navigation</li> <li>Stabilization</li> <li>Motion tracking</li> </ul> <p>See API: <code>hal::magnetometer</code></p> <p>Measures magnetic fields. Used for:</p> <ul> <li>Compass heading</li> <li>Position detection</li> <li>Metal detection</li> </ul> <p>See API: <code>hal::distance_sensor</code></p> <p>Measures linear distance. Used for:</p> <ul> <li>Object detection</li> <li>Range finding</li> <li>Proximity sensing</li> </ul> <p>See API: <code>hal::rotation_sensor</code></p> <p>Measures angular position. Used for:</p> <ul> <li>Motor position feedback</li> <li>Device orientation tracking</li> <li>Angle measurement</li> </ul>"},{"location":"user_guide/interfaces/#coming-soon","title":"\u23f3 Coming Soon","text":"Current SensorVoltage SensorGPS <p>API not available yet</p> <p>Measure electrical current flow in circuits. Used for:</p> <ul> <li>Calculating battery state of charge</li> <li>Measuring system power consumption</li> <li>Measure motor torque/force</li> </ul> <p>API not available yet</p> <p>Will measure voltage differences in circuits.</p> <p>API not available yet</p> <p>Will provide location, time, and velocity data from GPS signals.</p>"},{"location":"user_guide/interfaces/#understanding-virtual-functions-in-c","title":"Understanding Virtual Functions in C++","text":"<p>A quick note about virtual functions (which libhal uses extensively):</p> <ol> <li>They don't require heap memory: Virtual functions work fine with    stack-allocated objects.</li> <li>Performance impact is minimal: The overhead is usually just one pointer    lookup.</li> <li>Memory overhead is small: Each class with virtual functions needs only    one vtable (shared between all instances).</li> </ol> <p>Example of using virtual functions efficiently:</p> <pre><code>// This works fine - no heap allocation needed\nhal::lpc4078::i2c i2c2(2);  // Stack allocated\ninitialize_display(i2c2);   // Uses virtual functions, but still efficient\n</code></pre>"},{"location":"user_guide/policy/","title":"\u2696\ufe0f Policies &amp; FAQ","text":""},{"location":"user_guide/policy/#1-ensuring-consistency-across-platforms","title":"1. Ensuring Consistency Across Platforms","text":"<p>To maintain a consistent interface across platforms, libhal adopts:</p> <ol> <li>Clearly articulated rules and interface API documentation. This ensures every    potential input produces a predictable behavior.</li> <li>Testing mechanisms that ensure adherence to these standards.</li> </ol> <p>While libhal covers the documentation aspect, our CI integration doesn't yet encompass all testing facets, simulated or real-world. We are in the process of designing a compliance test suitable both for device testing and CI inclusion. Presently, the onus is on manual testing and meticulous inspection.</p> <p>Regarding unit tests: Although beneficial for purely software libraries, they're not always feasible for embedded systems. Once you mock components like i2c or input pins, the actual device testing veers towards simulation. This method is viable post verifying the device compatibility, solidifying the code behavior through unit tests. High-level conceptual and application codes can harness such tests, but unit testing often misaligns with low-level drivers.</p>"},{"location":"user_guide/policy/#2-driver-development-in-libhal","title":"2. Driver Development in libhal","text":"<p>How are these drivers created? Do new products gain immediate support?</p> <p>Our developers craft code by hand. Fully automated firmware driver solutions either fall short on efficiency or fail to span multiple devices. However, for devices adhering to standards like NMEA or JEDEC, automation holds potential. We're also considering tools that process SVD files into bit mask ranges, assuming no licensing complications arise.</p>"},{"location":"user_guide/policy/#3-oems-stance-on-libhal-software","title":"3. OEM's Stance on libhal Software","text":"<p>Does libhal have defenses against potential vendor objections?</p> <p>Using OEM-developed SDKs can be tricky due to restrictive licensing. For instance, SDKs from NXP or STM mandate their code only run on their specific devices. Some chips might mirror the architecture of another, but licensing can inhibit cross-utilization.</p> <p>Our safeguard? Any software we integrate is crafted by our engineers, strictly based on publicly accessible OEM manuals. We're mindful of potential exceptions and will handle them case-by-case.</p>"},{"location":"user_guide/policy/#4-vendor-sdk-utilization-in-libhal","title":"4. Vendor SDK Utilization in libhal","text":"<p>How does libhal tackle licensed APIs? What does it mean for the end developer?</p> <p>Currently, libhal steers clear of SDKs with confining licenses or those misaligned with Apache 2.0 or its equivalents. This includes licenses from NXP and STM. However, SDKs from Espressif Systems (with Apache 2.0) and Pico SDK are potentially usable so long as they reach our quality bar.</p>"},{"location":"user_guide/policy/#5-dealing-with-devices-lacking-public-manuals","title":"5. Dealing with Devices Lacking Public Manuals","text":"<p>Devices without public user manuals will not get a libhal library. Here's why:</p> <ol> <li>It risks unintentional exposure of proprietary device information.</li> <li>Without a manual, the code operates like a black box, turning debugging into    a reverse-engineering puzzle.</li> </ol> <p>We can craft drivers for such devices, but their source code would remain confidential. The libhal organization may perform such work on a contract basis but such work would not make it to the open source ecosystem.</p>"},{"location":"user_guide/setup_vscode/","title":"Setting up VSCode w/ <code>clangd</code>","text":"<p>Most of our users use VSCode so we made a guide for them. These guidelines should also work for non-vscode users as well.</p> <p>Info</p> <p>The default \"C/C++\" extension by VSCode is nice that it can figure a ton of things out about your system automatically. But the way we write code for <code>libhal</code> using <code>conan</code> makes the extension difficult and slow to use. This is due to the fact that we need to point the extension to the <code>.conan2/p/</code> (conan 2 package directory). Because that directory could have a large number of files and multiple version of the same project, it tends to get confused, stop working, or get very slow. We recommend <code>clangd</code> because it is fast, helpful, and easy to use.</p>"},{"location":"user_guide/setup_vscode/#setup-steps","title":"Setup Steps","text":"<p>Make sure you have already installed clang via the \ud83d\ude80 Getting Started guide.</p> <ol> <li>Install VSCode if you don't already have    it installed.</li> <li>Go the the \"Extensions\" section on the left side bar. It looks like 4 blocks    with the upper right hand block disconnected from the other 3.  Hover over    the icons to get their name.</li> <li>Search for \"C/C++\" and disable the Windows intellisense extension if it is    already installed and enabled.</li> <li>Search for the extension <code>clangd</code> and install the extension.</li> <li>Go the the <code>clangd</code> extension settings page. Find the clangd extension and    press the GEAR \u2699\ufe0f icon to open up it settings.</li> <li>Find the settings <code>clangd: Arguments</code> and add:<ol> <li>Linux &amp; Mac: <code>--query-driver=**/g++,**/*-g++</code></li> <li>Windows: <code>--query-driver=**/g++.exe,**/*-g++.exe</code></li> </ol> </li> <li>On Mac change <code>Clangd: Path</code> to:<ol> <li>Intel Mac 13: <code>/usr/local/opt/llvm@17/bin/clang++</code></li> <li>All other versions: <code>/opt/homebrew/opt/llvm@17/bin/clangd</code></li> </ol> </li> </ol> <p>Clangd arguments should look like this:</p> <p></p>"},{"location":"user_guide/setup_vscode/#refreshing-the-language-server","title":"Refreshing the Language Server","text":"<p>Now that you should have your <code>compile_commands.json</code> in the right location, you just need to refresh your LSP.</p> <ol> <li>In VSCode Press: <code>\u2318+shift+P</code> on Mac or <code>Ctrl+Shift+P</code> on everything else.</li> <li>Select the following command: <code>clangd: restart language server</code></li> </ol> <p>Now your LSP should be active and your C++ files should be able to find your includes as well as infer the types of your objects.</p>"},{"location":"user_guide/setup_vscode/#enabling-clangd","title":"Enabling <code>clangd</code>","text":""},{"location":"user_guide/setup_vscode/#for-a-libhal-library-projects","title":"For a libhal library projects","text":"<p>If you are contributing to libhal project/repo, then those libraries and demos will already be using <code>libhal-cmake-util/[^4.0.5]</code> which will automatically enable the generation of a <code>compile_commands.json</code> file. To get this file, run:</p> <pre><code>conan build .\n</code></pre> <p>And it will be generated.</p> <p>If you are attempting to do with is a demo or an application you will need to specify the platform and compiler like usual.</p> <pre><code>conan build . -pr lpc4078 -pr arm-gcc-12.3\n</code></pre>"},{"location":"user_guide/setup_vscode/#for-your-own-project","title":"For your own project","text":"<p>You can either add a <code>self.requires(\"libhal-cmake-util/[^4.0.5]\")</code> to your project or add the following lines to your <code>CMakeLists.txt</code>.</p> <pre><code># Generate compile commands for anyone using our libraries.\nset(CMAKE_EXPORT_COMPILE_COMMANDS ON)\n\n# Always run this custom target by making it depend on ALL\nadd_custom_target(copy_compile_commands ALL\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_BINARY_DIR}/compile_commands.json\n    ${CMAKE_SOURCE_DIR}/compile_commands.json\n    DEPENDS ${CMAKE_BINARY_DIR}/compile_commands.json)\n</code></pre> <p>Now run <code>conan build .</code> (where <code>.</code> is the path to your project or library) and it should generate the <code>compile_commands.json</code> file.</p> <p>Ensure that you include the necessary profiles added to the build.</p> <pre><code>conan build . -pr stm32f103 -pr arm-gcc-12.3\n</code></pre>"},{"location":"user_guide/setup_vscode/#how-clangd-works","title":"How <code>clangd</code> works","text":"<p>You are almost done, but we need to discuss what is needed to make <code>clangd</code> work. A workspace will need a <code>compile_commands.json</code> file to be present in your root directory or to use a <code>.clangd</code> file at the root of the repo that configures where to look for the <code>.json</code> file. <code>compile_commands.json</code> tells <code>clangd</code> what commands you are using in order to determine exactly how your files are built and what commands are used to build them, which provides the following benefits:</p> <ol> <li>More accurate warnings and error messages in the IDE</li> <li>Faster response time because only the necessary includes for the specific    version you are targeted will be used in the evaluation.</li> </ol>"}]}